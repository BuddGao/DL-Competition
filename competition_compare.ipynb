{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BuddGao/DL-Competition/blob/main/competition_compare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihsR_ew8QNCr"
      },
      "source": [
        "#COVID-19 Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ycwr5g60RUs",
        "outputId": "ba301768-6d55-4d2e-cc8e-a75d093d6e97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOZCN2EusO5_"
      },
      "outputs": [],
      "source": [
        "## if you haven't unzipped training data\n",
        "#!unzip \"drive/MyDrive/DL_Project/Train.zip\" -d  \"drive/MyDrive/DL_Project/\"\n",
        "\n",
        "## if you haven't unzipped val data\n",
        "#!unzip \"drive/MyDrive/DL_Project/Val Blind.zip\" -d  \"drive/MyDrive/DL_Project/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFBUy1lBQIM5"
      },
      "source": [
        "## Custom Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TckWJ9O4sVJT"
      },
      "outputs": [],
      "source": [
        "## preprocess data\n",
        "## create custom data class\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "\n",
        "#from monai.transforms import Compose, LoadImage, AddChannel, ScaleIntensity,RandRotate, ToTensor, RandFlip, RandZoom, Resize, RandGaussianNoise\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils, models, datasets\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "class CovidDataset(Dataset):\n",
        "    \"\"\"Covid CT dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.label_data = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        ## you can apply custom transformation on the image for data augmentation\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = os.path.join(self.root_dir, self.label_data.iloc[idx, 0])\n",
        "        image = io.imread(img_name)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR)\n",
        "        \n",
        " \n",
        "        p = self.label_data.iloc[idx, 1]\n",
        "\n",
        "        subject_num = self.label_data.iloc[idx, 2]\n",
        "        \n",
        "\n",
        "        # should be only applied on image, not percentage or subject #\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        sample = {'image': image, 'percentage': p, 'subject': subject_num, 'img_name':img_name}\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0hPdBQZ3DLE"
      },
      "outputs": [],
      "source": [
        "class CovidTestDataset(Dataset):\n",
        "    \"\"\"Covid CT TEST dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_list = []\n",
        "        for filename in glob.glob(self.root_dir+\"/*.png\"): #assuming png\n",
        "          self.image_list.append(filename)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = self.image_list[idx]\n",
        "        image = io.imread(img_name)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR)\n",
        "        image = torchvision.transforms.functional.to_tensor(image)\n",
        "\n",
        "        # should be only applied on image, not percentage or subject #\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "    \n",
        "        sample = {'image': image, 'img_name':img_name}\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmV47ZBJy1Nv"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "covid_dataset_train_val = CovidDataset(csv_file='drive/MyDrive/DL_Project/Train.csv',\n",
        "                                    root_dir='drive/MyDrive/DL_Project/Train'\n",
        "                                    ,transform = transforms.Compose([\n",
        "                                                transforms.ToPILImage(),                     \n",
        "                                                transforms.Resize((224, 224)),\n",
        "                                                transforms.RandomHorizontalFlip(),\n",
        "                                                transforms.RandomRotation(15),\n",
        "                                                \n",
        "                                                transforms.ToTensor(),\n",
        "                                                \n",
        "                                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ])\n",
        "                                    \n",
        "                                    )\n",
        "\n",
        "covid_dataset_test = CovidTestDataset(root_dir='drive/MyDrive/DL_Project/Val',\n",
        "                                      transform = transforms.Compose([\n",
        "                                                transforms.ToPILImage(),                     \n",
        "                                                transforms.Resize((224, 224)),\n",
        "                                                \n",
        "                                                transforms.ToTensor(),\n",
        "                                                \n",
        "                                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ])\n",
        "                                      #,transform = transforms.Compose([\n",
        "                                        #  LoadImage(),\n",
        "                                         # AddChannel(),\n",
        "                                          #ScaleIntensity(),\n",
        "                                          #ToTensor()])\n",
        "                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "rJg-KZXP1AcI",
        "outputId": "943683ad-c5fb-40da-e666-351c2789f172"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 torch.Size([3, 224, 224]) 0.0 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 torch.Size([3, 224, 224]) 0.0 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 torch.Size([3, 224, 224]) 0.0 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 torch.Size([3, 224, 224]) 0.0 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "## plot training example\n",
        "for i in range(len(covid_dataset_train_val)):\n",
        "    sample = covid_dataset_train_val[i]\n",
        "    print(i, sample['image'].shape, sample['percentage'], sample['subject'])\n",
        "    ax = plt.subplot(1, 4, i + 1)\n",
        "    plt.tight_layout()\n",
        "    ax.set_title('Sample #{}'.format(i))\n",
        "    ax.axis('off')\n",
        "    plt.imshow(sample['image'].numpy().transpose(1,2,0))\n",
        "    if i == 3:\n",
        "        plt.show()\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "YuAZNhAB1BXs",
        "outputId": "e2f31d45-8224-48b9-8e01-6786f961c49b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 torch.Size([3, 224, 224]) drive/MyDrive/DL_Project/Val/Image_0304.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 torch.Size([3, 224, 224]) drive/MyDrive/DL_Project/Val/Image_0301.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 torch.Size([3, 224, 224]) drive/MyDrive/DL_Project/Val/Image_0302.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 torch.Size([3, 224, 224]) drive/MyDrive/DL_Project/Val/Image_0303.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "## plot test examples\n",
        "for i in range(len(covid_dataset_test)):\n",
        "    sample = covid_dataset_test[i]\n",
        "    print(i, sample['image'].shape, sample['img_name'])\n",
        "    ax = plt.subplot(1, 4, i + 1)\n",
        "    plt.tight_layout()\n",
        "    ax.set_title('Sample #{}'.format(i))\n",
        "    ax.axis('off')\n",
        "    plt.imshow(sample['image'].numpy().transpose(1,2,0))\n",
        "    if i == 3:\n",
        "        plt.show()\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV7i3Ov9REFZ"
      },
      "source": [
        "##Split given train set to train & val set"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classic"
      ],
      "metadata": {
        "id": "Zz2jv7ROmOz7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiA6ycQE1wXu",
        "outputId": "1ac41dd2-e729-4d5f-926a-43cfd8c63f36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3053\n",
            "2137 916\n"
          ]
        }
      ],
      "source": [
        "## split given train set to train & val set\n",
        "\n",
        "#dataloader = DataLoader(covid_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
        "print(len(covid_dataset_train_val))\n",
        "train_size = int(0.7 * len(covid_dataset_train_val))\n",
        "val_size = len(covid_dataset_train_val) - train_size\n",
        "print(train_size, val_size)\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(covid_dataset_train_val, [train_size, val_size])\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
        "\n",
        "## test set\n",
        "test_dataloader = DataLoader(covid_dataset_test, batch_size=8, shuffle=True, num_workers=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewm9OtFoMA2r"
      },
      "source": [
        "### Apply CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNH8GIIsLtgR"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV, cross_validate\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# generate the index of subjects for k-fold cross validation\n",
        "def generate_index(dat,k):\n",
        "    \n",
        "    Y = list(range(0,dat[-1]['subject']+1))\n",
        "    kf = KFold(n_splits=k, shuffle=True)\n",
        "\n",
        "    n = len(Y)\n",
        "    index = {'train_index':[],\n",
        "             'val_index':[]}\n",
        "\n",
        "    for train_index, val_index in kf.split(np.zeros(n), Y):\n",
        "        index['train_index'].append(train_index)\n",
        "        index['val_index'].append(val_index)\n",
        "        \n",
        "    \n",
        "    return pd.DataFrame(index['train_index']).T,pd.DataFrame(index['val_index']).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QE_lq53MEg0"
      },
      "outputs": [],
      "source": [
        "# get links form subjects to images\n",
        "df = pd.read_csv('drive/MyDrive/DL_Project/Train.csv')\n",
        "subtoimage = []\n",
        "le = []\n",
        "for sub in range(0,covid_dataset_train_val[-1]['subject']+1):\n",
        "  subtoimage.append(df[df['0'] == sub].index.tolist())\n",
        "  le.append(len(df[df['0'] == sub].index.tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrNBeIwwMIVm"
      },
      "outputs": [],
      "source": [
        "# get images' index form subjects' index\n",
        "def get_image_index(subindex,subtoimage):\n",
        "    imageindex = []\n",
        "    for sub in range(0,len(subindex)):\n",
        "        imageindex.extend(subtoimage[subindex[sub]])\n",
        "    return imageindex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzNT_ZV0M2WU"
      },
      "outputs": [],
      "source": [
        "# from typing import NewType\n",
        "def cv_train(pars, k=4, dir='drive/MyDrive/DL_Project/CV/',n_epochs=20):\n",
        "  train_index,val_index = generate_index(covid_dataset_train_val,k)\n",
        "  model_cv = []\n",
        "  valid_cvloss = []\n",
        "  valid_cvloss_trend = []\n",
        "  for split_i in range(0,k):\n",
        "    print('CV - Fold ', split_i)\n",
        "    fold_dir = dir + str(split_i) + '/'\n",
        "\n",
        "    if not os.path.isdir(fold_dir):\n",
        "      os.makedirs(fold_dir)\n",
        "      print(\"created folder : \", fold_dir)\n",
        "    else:\n",
        "      print(fold_dir, \"folder already exists.\")\n",
        "\n",
        "    model, cri, lr = pars\n",
        "    freeze_stat = True\n",
        "    model_CNN = model(pretrained=True,freeze=freeze_stat).to(device)\n",
        "    criterion = cri\n",
        "    model_CNN_grad_paramaters = filter(lambda p: p.requires_grad, model_CNN.parameters())\n",
        "    optimizer = optim.Adam(model_CNN_grad_paramaters, lr=lr)\n",
        "\n",
        "    ## split given train set to train & val set by subjects\n",
        "    train_imageindex = get_image_index(train_index.iloc[:,split_i],subtoimage)\n",
        "    val_imageindex = get_image_index(val_index.iloc[:,split_i],subtoimage)\n",
        "    train_dataset = torch.utils.data.Subset(covid_dataset_train_val,train_imageindex)\n",
        "    val_dataset = torch.utils.data.Subset(covid_dataset_train_val,val_imageindex)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
        "\n",
        "    ## training model\n",
        "    model_conv, valid_loss_min, valid_loss_trend = train_model(model_CNN, criterion, optimizer,train_dataloader,val_dataloader, dir=fold_dir,n_epochs=n_epochs)\n",
        "\n",
        "    model_cv.append(model_conv)\n",
        "    valid_cvloss.append(valid_loss_min)\n",
        "    valid_cvloss_trend.append(valid_loss_trend)\n",
        "  \n",
        "  print('----------------------Final CV loss: %.6f -----------------------' % torch.stack(valid_cvloss).cpu().data.mean() )\n",
        "  \n",
        "  return model_cv, valid_cvloss, valid_cvloss_trend"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OClBrnNnRK_t"
      },
      "source": [
        "## Import pretrained models library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIQiUJcyvJ1y",
        "outputId": "3988497d-36d0-4bba-8259-391dd8fd9c8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pretrainedmodels\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▋                          | 10 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 30 kB 15.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 40 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 51 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 58 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels) (0.11.1+cu111)\n",
            "Collecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels) (4.63.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from munch->pretrainedmodels) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pretrainedmodels) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->pretrainedmodels) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->pretrainedmodels) (1.21.5)\n",
            "Building wheels for collected packages: pretrainedmodels\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60965 sha256=8c7c1d9126c65722a8634bf59e14f1951303f5e2f16d0c308e02908a73e8bba6\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/27/e8/9543d42de2740d3544db96aefef63bda3f2c1761b3334f4873\n",
            "Successfully built pretrainedmodels\n",
            "Installing collected packages: munch, pretrainedmodels\n",
            "Successfully installed munch-2.5.0 pretrainedmodels-0.7.4\n"
          ]
        }
      ],
      "source": [
        "## use imagenet pretrained model\n",
        "## let's start with resnet34\n",
        "!pip install pretrainedmodels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pretrainedmodels.__dict__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "-GdB8pZLqNe1",
        "outputId": "1f151bef-df32-4e39-cd33-b371f3ea1c02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-ca0483ad6f6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpretrainedmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pretrainedmodels' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJTMiALSRRHC"
      },
      "source": [
        "## Use CUDA to speed up training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BT-6cVxs_iT",
        "outputId": "bef2513d-3f4b-4273-e5b1-6de6d372a013"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqPiUx1XRbIL"
      },
      "source": [
        "## Create Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DIFuG0hvZn7"
      },
      "outputs": [],
      "source": [
        "import pretrainedmodels\n",
        "#For model building\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torchvision\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class CNN1(nn.Module):\n",
        "    def __init__(self, pretrained=True,freeze=True):\n",
        "        super(CNN1, self).__init__()\n",
        "        if pretrained is True:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet34\"](pretrained=\"imagenet\")\n",
        "        else:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet34\"](pretrained=None)\n",
        "        if freeze is True:\n",
        "            for param in self.model.parameters():\n",
        "                param.requires_grad = False\n",
        "        #self.fc1 = nn.Linear(512, 256)\n",
        "        self.conv1 = nn.Conv2d(512, 128, (5,5), stride=1, padding =0)\n",
        "        self.conv2 = nn.Conv2d(128, 32, (5,5), stride=1, padding =0)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.conv3 = nn.Conv2d(32, 8, (5,5), stride=1, padding =0)\n",
        "        self.fc1 = nn.Linear(128, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        bs, _, _, _ = x.shape\n",
        "        x = self.model.features(x)\n",
        "        #x = F.adaptive_avg_pool2d(x) #.reshape(bs, -1)\n",
        "        #x = F.relu(self.fc1(x))\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv3(F.relu(x))\n",
        "        #print(x.size()) # [8, 8, 4, 4]\n",
        "        label = self.fc1(x.reshape(bs, -1))  # [8, 128]\n",
        "        return label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iwJs3cZFG0y"
      },
      "outputs": [],
      "source": [
        "class CNN2(nn.Module):\n",
        "    def __init__(self, pretrained=True,freeze=True):\n",
        "        super(CNN2, self).__init__()\n",
        "        if pretrained is True:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet18\"](pretrained=\"imagenet\")\n",
        "        else:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet18\"](pretrained=None)\n",
        "        if freeze is True:\n",
        "            for param in self.model.parameters():\n",
        "                param.requires_grad = False\n",
        "        #self.fc1 = nn.Linear(512, 256)\n",
        "        self.conv1 = nn.Conv2d(512, 128, (5,5), stride=1, padding =0)\n",
        "        self.conv2 = nn.Conv2d(128, 32, (5,5), stride=1, padding =0)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.conv3 = nn.Conv2d(32, 8, (5,5), stride=1, padding =0)\n",
        "        self.fc1 = nn.Linear(128, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        bs, _, _, _ = x.shape\n",
        "        x = self.model.features(x)\n",
        "        #x = F.adaptive_avg_pool2d(x) #.reshape(bs, -1)\n",
        "        #x = F.relu(self.fc1(x))\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv3(F.relu(x))\n",
        "        #print(x.size()) # [8, 8, 4, 4]\n",
        "        label = self.fc1(x.reshape(bs, -1))  # [8, 128]\n",
        "        return label"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reference: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8081579/\n",
        "def conv_block(in_channels,out_channels):\n",
        "    blk = nn.Sequential(\n",
        "        nn.Conv2d(in_channels,out_channels,(1,1)),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(),\n",
        "        nn.AdaptiveAvgPool2d((1,1))\n",
        "    )\n",
        "    return blk\n",
        "\n",
        "class CNN22(nn.Module):\n",
        "    def __init__(self, pretrained=True, freeze=True):\n",
        "        super(CNN22, self).__init__()\n",
        "        if pretrained is True:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet18\"](pretrained=\"imagenet\")\n",
        "        else:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet18\"](pretrained=None)\n",
        "        if freeze is True:\n",
        "            for param in self.model.parameters():\n",
        "                param.requires_grad = False\n",
        "        self.w = conv_block(3,5)\n",
        "        self.convblk1 = conv_block(64,32)\n",
        "        # self.part2 = self.model.features[4]\n",
        "        self.convblk2 = conv_block(64,32) \n",
        "        # self.part3 = self.model.features[5]\n",
        "        self.convblk3 = conv_block(128,32) \n",
        "        # self.part4 = self.model.features[6]\n",
        "        self.convblk4 = conv_block(256,32)\n",
        "        # self.part5 = self.model.features[7:] \n",
        "        self.convblk5 = conv_block(512,32) \n",
        "        self.lc1 = nn.Linear(32,1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        bs, _, _, _ = x.shape\n",
        "        w = self.w(x)\n",
        "        w = w.reshape(bs, -1)\n",
        "        x = self.model.relu(self.model.bn1(self.model.conv1(x)))\n",
        "        x1 = self.convblk1(x).reshape(bs,-1)\n",
        "        x = self.model.layer1(x)\n",
        "        x2 = self.convblk2(x).reshape(bs,-1)\n",
        "        x = self.model.layer2(x)\n",
        "        x3 = self.convblk3(x).reshape(bs,-1)\n",
        "        x = self.model.layer3(x)\n",
        "        x4 = self.convblk4(x).reshape(bs,-1)\n",
        "        x = self.model.layer4(x)\n",
        "        x5 = self.convblk5(x).reshape(bs,-1)\n",
        "        x = w[:,0]*x1.t()+w[:,1]*x2.t()+w[:,2]*x3.t()+w[:,3]*x4.t()+w[:,4]*x5.t()\n",
        "    #    x = nd.concat(w[0]*x, w[1]*x1, w[2]*x2, w[3]*x3, w[4]*x4, dim=1)\n",
        "        x = x.t()\n",
        "        x = x.reshape(bs,-1)\n",
        "        label = self.lc1(x)\n",
        "        return label"
      ],
      "metadata": {
        "id": "NCFvUpSrahGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reference: https://github.com/mr7495/COVID-CT-Code/blob/master/COVID_Train%26Validation.ipynb\n",
        "class CNN3(nn.Module):\n",
        "    def __init__(self, pretrained=True,freeze=True):\n",
        "        super(CNN3, self).__init__()\n",
        "        if pretrained is True:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet50\"](pretrained=\"imagenet\")\n",
        "        else:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet50\"](pretrained=None)\n",
        "        if freeze is True:\n",
        "            for param in self.model.parameters():\n",
        "                param.requires_grad = False\n",
        "        #self.fc1 = nn.Linear(512, 256)\n",
        "        self.conv1 = nn.Conv2d(2048, 512, (2,2), stride=1, padding =0)\n",
        "        self.conv2 = nn.Conv2d(512, 32, (2,2), stride=1, padding =0)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.conv3 = nn.Conv2d(32, 8, (2,2), stride=1, padding =0)\n",
        "        self.fc1 = nn.Linear(128, 16)\n",
        "        self.fc2 = nn.Linear(16, 8)\n",
        "        self.fc3 = nn.Linear(8, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        bs, _, _, _ = x.shape\n",
        "        x = self.model.features(x)\n",
        "        #x = F.adaptive_avg_pool2d(x) #.reshape(bs, -1)\n",
        "        #x = F.relu(self.fc1(x))\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv3(F.relu(x))\n",
        "        # print(x.size()) # [8, 8, 4, 4]\n",
        "        label = self.fc1(x.reshape(bs, -1))  # [8, 128]\n",
        "        label = self.fc2(label)\n",
        "        label = self.fc3(label)\n",
        "        return label"
      ],
      "metadata": {
        "id": "ZRerv97G3wWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reference: https://github.com/mr7495/COVID-CT-Code/blob/master/COVID_Train%26Validation.ipynb\n",
        "class CNN31(nn.Module):\n",
        "    def __init__(self, pretrained=True,freeze=True):\n",
        "        super(CNN31, self).__init__()\n",
        "        if pretrained is True:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet50\"](pretrained=\"imagenet\")\n",
        "        else:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet50\"](pretrained=None)\n",
        "        if freeze is True:\n",
        "            for param in self.model.parameters():\n",
        "                param.requires_grad = False\n",
        "        #self.fc1 = nn.Linear(512, 256)\n",
        "        self.conv1 = nn.Conv2d(2048, 512, (2,2), stride=1, padding =0)\n",
        "        self.conv2 = nn.Conv2d(512, 32, (2,2), stride=1, padding =0)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.conv3 = nn.Conv2d(32, 8, (2,2), stride=1, padding =0)\n",
        "        self.fc1 = nn.Linear(128, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        bs, _, _, _ = x.shape\n",
        "        x = self.model.features(x)\n",
        "        #x = F.adaptive_avg_pool2d(x) #.reshape(bs, -1)\n",
        "        #x = F.relu(self.fc1(x))\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv3(F.relu(x))\n",
        "        # print(x.size()) # [8, 8, 4, 4]\n",
        "        label = self.fc1(x.reshape(bs, -1))  # [8, 128]\n",
        "        return label"
      ],
      "metadata": {
        "id": "kc7aTZwrf1Fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reference: https://github.com/mr7495/COVID-CT-Code/blob/master/COVID_Train%26Validation.ipynb\n",
        "class CNN32(nn.Module):\n",
        "    def __init__(self, pretrained=True,freeze=True):\n",
        "        super(CNN32, self).__init__()\n",
        "        if pretrained is True:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet50\"](pretrained=\"imagenet\")\n",
        "        else:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet50\"](pretrained=None)\n",
        "        if freeze is True:\n",
        "            for param in self.model.parameters():\n",
        "                param.requires_grad = False\n",
        "        #self.fc1 = nn.Linear(512, 256)\n",
        "        self.conv1 = nn.Conv2d(2048, 512, (3,3), stride=1, padding =0)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.conv2 = nn.Conv2d(512, 8, (3,3), stride=1, padding =0)\n",
        "        self.fc1 = nn.Linear(72, 16)\n",
        "        self.fc2 = nn.Linear(16, 8)\n",
        "        self.fc3 = nn.Linear(8, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        bs, _, _, _ = x.shape\n",
        "        x = self.model.features(x)\n",
        "        #x = F.adaptive_avg_pool2d(x) #.reshape(bs, -1)\n",
        "        #x = F.relu(self.fc1(x))\n",
        "        x = self.conv1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv2(F.relu(x))\n",
        "        # print(x.size()) # [8, 8, 4, 4]\n",
        "        label = self.fc1(x.reshape(bs, -1))  # [8, 128]\n",
        "        label = self.fc2(label)\n",
        "        label = self.fc3(label)\n",
        "        return label"
      ],
      "metadata": {
        "id": "O_ZL-ODhfw4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules import padding\n",
        "# reference: https://github.com/mr7495/COVID-CT-Code/blob/master/COVID_Train%26Validation.ipynb\n",
        "class CNN33(nn.Module):\n",
        "    def __init__(self, pretrained=True,freeze=True):\n",
        "        super(CNN33, self).__init__()\n",
        "        if pretrained is True:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet50\"](pretrained=\"imagenet\")\n",
        "        else:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet50\"](pretrained=None)\n",
        "        if freeze is True:\n",
        "            for param in self.model.parameters():\n",
        "                param.requires_grad = False\n",
        "        #self.fc1 = nn.Linear(512, 256)\n",
        "        self.conv11 = nn.Conv2d(2048,256,(1,1),padding='same')\n",
        "        self.upsampled1 = nn.Upsample(scale_factor=2)\n",
        "        self.conv12 = nn.Conv2d(256,256,(3,3),padding='same')\n",
        "        self.conv21 = nn.Conv2d(1024,256,(1,1),padding='same')\n",
        "        self.upsampled2 = nn.Upsample(scale_factor=2)\n",
        "        self.conv22 = nn.Conv2d(256,256,(3,3))\n",
        "        self.conv31 = nn.Conv2d(512,256,(1,1),padding='same')\n",
        "        self.conv32 = nn.Conv2d(256,256,(3,3))\n",
        "        self.conv4 = nn.Conv2d(2048,256,(3,3),stride=2) #,padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv5 = nn.Conv2d(256,256,(3,3),stride=2) #,padding='same')\n",
        "        \n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(545792,1)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(79872,1)\n",
        "        self.dropout3 = nn.Dropout(0.5)\n",
        "        self.fc3 = nn.Linear(12544,1)\n",
        "        self.dropout4 = nn.Dropout(0.5)\n",
        "        self.fc4 = nn.Linear(2304,1)\n",
        "        self.dropout5 = nn.Dropout(0.5)\n",
        "        self.fc5 = nn.Linear(256,1)\n",
        "        self.fc6 = nn.Linear(5,1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        bs, _, _, _ = x.shape\n",
        "        x = self.model.maxpool(self.model.relu(self.model.bn1(self.model.conv1(x))))\n",
        "        x = self.model.layer1(x)\n",
        "        c3 = self.model.layer2(x)\n",
        "        c4 = self.model.layer3(c3)\n",
        "        c5 = self.model.layer4(c4)\n",
        "\n",
        "        ## Feature Pyramid Network (FPN)\n",
        "        p5 = self.conv11(c5)\n",
        "        p5_up = self.upsampled1(p5)\n",
        "        p5 = self.conv12(p5)\n",
        "\n",
        "        p4 = self.conv21(c4)\n",
        "        p4 = torch.concat([p5_up,p4],dim=3)\n",
        "        p4_up = self.upsampled2(p4)\n",
        "        p4 = self.conv22(p4)\n",
        "\n",
        "        p3 = self.conv31(c3)\n",
        "        p3 = torch.concat([p4_up,p3],dim=3)\n",
        "        p3 = self.conv32(p3)\n",
        "\n",
        "        p6 = self.conv4(c5)\n",
        "        p7 = self.relu(p6)\n",
        "        p7 = self.conv5(p7)\n",
        "\n",
        "        ## feature generation\n",
        "        f1 = p3.reshape(bs,-1)\n",
        "        dp1 = self.dropout1(f1)\n",
        "        preds1 = F.relu(self.fc1(dp1))\n",
        "        f2 = p4.reshape(bs,-1)\n",
        "        dp2 = self.dropout2(f2)\n",
        "        preds2 = F.relu(self.fc2(dp2))\n",
        "        f3 = p5.reshape(bs,-1)\n",
        "        dp3 = self.dropout3(f3)\n",
        "        preds3 = F.relu(self.fc3(dp3))\n",
        "        f4 = p6.reshape(bs,-1)\n",
        "        dp4 = self.dropout4(f4)\n",
        "        preds4 = F.relu(self.fc4(dp4))\n",
        "        f5 = p7.reshape(bs,-1)\n",
        "        dp5 = self.dropout5(f5)\n",
        "        preds5 = F.relu(self.fc5(dp5))\n",
        "        concat = torch.concat([preds1,preds2,preds3,preds4,preds5],dim=1)\n",
        "        label = self.fc6(concat)\n",
        "\n",
        "        return label"
      ],
      "metadata": {
        "id": "E5FLewHmftiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reference: https://www.researchsquare.com/article/rs-32957/v1\n",
        "class CNN4(nn.Module):\n",
        "    def __init__(self, pretrained=True, freeze=True):\n",
        "        super(CNN4, self).__init__()\n",
        "        if pretrained is True:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet34\"](pretrained=\"imagenet\")\n",
        "        else:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet34\"](pretrained=None)\n",
        "        if freeze is True:\n",
        "            for param in self.model.parameters():\n",
        "                param.requires_grad = False\n",
        "        self.conv1 = nn.Conv2d(512, 128, (2,2), stride=1, padding =0)\n",
        "        self.conv2 = nn.Conv2d(128, 32, (2,2), stride=1, padding =0)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.conv3 = nn.Conv2d(32, 8, (2,2), stride=1, padding =0)\n",
        "        self.fc1 = nn.Linear(128, 16)\n",
        "        self.fc2 = nn.Linear(16, 8)\n",
        "        self.fc3 = nn.Linear(20, 1)\n",
        "\n",
        "        self.conv4 = nn.Conv1d(1,1,kernel_size=5)\n",
        "        self.bn = nn.BatchNorm1d(1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        bs, _, _, _ = x.shape\n",
        "        x = self.model.features(x)\n",
        "        #x = F.adaptive_avg_pool2d(x) #.reshape(bs, -1)\n",
        "        #x = F.relu(self.fc1(x))\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv3(F.relu(x))\n",
        "        x = F.adaptive_avg_pool2d(x, x.shape[3])\n",
        "        # print(x.reshape(bs,-1).size())\n",
        "\n",
        "        l = self.fc1(x.reshape(bs, -1))\n",
        "        c = self.conv4(l.reshape(bs,1,-1))\n",
        "        c = self.bn(c)\n",
        "        c = F.relu(c)\n",
        "        l = self.fc2(l)\n",
        "        \n",
        "        # print(c.size()) # [8, 8, 4, 4]\n",
        "        # print(l.size())\n",
        "\n",
        "        x = torch.cat((c.reshape(bs,-1), l),1)\n",
        "        label = self.fc3(x)\n",
        "\n",
        "        return label"
      ],
      "metadata": {
        "id": "aqjx6SX1rG2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reference: https://towardsdatascience.com/using-pretrained-deep-convolutional-neural-networks-for-binary-classification-of-covid-19-ct-scans-3a7f7ea8b543\n",
        "class CNN5(nn.Module):\n",
        "    def __init__(self, pretrained=True, freeze=True):\n",
        "        super(CNN5, self).__init__()\n",
        "        if pretrained is True:\n",
        "            self.model = pretrainedmodels.__dict__[\"vgg16\"](pretrained=\"imagenet\")\n",
        "        else:\n",
        "            self.model = pretrainedmodels.__dict__[\"vgg16\"](pretrained=None)\n",
        "        if freeze is True:\n",
        "            for param in self.model.parameters():\n",
        "                param.requires_grad = False\n",
        "        self.fc1 = nn.Linear(25088, 512)\n",
        "        self.activation1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout()\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.activation2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout()\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.activation3 = nn.ReLU()\n",
        "        self.dropout3 = nn.Dropout()\n",
        "        self.fc4 = nn.Linear(128, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        bs, _, _, _ = x.shape\n",
        "        # print(x.size(0))\n",
        "        x = self.model._features(x)\n",
        "        x = self.fc1(x.reshape(bs,-1))\n",
        "        x = self.activation1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.activation2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.activation3(x)\n",
        "        x = self.dropout3(x)\n",
        "        label = self.fc4(x)\n",
        "        return label"
      ],
      "metadata": {
        "id": "82Lv66KO3Xte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reference: https://towardsdatascience.com/using-pretrained-deep-convolutional-neural-networks-for-binary-classification-of-covid-19-ct-scans-3a7f7ea8b543\n",
        "class CNN6(nn.Module):\n",
        "    def __init__(self, pretrained=True,freeze=True):\n",
        "        super(CNN6, self).__init__()\n",
        "        if pretrained is True:\n",
        "            self.model = pretrainedmodels.__dict__[\"vgg19\"](pretrained=\"imagenet\")\n",
        "        else:\n",
        "            self.model = pretrainedmodels.__dict__[\"vgg19\"](pretrained=None)\n",
        "        if freeze is True:\n",
        "            for param in self.model.parameters():\n",
        "                param.requires_grad = False\n",
        "        self.fc1 = nn.Linear(25088, 512)\n",
        "        self.activation1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout()\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.activation2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout()\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.activation3 = nn.ReLU()\n",
        "        self.dropout3 = nn.Dropout()\n",
        "        self.fc4 = nn.Linear(128, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        bs, _, _, _ = x.shape\n",
        "        x = self.model._features(x)\n",
        "        x = self.fc1(x.reshape(bs,-1))\n",
        "        x = self.activation1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.activation2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.activation3(x)\n",
        "        x = self.dropout3(x)\n",
        "        label = self.fc4(x)\n",
        "        return label"
      ],
      "metadata": {
        "id": "VEl_6IvEteMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN7(nn.Module):\n",
        "    def __init__(self, pretrained=True,freeze=True):\n",
        "        super(CNN7, self).__init__()\n",
        "        if pretrained is True:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet101\"](pretrained=\"imagenet\")\n",
        "        else:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet101\"](pretrained=None)\n",
        "        if freeze is True:\n",
        "            for param in self.model.parameters():\n",
        "                param.requires_grad = False\n",
        "        #self.fc1 = nn.Linear(512, 256)\n",
        "        self.conv1 = nn.Conv2d(2048, 512, (2,2), stride=1, padding =0)\n",
        "        self.conv2 = nn.Conv2d(512, 32, (2,2), stride=1, padding =0)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.conv3 = nn.Conv2d(32, 8, (2,2), stride=1, padding =0)\n",
        "        self.fc1 = nn.Linear(128, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        bs, _, _, _ = x.shape\n",
        "        x = self.model.features(x)\n",
        "        #x = F.adaptive_avg_pool2d(x) #.reshape(bs, -1)\n",
        "        #x = F.relu(self.fc1(x))\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv3(F.relu(x))\n",
        "        label = self.fc1(x.reshape(bs, -1))  # [8, 128]\n",
        "        return label"
      ],
      "metadata": {
        "id": "DKSLduB333Wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iV9C3yfx5BmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "model_CNN = CNN6(pretrained=True,freeze=True).to(device)\n",
        "model_CNN\n",
        "summary(model_CNN, input_size=(3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jufJhWZMmy4d",
        "outputId": "4205cd4c-7fa6-4237-a21c-7ec5335d4856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
            "              ReLU-2         [-1, 64, 224, 224]               0\n",
            "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
            "              ReLU-4         [-1, 64, 224, 224]               0\n",
            "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
            "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
            "              ReLU-7        [-1, 128, 112, 112]               0\n",
            "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
            "              ReLU-9        [-1, 128, 112, 112]               0\n",
            "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
            "             ReLU-12          [-1, 256, 56, 56]               0\n",
            "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-14          [-1, 256, 56, 56]               0\n",
            "           Conv2d-15          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-16          [-1, 256, 56, 56]               0\n",
            "           Conv2d-17          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-18          [-1, 256, 56, 56]               0\n",
            "        MaxPool2d-19          [-1, 256, 28, 28]               0\n",
            "           Conv2d-20          [-1, 512, 28, 28]       1,180,160\n",
            "             ReLU-21          [-1, 512, 28, 28]               0\n",
            "           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-23          [-1, 512, 28, 28]               0\n",
            "           Conv2d-24          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-25          [-1, 512, 28, 28]               0\n",
            "           Conv2d-26          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-27          [-1, 512, 28, 28]               0\n",
            "        MaxPool2d-28          [-1, 512, 14, 14]               0\n",
            "           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-30          [-1, 512, 14, 14]               0\n",
            "           Conv2d-31          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-32          [-1, 512, 14, 14]               0\n",
            "           Conv2d-33          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-34          [-1, 512, 14, 14]               0\n",
            "           Conv2d-35          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-36          [-1, 512, 14, 14]               0\n",
            "        MaxPool2d-37            [-1, 512, 7, 7]               0\n",
            "           Linear-38                  [-1, 512]      12,845,568\n",
            "             ReLU-39                  [-1, 512]               0\n",
            "          Dropout-40                  [-1, 512]               0\n",
            "           Linear-41                  [-1, 256]         131,328\n",
            "             ReLU-42                  [-1, 256]               0\n",
            "          Dropout-43                  [-1, 256]               0\n",
            "           Linear-44                  [-1, 128]          32,896\n",
            "             ReLU-45                  [-1, 128]               0\n",
            "          Dropout-46                  [-1, 128]               0\n",
            "           Linear-47                    [-1, 1]             129\n",
            "================================================================\n",
            "Total params: 33,034,305\n",
            "Trainable params: 13,009,921\n",
            "Non-trainable params: 20,024,384\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 238.32\n",
            "Params size (MB): 126.02\n",
            "Estimated Total Size (MB): 364.91\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufc5DuRU_8VO"
      },
      "outputs": [],
      "source": [
        "# #Setting model and moving to device\n",
        "# model_CNN = CNN1(True).to(device)\n",
        "\n",
        "# criterion = nn.L1Loss()\n",
        "# #optimizer = optim.SGD(model_CNN.parameters(), lr=0.001, momentum=0.9)\n",
        "# optimizer = optim.Adam(model_CNN.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O42uOYtUAK2D"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, train_dataloader, val_dataloader, dir='drive/MyDrive/DL_Project/', n_epochs=20):\n",
        "    \"\"\"returns trained model\"\"\"\n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf\n",
        "    model_best = model\n",
        "    valid_loss_trend = []\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        # train the model #\n",
        "        model.train()\n",
        "        for batch_idx, sample_batched in enumerate(train_dataloader):\n",
        "            # importing data and moving to GPU\n",
        "            image, label = sample_batched['image'].to(device), sample_batched['percentage'].to(device)\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            output=model(image).reshape(-1)\n",
        "            # calculate loss\n",
        "            loss = criterion((output).type(torch.FloatTensor).to(device), label.type(torch.FloatTensor).to(device))\n",
        "            # back prop\n",
        "            loss.backward()\n",
        "            # grad\n",
        "            optimizer.step()\n",
        "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "            if batch_idx % 100 == 0:\n",
        "                print('Epoch %d, Batch %d loss: %.6f' %\n",
        "                  (epoch, batch_idx + 1, train_loss))\n",
        "        # validate the model #\n",
        "        model.eval()\n",
        "        for batch_idx, sample_batched in enumerate(val_dataloader):\n",
        "            image, label = sample_batched['image'].to(device), sample_batched['percentage'].to(device)  \n",
        "            output = model(image).reshape(-1)\n",
        "            # calculate loss\n",
        "            loss=criterion((output).type(torch.FloatTensor).to(device), label.type(torch.FloatTensor).to(device))\n",
        "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
        "        \n",
        "        # print training/validation statistics \n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "            epoch, train_loss, valid_loss))\n",
        "        \n",
        "        valid_loss_trend.append(valid_loss)\n",
        "        \n",
        "        ## TODO: save the model if validation loss has decreased\n",
        "        if valid_loss < valid_loss_min:\n",
        "            model_best = model\n",
        "            model_dir = dir+'model.pth'\n",
        "            torch.save(model.state_dict(), model_dir)\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "            valid_loss_min,\n",
        "            valid_loss))\n",
        "            valid_loss_min = valid_loss\n",
        "    # return trained model\n",
        "    return model_best, valid_loss_min, valid_loss_trend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRcDzZQnAScu"
      },
      "outputs": [],
      "source": [
        "# model_conv=train_model(model_CNN, criterion, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-TDjNZblDCd"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJePsT4QUDdh"
      },
      "source": [
        "## Save result on Actual Test Data to csv File"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Classic"
      ],
      "metadata": {
        "id": "xjupKih5mzlq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jnfu9xdYX7YC"
      },
      "outputs": [],
      "source": [
        "def save_test(model,dir):\n",
        "  test_dataloader = DataLoader(covid_dataset_test, batch_size=8, shuffle=True, num_workers=0)\n",
        "  df = pd.DataFrame(columns=['image_name','output'])\n",
        "  for batch_idx, sample_batched in enumerate(test_dataloader):\n",
        "      image= sample_batched['image'].to(device)\n",
        "      img_name= sample_batched['img_name']\n",
        "      output = model(image).type(torch.LongTensor).reshape(-1)\n",
        "      img_name = np.array(img_name).reshape(output.shape[0],1)\n",
        "      o = output.cpu().data.numpy().reshape(output.shape[0],1)\n",
        "      a = np.concatenate((img_name,o),axis=1)\n",
        "      df = df.append(pd.DataFrame(a, columns=df.columns), ignore_index=True)\n",
        "\n",
        "  #Extracting image name from the image path\n",
        "  df['image_name']=df['image_name'].str.split(\"/\").str[-1]\n",
        "  df = df.sort_values('image_name',ignore_index=True)\n",
        "\n",
        "  file_dir = dir+'predictions.zip'\n",
        "  print(file_dir)\n",
        "  comp_opt = dict(method='zip', archive_name='predictions.csv')\n",
        "  df.to_csv(file_dir, index=False, header=False,compression=comp_opt)\n",
        "  df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CV"
      ],
      "metadata": {
        "id": "TjV8jsWcm2Y3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4liD6xDr_m3"
      },
      "outputs": [],
      "source": [
        "def save_test_cv(model,dir):\n",
        "  test_dataloader = DataLoader(covid_dataset_test, batch_size=8, shuffle=True, num_workers=0)\n",
        "  all_df = pd.DataFrame(columns=[])\n",
        "  for fold_idx in range(len(model)):\n",
        "    model_tmp = model[fold_idx]\n",
        "    col_name = 'fold_'+str(fold_idx)\n",
        "    df = pd.DataFrame(columns=['image_name',col_name])\n",
        "    for batch_idx, sample_batched in enumerate(test_dataloader):\n",
        "        image= sample_batched['image'].to(device)\n",
        "        img_name= sample_batched['img_name']\n",
        "        output = model_tmp(image).type(torch.LongTensor).reshape(-1)\n",
        "        img_name = np.array(img_name).reshape(output.shape[0],1)\n",
        "        o = output.cpu().data.numpy().reshape(output.shape[0],1)\n",
        "        a = np.concatenate((img_name,o),axis=1)\n",
        "        df = df.append(pd.DataFrame(a, columns=df.columns), ignore_index=True)\n",
        "    #Extracting image name from the image path\n",
        "    df['image_name']=df['image_name'].str.split(\"/\").str[-1]\n",
        "    df = df.sort_values('image_name',ignore_index=True)\n",
        "    all_df[col_name] = df[col_name].astype(float)\n",
        "  all_df['output'] = all_df.mean(axis=1)\n",
        "  all_df['image_name'] = df['image_name']\n",
        "  res = all_df[['image_name','output']]\n",
        "\n",
        "  file_dir = dir+'predictions.zip'\n",
        "  print(file_dir)\n",
        "  comp_opt = dict(method='zip', archive_name='predictions.csv')\n",
        "  res.to_csv(file_dir, index=False, header=False,compression=comp_opt)\n",
        "  all_df.to_csv(dir+'cv_predictions.csv', index=False, header=False)\n",
        "  all_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIXtwdZ5NHsi"
      },
      "source": [
        "## Model Training and Comparing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVB8B6aPNSQt"
      },
      "outputs": [],
      "source": [
        "# #Setting model and moving to device\n",
        "# model_CNN = CNN1(True).to(device)\n",
        "\n",
        "# criterion = nn.L1Loss()\n",
        "# #optimizer = optim.SGD(model_CNN.parameters(), lr=0.001, momentum=0.9)\n",
        "# optimizer = optim.Adam(model_CNN.parameters(), lr=0.001)\n",
        "model_set = [CNN31,CNN32,CNN33] # [CNN4,CNN6,CNN7] # CNN1, CNN2, CNN4, CNN22\n",
        "cri_set = [nn.SmoothL1Loss()] #[nn.L1Loss(),\n",
        "optim_lr = [0.0005] # 0.0001, 0.0005, 0.001, 0.005"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vLG5ZQBOQTb"
      },
      "source": [
        "#### Classic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPYlBVTzOD94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "888981ea-fb7d-404a-c553-70f8f5322bdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive/MyDrive/DL_Project/classic_2/0/ folder already exists.\n",
            "0 <class '__main__.CNN1'> SmoothL1Loss() 0.0005 drive/MyDrive/DL_Project/classic_2/0/\n",
            "Epoch 1, Batch 1 loss: 35.551823\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-c750c23925e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mmodel_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss_trend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_CNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# ## load best val_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-527b5ba89c00>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, train_dataloader, val_dataloader, dir, n_epochs)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# train the model #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_batched\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0;31m# importing data and moving to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_batched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_batched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'percentage'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-bcfbf48c0699>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGRA2BGR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m                                (plugin, kind))\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skimage/io/_plugins/imageio_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;31m# Get reader and read first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[0;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;31m# Create request object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# Get format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, uri, mode, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m# Parse what was given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;31m# Set extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename_zip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename_zip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mEXAMPLE_IMAGES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m                 raise IOError(\n\u001b[1;32m    249\u001b[0m                     \u001b[0;34m\"No such file: %r. This file looks like one of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/genericpath.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;34m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from itertools import product, chain\n",
        "import os\n",
        "\n",
        "comp_model = []\n",
        "comp_valid_loss = []\n",
        "comp_valid_trend = []\n",
        "log = pd.DataFrame(columns=['num','model','criterion','adam_lr','directory'])\n",
        "root = 'drive/MyDrive/DL_Project/classic_2/'\n",
        "\n",
        "for n, (model,cri,lr) in enumerate(product(model_set,cri_set, optim_lr)):\n",
        "    model_CNN = model(True).to(device)\n",
        "    criterion = cri\n",
        "    optimizer = optim.Adam(model_CNN.parameters(), lr=lr)\n",
        "\n",
        "    dir = root+str(n)+'/'\n",
        "    if not os.path.isdir(dir):\n",
        "      os.makedirs(dir)\n",
        "      print(\"created folder : \", dir)\n",
        "    else:\n",
        "      print(dir, \"folder already exists.\")\n",
        "\n",
        "    print(n,model,cri,lr,dir)\n",
        "\n",
        "    model_best, valid_loss_min, valid_loss_trend = train_model(model_CNN, criterion, optimizer, train_dataloader, val_dataloader, dir, n_epochs=20)\n",
        "\n",
        "    # ## load best val_model\n",
        "    # model_best = model_CNN\n",
        "    # model_best.load_state_dict(torch.load(dir+'model.pt'))\n",
        "    # model_best.eval()\n",
        "\n",
        "    # save test result\n",
        "    save_test(model_best,dir)\n",
        "    \n",
        "    # value_val_loss = valid_loss_min.cpu().data()\n",
        "    row = pd.Series([n,model,cri,lr,dir],index=log.columns)\n",
        "    log = log.append(row,ignore_index=True)\n",
        "\n",
        "    # comp_idx = comp_idx.append(n)\n",
        "    # comp_idx_model = comp_idx_model.append(model)\n",
        "    # comp_cri = comp_cri.append(cri)\n",
        "    # comp_optim = comp_optim.append(optim)\n",
        "\n",
        "    comp_model.append(model_best)\n",
        "    comp_valid_loss.append(valid_loss_min)\n",
        "    comp_valid_trend.append(valid_loss_trend)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1wVaYkKrybp"
      },
      "outputs": [],
      "source": [
        "log['val_loss']=torch.stack(comp_valid_loss).cpu().tolist()\n",
        "\n",
        "log_path = root+'log.csv'\n",
        "log.to_csv(root+'log.csv')\n",
        "log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La68oRanojT1"
      },
      "source": [
        "#### CV training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DH_anixCoewB",
        "outputId": "807d524b-0b1e-47b2-9da1-8a47aea15f6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created folder :  drive/MyDrive/DL_Project/cv/CNN3/0/\n",
            "0 (<class '__main__.CNN31'>, SmoothL1Loss(), 0.0005) drive/MyDrive/DL_Project/cv/CNN3/0/\n",
            "CV - Fold  0\n",
            "created folder :  drive/MyDrive/DL_Project/cv/CNN3/0/0/\n",
            "Epoch 1, Batch 1 loss: 23.021463\n",
            "Epoch 1, Batch 101 loss: 11.395896\n",
            "Epoch 1, Batch 201 loss: 11.289553\n",
            "Epoch: 1 \tTraining Loss: 10.837865 \tValidation Loss: 12.559104\n",
            "Validation loss decreased (inf --> 12.559104).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 12.116649\n",
            "Epoch 2, Batch 101 loss: 8.430355\n",
            "Epoch 2, Batch 201 loss: 8.427979\n",
            "Epoch: 2 \tTraining Loss: 8.214499 \tValidation Loss: 11.652262\n",
            "Validation loss decreased (12.559104 --> 11.652262).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 4.794877\n",
            "Epoch 3, Batch 101 loss: 7.844219\n",
            "Epoch 3, Batch 201 loss: 7.252107\n",
            "Epoch: 3 \tTraining Loss: 7.345779 \tValidation Loss: 13.173133\n",
            "Epoch 4, Batch 1 loss: 8.440363\n",
            "Epoch 4, Batch 101 loss: 7.222564\n",
            "Epoch 4, Batch 201 loss: 7.120494\n",
            "Epoch: 4 \tTraining Loss: 7.116403 \tValidation Loss: 11.212495\n",
            "Validation loss decreased (11.652262 --> 11.212495).  Saving model ...\n",
            "Epoch 5, Batch 1 loss: 9.214885\n",
            "Epoch 5, Batch 101 loss: 6.910826\n",
            "Epoch 5, Batch 201 loss: 6.559707\n",
            "Epoch: 5 \tTraining Loss: 6.734387 \tValidation Loss: 11.526388\n",
            "Epoch 6, Batch 1 loss: 3.078469\n",
            "Epoch 6, Batch 101 loss: 6.118374\n",
            "Epoch 6, Batch 201 loss: 6.270343\n",
            "Epoch: 6 \tTraining Loss: 6.159104 \tValidation Loss: 11.082469\n",
            "Validation loss decreased (11.212495 --> 11.082469).  Saving model ...\n",
            "Epoch 7, Batch 1 loss: 6.498119\n",
            "Epoch 7, Batch 101 loss: 5.697463\n",
            "Epoch 7, Batch 201 loss: 6.421117\n",
            "Epoch: 7 \tTraining Loss: 6.342129 \tValidation Loss: 10.900729\n",
            "Validation loss decreased (11.082469 --> 10.900729).  Saving model ...\n",
            "Epoch 8, Batch 1 loss: 4.010052\n",
            "Epoch 8, Batch 101 loss: 6.455201\n",
            "Epoch 8, Batch 201 loss: 6.584270\n",
            "Epoch: 8 \tTraining Loss: 6.353785 \tValidation Loss: 11.163713\n",
            "Epoch 9, Batch 1 loss: 5.042896\n",
            "Epoch 9, Batch 101 loss: 5.737516\n",
            "Epoch 9, Batch 201 loss: 5.958294\n",
            "Epoch: 9 \tTraining Loss: 6.038521 \tValidation Loss: 11.834636\n",
            "Epoch 10, Batch 1 loss: 1.346323\n",
            "Epoch 10, Batch 101 loss: 5.958664\n",
            "Epoch 10, Batch 201 loss: 5.977580\n",
            "Epoch: 10 \tTraining Loss: 5.939421 \tValidation Loss: 11.291073\n",
            "Epoch 11, Batch 1 loss: 2.398588\n",
            "Epoch 11, Batch 101 loss: 6.049481\n",
            "Epoch 11, Batch 201 loss: 6.195661\n",
            "Epoch: 11 \tTraining Loss: 6.024022 \tValidation Loss: 11.341060\n",
            "Epoch 12, Batch 1 loss: 10.056677\n",
            "Epoch 12, Batch 101 loss: 5.429729\n",
            "Epoch 12, Batch 201 loss: 5.684938\n",
            "Epoch: 12 \tTraining Loss: 5.829736 \tValidation Loss: 12.330690\n",
            "Epoch 13, Batch 1 loss: 6.462751\n",
            "Epoch 13, Batch 101 loss: 5.567070\n",
            "Epoch 13, Batch 201 loss: 5.687330\n",
            "Epoch: 13 \tTraining Loss: 5.722204 \tValidation Loss: 10.999360\n",
            "Epoch 14, Batch 1 loss: 7.204664\n",
            "Epoch 14, Batch 101 loss: 5.892213\n",
            "Epoch 14, Batch 201 loss: 6.080994\n",
            "Epoch: 14 \tTraining Loss: 5.828829 \tValidation Loss: 11.771840\n",
            "Epoch 15, Batch 1 loss: 6.037210\n",
            "Epoch 15, Batch 101 loss: 5.652474\n",
            "Epoch 15, Batch 201 loss: 5.554718\n",
            "Epoch: 15 \tTraining Loss: 5.693390 \tValidation Loss: 10.247972\n",
            "Validation loss decreased (10.900729 --> 10.247972).  Saving model ...\n",
            "Epoch 16, Batch 1 loss: 9.650362\n",
            "Epoch 16, Batch 101 loss: 5.525734\n",
            "Epoch 16, Batch 201 loss: 5.585732\n",
            "Epoch: 16 \tTraining Loss: 5.698458 \tValidation Loss: 10.490088\n",
            "Epoch 17, Batch 1 loss: 4.478968\n",
            "Epoch 17, Batch 101 loss: 5.394399\n",
            "Epoch 17, Batch 201 loss: 5.132919\n",
            "Epoch: 17 \tTraining Loss: 5.393811 \tValidation Loss: 11.620648\n",
            "Epoch 18, Batch 1 loss: 7.104666\n",
            "Epoch 18, Batch 101 loss: 5.811766\n",
            "Epoch 18, Batch 201 loss: 5.619948\n",
            "Epoch: 18 \tTraining Loss: 5.698222 \tValidation Loss: 10.259485\n",
            "Epoch 19, Batch 1 loss: 4.570249\n",
            "Epoch 19, Batch 101 loss: 5.613151\n",
            "Epoch 19, Batch 201 loss: 5.676208\n",
            "Epoch: 19 \tTraining Loss: 5.688482 \tValidation Loss: 10.799438\n",
            "Epoch 20, Batch 1 loss: 2.848578\n",
            "Epoch 20, Batch 101 loss: 5.079849\n",
            "Epoch 20, Batch 201 loss: 5.288157\n",
            "Epoch: 20 \tTraining Loss: 5.336850 \tValidation Loss: 10.398248\n",
            "CV - Fold  1\n",
            "created folder :  drive/MyDrive/DL_Project/cv/CNN3/0/1/\n",
            "Epoch 1, Batch 1 loss: 20.777349\n",
            "Epoch 1, Batch 101 loss: 15.220424\n",
            "Epoch 1, Batch 201 loss: 13.121951\n",
            "Epoch: 1 \tTraining Loss: 12.659033 \tValidation Loss: 8.266439\n",
            "Validation loss decreased (inf --> 8.266439).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 4.797704\n",
            "Epoch 2, Batch 101 loss: 12.532991\n",
            "Epoch 2, Batch 201 loss: 11.436483\n",
            "Epoch: 2 \tTraining Loss: 10.807289 \tValidation Loss: 7.317335\n",
            "Validation loss decreased (8.266439 --> 7.317335).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 6.297460\n",
            "Epoch 3, Batch 101 loss: 9.033580\n",
            "Epoch 3, Batch 201 loss: 8.933463\n",
            "Epoch: 3 \tTraining Loss: 9.012576 \tValidation Loss: 7.948039\n",
            "Epoch 4, Batch 1 loss: 9.055244\n",
            "Epoch 4, Batch 101 loss: 7.838452\n",
            "Epoch 4, Batch 201 loss: 8.738638\n",
            "Epoch: 4 \tTraining Loss: 8.799307 \tValidation Loss: 7.789643\n",
            "Epoch 5, Batch 1 loss: 9.411277\n",
            "Epoch 5, Batch 101 loss: 7.700464\n",
            "Epoch 5, Batch 201 loss: 7.846497\n",
            "Epoch: 5 \tTraining Loss: 7.686786 \tValidation Loss: 6.580015\n",
            "Validation loss decreased (7.317335 --> 6.580015).  Saving model ...\n",
            "Epoch 6, Batch 1 loss: 10.865433\n",
            "Epoch 6, Batch 101 loss: 7.346715\n",
            "Epoch 6, Batch 201 loss: 7.741486\n",
            "Epoch: 6 \tTraining Loss: 8.117153 \tValidation Loss: 6.772744\n",
            "Epoch 7, Batch 1 loss: 7.824043\n",
            "Epoch 7, Batch 101 loss: 8.151356\n",
            "Epoch 7, Batch 201 loss: 8.025776\n",
            "Epoch: 7 \tTraining Loss: 8.064931 \tValidation Loss: 8.007500\n",
            "Epoch 8, Batch 1 loss: 9.199683\n",
            "Epoch 8, Batch 101 loss: 8.012418\n",
            "Epoch 8, Batch 201 loss: 7.946841\n",
            "Epoch: 8 \tTraining Loss: 8.021655 \tValidation Loss: 6.557637\n",
            "Validation loss decreased (6.580015 --> 6.557637).  Saving model ...\n",
            "Epoch 9, Batch 1 loss: 4.793174\n",
            "Epoch 9, Batch 101 loss: 7.189142\n",
            "Epoch 9, Batch 201 loss: 7.679516\n",
            "Epoch: 9 \tTraining Loss: 7.808887 \tValidation Loss: 6.680810\n",
            "Epoch 10, Batch 1 loss: 4.104905\n",
            "Epoch 10, Batch 101 loss: 7.528505\n",
            "Epoch 10, Batch 201 loss: 7.545156\n",
            "Epoch: 10 \tTraining Loss: 7.225738 \tValidation Loss: 6.882246\n",
            "Epoch 11, Batch 1 loss: 2.074552\n",
            "Epoch 11, Batch 101 loss: 7.303446\n",
            "Epoch 11, Batch 201 loss: 7.366902\n",
            "Epoch: 11 \tTraining Loss: 7.321272 \tValidation Loss: 6.667488\n",
            "Epoch 12, Batch 1 loss: 3.974363\n",
            "Epoch 12, Batch 101 loss: 7.322931\n",
            "Epoch 12, Batch 201 loss: 7.208582\n",
            "Epoch: 12 \tTraining Loss: 7.244126 \tValidation Loss: 8.239839\n",
            "Epoch 13, Batch 1 loss: 3.582445\n",
            "Epoch 13, Batch 101 loss: 7.520054\n",
            "Epoch 13, Batch 201 loss: 7.459570\n",
            "Epoch: 13 \tTraining Loss: 7.407604 \tValidation Loss: 7.166356\n",
            "Epoch 14, Batch 1 loss: 5.805703\n",
            "Epoch 14, Batch 101 loss: 6.946851\n",
            "Epoch 14, Batch 201 loss: 7.182024\n",
            "Epoch: 14 \tTraining Loss: 7.353294 \tValidation Loss: 7.055289\n",
            "Epoch 15, Batch 1 loss: 4.153957\n",
            "Epoch 15, Batch 101 loss: 7.087313\n",
            "Epoch 15, Batch 201 loss: 6.963351\n",
            "Epoch: 15 \tTraining Loss: 7.101109 \tValidation Loss: 7.587156\n",
            "Epoch 16, Batch 1 loss: 9.858317\n",
            "Epoch 16, Batch 101 loss: 6.982172\n",
            "Epoch 16, Batch 201 loss: 6.924700\n",
            "Epoch: 16 \tTraining Loss: 7.097786 \tValidation Loss: 6.198877\n",
            "Validation loss decreased (6.557637 --> 6.198877).  Saving model ...\n",
            "Epoch 17, Batch 1 loss: 2.306960\n",
            "Epoch 17, Batch 101 loss: 6.804560\n",
            "Epoch 17, Batch 201 loss: 6.790950\n",
            "Epoch: 17 \tTraining Loss: 6.847702 \tValidation Loss: 6.885469\n",
            "Epoch 18, Batch 1 loss: 3.621483\n",
            "Epoch 18, Batch 101 loss: 6.872215\n",
            "Epoch 18, Batch 201 loss: 6.828921\n",
            "Epoch: 18 \tTraining Loss: 6.718334 \tValidation Loss: 6.460340\n",
            "Epoch 19, Batch 1 loss: 9.171741\n",
            "Epoch 19, Batch 101 loss: 7.173576\n",
            "Epoch 19, Batch 201 loss: 6.762672\n",
            "Epoch: 19 \tTraining Loss: 6.680714 \tValidation Loss: 6.799101\n",
            "Epoch 20, Batch 1 loss: 6.428805\n",
            "Epoch 20, Batch 101 loss: 6.897186\n",
            "Epoch 20, Batch 201 loss: 7.011106\n",
            "Epoch: 20 \tTraining Loss: 6.903671 \tValidation Loss: 7.536403\n",
            "CV - Fold  2\n",
            "created folder :  drive/MyDrive/DL_Project/cv/CNN3/0/2/\n",
            "Epoch 1, Batch 1 loss: 18.720089\n",
            "Epoch 1, Batch 101 loss: 15.291587\n",
            "Epoch 1, Batch 201 loss: 13.416924\n",
            "Epoch: 1 \tTraining Loss: 12.282088 \tValidation Loss: 7.921046\n",
            "Validation loss decreased (inf --> 7.921046).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 7.124372\n",
            "Epoch 2, Batch 101 loss: 9.321908\n",
            "Epoch 2, Batch 201 loss: 9.612951\n",
            "Epoch: 2 \tTraining Loss: 9.857027 \tValidation Loss: 8.552900\n",
            "Epoch 3, Batch 1 loss: 25.978750\n",
            "Epoch 3, Batch 101 loss: 9.645651\n",
            "Epoch 3, Batch 201 loss: 9.233828\n",
            "Epoch: 3 \tTraining Loss: 9.297809 \tValidation Loss: 6.578342\n",
            "Validation loss decreased (7.921046 --> 6.578342).  Saving model ...\n",
            "Epoch 4, Batch 1 loss: 2.231355\n",
            "Epoch 4, Batch 101 loss: 9.551432\n",
            "Epoch 4, Batch 201 loss: 9.265615\n",
            "Epoch: 4 \tTraining Loss: 9.187568 \tValidation Loss: 7.315390\n",
            "Epoch 5, Batch 1 loss: 3.989324\n",
            "Epoch 5, Batch 101 loss: 8.667678\n",
            "Epoch 5, Batch 201 loss: 8.566172\n",
            "Epoch: 5 \tTraining Loss: 8.490762 \tValidation Loss: 7.012946\n",
            "Epoch 6, Batch 1 loss: 7.363701\n",
            "Epoch 6, Batch 101 loss: 8.066405\n",
            "Epoch 6, Batch 201 loss: 8.020122\n",
            "Epoch: 6 \tTraining Loss: 8.117889 \tValidation Loss: 7.077727\n",
            "Epoch 7, Batch 1 loss: 6.487315\n",
            "Epoch 7, Batch 101 loss: 7.941072\n",
            "Epoch 7, Batch 201 loss: 8.122286\n",
            "Epoch: 7 \tTraining Loss: 8.058615 \tValidation Loss: 7.724801\n",
            "Epoch 8, Batch 1 loss: 10.870176\n",
            "Epoch 8, Batch 101 loss: 8.083925\n",
            "Epoch 8, Batch 201 loss: 8.331589\n",
            "Epoch: 8 \tTraining Loss: 8.306296 \tValidation Loss: 6.763392\n",
            "Epoch 9, Batch 1 loss: 10.424266\n",
            "Epoch 9, Batch 101 loss: 8.152685\n",
            "Epoch 9, Batch 201 loss: 7.902709\n",
            "Epoch: 9 \tTraining Loss: 7.650331 \tValidation Loss: 6.686462\n",
            "Epoch 10, Batch 1 loss: 9.705538\n",
            "Epoch 10, Batch 101 loss: 7.923326\n",
            "Epoch 10, Batch 201 loss: 8.083540\n",
            "Epoch: 10 \tTraining Loss: 7.712248 \tValidation Loss: 6.163784\n",
            "Validation loss decreased (6.578342 --> 6.163784).  Saving model ...\n",
            "Epoch 11, Batch 1 loss: 15.068018\n",
            "Epoch 11, Batch 101 loss: 7.794699\n",
            "Epoch 11, Batch 201 loss: 7.579730\n",
            "Epoch: 11 \tTraining Loss: 7.548042 \tValidation Loss: 7.156813\n",
            "Epoch 12, Batch 1 loss: 5.162824\n",
            "Epoch 12, Batch 101 loss: 7.316849\n",
            "Epoch 12, Batch 201 loss: 7.473341\n",
            "Epoch: 12 \tTraining Loss: 7.926599 \tValidation Loss: 6.268368\n",
            "Epoch 13, Batch 1 loss: 5.957167\n",
            "Epoch 13, Batch 101 loss: 7.250196\n",
            "Epoch 13, Batch 201 loss: 7.407345\n",
            "Epoch: 13 \tTraining Loss: 7.396139 \tValidation Loss: 7.039888\n",
            "Epoch 14, Batch 1 loss: 10.020694\n",
            "Epoch 14, Batch 101 loss: 7.282779\n",
            "Epoch 14, Batch 201 loss: 7.156571\n",
            "Epoch: 14 \tTraining Loss: 6.974886 \tValidation Loss: 6.960036\n",
            "Epoch 15, Batch 1 loss: 7.908268\n",
            "Epoch 15, Batch 101 loss: 8.219394\n",
            "Epoch 15, Batch 201 loss: 7.660913\n",
            "Epoch: 15 \tTraining Loss: 7.326602 \tValidation Loss: 6.258818\n",
            "Epoch 16, Batch 1 loss: 8.795199\n",
            "Epoch 16, Batch 101 loss: 7.232513\n",
            "Epoch 16, Batch 201 loss: 7.431461\n",
            "Epoch: 16 \tTraining Loss: 7.380852 \tValidation Loss: 6.297220\n",
            "Epoch 17, Batch 1 loss: 10.457336\n",
            "Epoch 17, Batch 101 loss: 6.951838\n",
            "Epoch 17, Batch 201 loss: 7.006693\n",
            "Epoch: 17 \tTraining Loss: 7.025219 \tValidation Loss: 6.782042\n",
            "Epoch 18, Batch 1 loss: 5.050210\n",
            "Epoch 18, Batch 101 loss: 6.749750\n",
            "Epoch 18, Batch 201 loss: 6.756574\n",
            "Epoch: 18 \tTraining Loss: 6.978545 \tValidation Loss: 7.020611\n",
            "Epoch 19, Batch 1 loss: 3.654106\n",
            "Epoch 19, Batch 101 loss: 7.089519\n",
            "Epoch 19, Batch 201 loss: 6.910403\n",
            "Epoch: 19 \tTraining Loss: 6.915944 \tValidation Loss: 10.091606\n",
            "Epoch 20, Batch 1 loss: 11.172361\n",
            "Epoch 20, Batch 101 loss: 7.337970\n",
            "Epoch 20, Batch 201 loss: 7.163740\n",
            "Epoch: 20 \tTraining Loss: 7.087897 \tValidation Loss: 6.915038\n",
            "CV - Fold  3\n",
            "created folder :  drive/MyDrive/DL_Project/cv/CNN3/0/3/\n",
            "Epoch 1, Batch 1 loss: 15.201139\n",
            "Epoch 1, Batch 101 loss: 16.544544\n",
            "Epoch 1, Batch 201 loss: 13.889714\n",
            "Epoch: 1 \tTraining Loss: 12.940560 \tValidation Loss: 8.741199\n",
            "Validation loss decreased (inf --> 8.741199).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 10.260372\n",
            "Epoch 2, Batch 101 loss: 10.234853\n",
            "Epoch 2, Batch 201 loss: 10.176236\n",
            "Epoch: 2 \tTraining Loss: 9.861524 \tValidation Loss: 7.214388\n",
            "Validation loss decreased (8.741199 --> 7.214388).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 11.283382\n",
            "Epoch 3, Batch 101 loss: 8.655854\n",
            "Epoch 3, Batch 201 loss: 9.204435\n",
            "Epoch: 3 \tTraining Loss: 9.004230 \tValidation Loss: 7.289109\n",
            "Epoch 4, Batch 1 loss: 4.414914\n",
            "Epoch 4, Batch 101 loss: 9.904987\n",
            "Epoch 4, Batch 201 loss: 9.301190\n",
            "Epoch: 4 \tTraining Loss: 8.836745 \tValidation Loss: 7.242423\n",
            "Epoch 5, Batch 1 loss: 5.395234\n",
            "Epoch 5, Batch 101 loss: 8.020184\n",
            "Epoch 5, Batch 201 loss: 8.221647\n",
            "Epoch: 5 \tTraining Loss: 8.132125 \tValidation Loss: 7.376283\n",
            "Epoch 6, Batch 1 loss: 2.920093\n",
            "Epoch 6, Batch 101 loss: 7.247537\n",
            "Epoch 6, Batch 201 loss: 8.081818\n",
            "Epoch: 6 \tTraining Loss: 7.903286 \tValidation Loss: 6.957289\n",
            "Validation loss decreased (7.214388 --> 6.957289).  Saving model ...\n",
            "Epoch 7, Batch 1 loss: 9.328034\n",
            "Epoch 7, Batch 101 loss: 7.722918\n",
            "Epoch 7, Batch 201 loss: 7.684104\n",
            "Epoch: 7 \tTraining Loss: 7.842036 \tValidation Loss: 7.185969\n",
            "Epoch 8, Batch 1 loss: 4.273705\n",
            "Epoch 8, Batch 101 loss: 7.768157\n",
            "Epoch 8, Batch 201 loss: 7.818926\n",
            "Epoch: 8 \tTraining Loss: 7.744829 \tValidation Loss: 7.306965\n",
            "Epoch 9, Batch 1 loss: 3.830885\n",
            "Epoch 9, Batch 101 loss: 7.015408\n",
            "Epoch 9, Batch 201 loss: 6.930234\n",
            "Epoch: 9 \tTraining Loss: 7.253175 \tValidation Loss: 8.862473\n",
            "Epoch 10, Batch 1 loss: 14.853128\n",
            "Epoch 10, Batch 101 loss: 7.472047\n",
            "Epoch 10, Batch 201 loss: 7.594227\n",
            "Epoch: 10 \tTraining Loss: 7.617067 \tValidation Loss: 7.541348\n",
            "Epoch 11, Batch 1 loss: 3.045955\n",
            "Epoch 11, Batch 101 loss: 7.274575\n",
            "Epoch 11, Batch 201 loss: 7.434627\n",
            "Epoch: 11 \tTraining Loss: 7.292049 \tValidation Loss: 6.410708\n",
            "Validation loss decreased (6.957289 --> 6.410708).  Saving model ...\n",
            "Epoch 12, Batch 1 loss: 4.229445\n",
            "Epoch 12, Batch 101 loss: 7.250428\n",
            "Epoch 12, Batch 201 loss: 6.962839\n",
            "Epoch: 12 \tTraining Loss: 7.297445 \tValidation Loss: 7.091537\n",
            "Epoch 13, Batch 1 loss: 7.246884\n",
            "Epoch 13, Batch 101 loss: 7.283281\n",
            "Epoch 13, Batch 201 loss: 6.941741\n",
            "Epoch: 13 \tTraining Loss: 7.065717 \tValidation Loss: 6.436434\n",
            "Epoch 14, Batch 1 loss: 5.282290\n",
            "Epoch 14, Batch 101 loss: 7.197280\n",
            "Epoch 14, Batch 201 loss: 7.085799\n",
            "Epoch: 14 \tTraining Loss: 6.902944 \tValidation Loss: 6.390926\n",
            "Validation loss decreased (6.410708 --> 6.390926).  Saving model ...\n",
            "Epoch 15, Batch 1 loss: 8.811110\n",
            "Epoch 15, Batch 101 loss: 7.058960\n",
            "Epoch 15, Batch 201 loss: 7.113107\n",
            "Epoch: 15 \tTraining Loss: 7.036074 \tValidation Loss: 6.388117\n",
            "Validation loss decreased (6.390926 --> 6.388117).  Saving model ...\n",
            "Epoch 16, Batch 1 loss: 4.209668\n",
            "Epoch 16, Batch 101 loss: 6.670171\n",
            "Epoch 16, Batch 201 loss: 6.554812\n",
            "Epoch: 16 \tTraining Loss: 6.720180 \tValidation Loss: 6.140836\n",
            "Validation loss decreased (6.388117 --> 6.140836).  Saving model ...\n",
            "Epoch 17, Batch 1 loss: 7.518545\n",
            "Epoch 17, Batch 101 loss: 6.602902\n",
            "Epoch 17, Batch 201 loss: 6.591264\n",
            "Epoch: 17 \tTraining Loss: 6.717206 \tValidation Loss: 6.358129\n",
            "Epoch 18, Batch 1 loss: 3.604254\n",
            "Epoch 18, Batch 101 loss: 7.411508\n",
            "Epoch 18, Batch 201 loss: 7.128222\n",
            "Epoch: 18 \tTraining Loss: 7.122363 \tValidation Loss: 6.703024\n",
            "Epoch 19, Batch 1 loss: 3.724609\n",
            "Epoch 19, Batch 101 loss: 6.988438\n",
            "Epoch 19, Batch 201 loss: 6.926092\n",
            "Epoch: 19 \tTraining Loss: 6.787380 \tValidation Loss: 6.594856\n",
            "Epoch 20, Batch 1 loss: 8.978286\n",
            "Epoch 20, Batch 101 loss: 6.483687\n",
            "Epoch 20, Batch 201 loss: 6.454788\n",
            "Epoch: 20 \tTraining Loss: 6.402810 \tValidation Loss: 6.737414\n",
            "----------------------Final CV loss: 7.187867 -----------------------\n",
            "drive/MyDrive/DL_Project/cv/CNN3/0/predictions.zip\n",
            "created folder :  drive/MyDrive/DL_Project/cv/CNN3/1/\n",
            "1 (<class '__main__.CNN32'>, SmoothL1Loss(), 0.0005) drive/MyDrive/DL_Project/cv/CNN3/1/\n",
            "CV - Fold  0\n",
            "created folder :  drive/MyDrive/DL_Project/cv/CNN3/1/0/\n",
            "Epoch 1, Batch 1 loss: 7.232540\n",
            "Epoch 1, Batch 101 loss: 16.076571\n",
            "Epoch 1, Batch 201 loss: 13.494756\n",
            "Epoch: 1 \tTraining Loss: 12.741011 \tValidation Loss: 7.180889\n",
            "Validation loss decreased (inf --> 7.180889).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 11.317123\n",
            "Epoch 2, Batch 101 loss: 10.034024\n",
            "Epoch 2, Batch 201 loss: 9.362321\n",
            "Epoch: 2 \tTraining Loss: 9.341332 \tValidation Loss: 6.849995\n",
            "Validation loss decreased (7.180889 --> 6.849995).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 19.722368\n",
            "Epoch 3, Batch 101 loss: 9.139887\n",
            "Epoch 3, Batch 201 loss: 9.378250\n",
            "Epoch: 3 \tTraining Loss: 9.043403 \tValidation Loss: 6.453872\n",
            "Validation loss decreased (6.849995 --> 6.453872).  Saving model ...\n",
            "Epoch 4, Batch 1 loss: 6.368629\n",
            "Epoch 4, Batch 101 loss: 8.193296\n",
            "Epoch 4, Batch 201 loss: 8.316404\n",
            "Epoch: 4 \tTraining Loss: 8.142147 \tValidation Loss: 6.019778\n",
            "Validation loss decreased (6.453872 --> 6.019778).  Saving model ...\n",
            "Epoch 5, Batch 1 loss: 5.206939\n",
            "Epoch 5, Batch 101 loss: 7.248780\n",
            "Epoch 5, Batch 201 loss: 7.470802\n",
            "Epoch: 5 \tTraining Loss: 7.776000 \tValidation Loss: 7.795448\n",
            "Epoch 6, Batch 1 loss: 12.683352\n",
            "Epoch 6, Batch 101 loss: 7.847147\n",
            "Epoch 6, Batch 201 loss: 8.131271\n",
            "Epoch: 6 \tTraining Loss: 7.915958 \tValidation Loss: 5.950757\n",
            "Validation loss decreased (6.019778 --> 5.950757).  Saving model ...\n",
            "Epoch 7, Batch 1 loss: 5.323799\n",
            "Epoch 7, Batch 101 loss: 8.841597\n",
            "Epoch 7, Batch 201 loss: 8.298384\n",
            "Epoch: 7 \tTraining Loss: 7.937041 \tValidation Loss: 6.766624\n",
            "Epoch 8, Batch 1 loss: 3.474538\n",
            "Epoch 8, Batch 101 loss: 7.560962\n",
            "Epoch 8, Batch 201 loss: 7.660889\n",
            "Epoch: 8 \tTraining Loss: 7.707511 \tValidation Loss: 6.991369\n",
            "Epoch 9, Batch 1 loss: 6.535618\n",
            "Epoch 9, Batch 101 loss: 7.211660\n",
            "Epoch 9, Batch 201 loss: 7.182763\n",
            "Epoch: 9 \tTraining Loss: 7.256129 \tValidation Loss: 6.218963\n",
            "Epoch 10, Batch 1 loss: 5.990664\n",
            "Epoch 10, Batch 101 loss: 7.422874\n",
            "Epoch 10, Batch 201 loss: 7.094525\n",
            "Epoch: 10 \tTraining Loss: 6.953683 \tValidation Loss: 5.799984\n",
            "Validation loss decreased (5.950757 --> 5.799984).  Saving model ...\n",
            "Epoch 11, Batch 1 loss: 5.354589\n",
            "Epoch 11, Batch 101 loss: 7.061576\n",
            "Epoch 11, Batch 201 loss: 7.137966\n",
            "Epoch: 11 \tTraining Loss: 6.926364 \tValidation Loss: 6.122059\n",
            "Epoch 12, Batch 1 loss: 4.208307\n",
            "Epoch 12, Batch 101 loss: 6.752352\n",
            "Epoch 12, Batch 201 loss: 7.043387\n",
            "Epoch: 12 \tTraining Loss: 7.111056 \tValidation Loss: 6.549973\n",
            "Epoch 13, Batch 1 loss: 4.633792\n",
            "Epoch 13, Batch 101 loss: 6.671119\n",
            "Epoch 13, Batch 201 loss: 6.779849\n",
            "Epoch: 13 \tTraining Loss: 6.744814 \tValidation Loss: 5.548778\n",
            "Validation loss decreased (5.799984 --> 5.548778).  Saving model ...\n",
            "Epoch 14, Batch 1 loss: 5.224423\n",
            "Epoch 14, Batch 101 loss: 6.732185\n",
            "Epoch 14, Batch 201 loss: 7.004280\n",
            "Epoch: 14 \tTraining Loss: 6.992101 \tValidation Loss: 6.403865\n",
            "Epoch 15, Batch 1 loss: 7.977262\n",
            "Epoch 15, Batch 101 loss: 6.313281\n",
            "Epoch 15, Batch 201 loss: 6.404596\n",
            "Epoch: 15 \tTraining Loss: 6.461418 \tValidation Loss: 6.742841\n",
            "Epoch 16, Batch 1 loss: 7.405327\n",
            "Epoch 16, Batch 101 loss: 6.940476\n",
            "Epoch 16, Batch 201 loss: 7.030943\n",
            "Epoch: 16 \tTraining Loss: 6.851923 \tValidation Loss: 6.026711\n",
            "Epoch 17, Batch 1 loss: 3.558577\n",
            "Epoch 17, Batch 101 loss: 6.609895\n",
            "Epoch 17, Batch 201 loss: 6.620667\n",
            "Epoch: 17 \tTraining Loss: 6.738657 \tValidation Loss: 6.351977\n",
            "Epoch 18, Batch 1 loss: 6.453867\n",
            "Epoch 18, Batch 101 loss: 6.802027\n",
            "Epoch 18, Batch 201 loss: 6.723855\n",
            "Epoch: 18 \tTraining Loss: 6.693800 \tValidation Loss: 5.875677\n",
            "Epoch 19, Batch 1 loss: 4.416806\n",
            "Epoch 19, Batch 101 loss: 6.034730\n",
            "Epoch 19, Batch 201 loss: 6.248184\n",
            "Epoch: 19 \tTraining Loss: 6.283702 \tValidation Loss: 6.436433\n",
            "Epoch 20, Batch 1 loss: 9.447762\n",
            "Epoch 20, Batch 101 loss: 7.074205\n",
            "Epoch 20, Batch 201 loss: 6.697090\n",
            "Epoch: 20 \tTraining Loss: 6.576228 \tValidation Loss: 6.060855\n",
            "CV - Fold  1\n",
            "created folder :  drive/MyDrive/DL_Project/cv/CNN3/1/1/\n",
            "Epoch 1, Batch 1 loss: 21.497410\n",
            "Epoch 1, Batch 101 loss: 14.429524\n",
            "Epoch 1, Batch 201 loss: 13.348989\n",
            "Epoch: 1 \tTraining Loss: 12.112365 \tValidation Loss: 8.056513\n",
            "Validation loss decreased (inf --> 8.056513).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 5.051145\n",
            "Epoch 2, Batch 101 loss: 9.259742\n",
            "Epoch 2, Batch 201 loss: 8.867346\n",
            "Epoch: 2 \tTraining Loss: 8.943541 \tValidation Loss: 8.704325\n",
            "Epoch 3, Batch 1 loss: 4.762881\n",
            "Epoch 3, Batch 101 loss: 8.180647\n",
            "Epoch 3, Batch 201 loss: 8.385260\n",
            "Epoch: 3 \tTraining Loss: 8.198286 \tValidation Loss: 7.795616\n",
            "Validation loss decreased (8.056513 --> 7.795616).  Saving model ...\n",
            "Epoch 4, Batch 1 loss: 7.333575\n",
            "Epoch 4, Batch 101 loss: 7.486864\n",
            "Epoch 4, Batch 201 loss: 7.796537\n",
            "Epoch: 4 \tTraining Loss: 7.768957 \tValidation Loss: 7.599626\n",
            "Validation loss decreased (7.795616 --> 7.599626).  Saving model ...\n",
            "Epoch 5, Batch 1 loss: 8.370784\n",
            "Epoch 5, Batch 101 loss: 7.702926\n",
            "Epoch 5, Batch 201 loss: 8.042049\n",
            "Epoch: 5 \tTraining Loss: 7.870266 \tValidation Loss: 7.208500\n",
            "Validation loss decreased (7.599626 --> 7.208500).  Saving model ...\n",
            "Epoch 6, Batch 1 loss: 6.316704\n",
            "Epoch 6, Batch 101 loss: 7.588361\n",
            "Epoch 6, Batch 201 loss: 7.734543\n",
            "Epoch: 6 \tTraining Loss: 7.548403 \tValidation Loss: 6.985474\n",
            "Validation loss decreased (7.208500 --> 6.985474).  Saving model ...\n",
            "Epoch 7, Batch 1 loss: 3.774788\n",
            "Epoch 7, Batch 101 loss: 7.550239\n",
            "Epoch 7, Batch 201 loss: 7.395975\n",
            "Epoch: 7 \tTraining Loss: 7.405644 \tValidation Loss: 8.921126\n",
            "Epoch 8, Batch 1 loss: 4.982258\n",
            "Epoch 8, Batch 101 loss: 8.005941\n",
            "Epoch 8, Batch 201 loss: 7.532450\n",
            "Epoch: 8 \tTraining Loss: 7.705715 \tValidation Loss: 7.596021\n",
            "Epoch 9, Batch 1 loss: 16.668518\n",
            "Epoch 9, Batch 101 loss: 7.589548\n",
            "Epoch 9, Batch 201 loss: 7.405128\n",
            "Epoch: 9 \tTraining Loss: 7.269004 \tValidation Loss: 7.161546\n",
            "Epoch 10, Batch 1 loss: 3.683403\n",
            "Epoch 10, Batch 101 loss: 7.456419\n",
            "Epoch 10, Batch 201 loss: 7.292335\n",
            "Epoch: 10 \tTraining Loss: 7.135951 \tValidation Loss: 7.988980\n",
            "Epoch 11, Batch 1 loss: 3.381961\n",
            "Epoch 11, Batch 101 loss: 7.048944\n",
            "Epoch 11, Batch 201 loss: 7.170469\n",
            "Epoch: 11 \tTraining Loss: 6.861446 \tValidation Loss: 7.324236\n",
            "Epoch 12, Batch 1 loss: 4.949329\n",
            "Epoch 12, Batch 101 loss: 6.983872\n",
            "Epoch 12, Batch 201 loss: 6.933657\n",
            "Epoch: 12 \tTraining Loss: 6.965828 \tValidation Loss: 7.175266\n",
            "Epoch 13, Batch 1 loss: 3.926679\n",
            "Epoch 13, Batch 101 loss: 7.173588\n",
            "Epoch 13, Batch 201 loss: 7.217603\n",
            "Epoch: 13 \tTraining Loss: 7.165302 \tValidation Loss: 7.834933\n",
            "Epoch 14, Batch 1 loss: 2.104316\n",
            "Epoch 14, Batch 101 loss: 6.474133\n",
            "Epoch 14, Batch 201 loss: 6.908890\n",
            "Epoch: 14 \tTraining Loss: 6.966109 \tValidation Loss: 7.896794\n",
            "Epoch 15, Batch 1 loss: 8.281893\n",
            "Epoch 15, Batch 101 loss: 6.870448\n",
            "Epoch 15, Batch 201 loss: 6.916319\n",
            "Epoch: 15 \tTraining Loss: 6.932075 \tValidation Loss: 7.446352\n",
            "Epoch 16, Batch 1 loss: 7.584356\n",
            "Epoch 16, Batch 101 loss: 6.269760\n",
            "Epoch 16, Batch 201 loss: 6.555245\n",
            "Epoch: 16 \tTraining Loss: 6.570248 \tValidation Loss: 7.006744\n",
            "Epoch 17, Batch 1 loss: 2.766495\n",
            "Epoch 17, Batch 101 loss: 6.210470\n",
            "Epoch 17, Batch 201 loss: 6.411180\n",
            "Epoch: 17 \tTraining Loss: 6.360400 \tValidation Loss: 6.904660\n",
            "Validation loss decreased (6.985474 --> 6.904660).  Saving model ...\n",
            "Epoch 18, Batch 1 loss: 3.876374\n",
            "Epoch 18, Batch 101 loss: 6.683882\n",
            "Epoch 18, Batch 201 loss: 6.618870\n",
            "Epoch: 18 \tTraining Loss: 6.558151 \tValidation Loss: 6.877239\n",
            "Validation loss decreased (6.904660 --> 6.877239).  Saving model ...\n",
            "Epoch 19, Batch 1 loss: 5.418923\n",
            "Epoch 19, Batch 101 loss: 6.552138\n",
            "Epoch 19, Batch 201 loss: 6.349500\n",
            "Epoch: 19 \tTraining Loss: 6.317449 \tValidation Loss: 7.253143\n",
            "Epoch 20, Batch 1 loss: 7.366292\n",
            "Epoch 20, Batch 101 loss: 6.160477\n",
            "Epoch 20, Batch 201 loss: 6.082417\n",
            "Epoch: 20 \tTraining Loss: 6.473532 \tValidation Loss: 7.148052\n",
            "CV - Fold  2\n",
            "created folder :  drive/MyDrive/DL_Project/cv/CNN3/1/2/\n",
            "Epoch 1, Batch 1 loss: 25.077339\n",
            "Epoch 1, Batch 101 loss: 15.029408\n",
            "Epoch 1, Batch 201 loss: 12.866036\n",
            "Epoch: 1 \tTraining Loss: 11.688887 \tValidation Loss: 11.002255\n",
            "Validation loss decreased (inf --> 11.002255).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 11.831655\n",
            "Epoch 2, Batch 101 loss: 8.014017\n",
            "Epoch 2, Batch 201 loss: 7.858737\n",
            "Epoch: 2 \tTraining Loss: 7.789388 \tValidation Loss: 10.425967\n",
            "Validation loss decreased (11.002255 --> 10.425967).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 17.557865\n",
            "Epoch 3, Batch 101 loss: 7.691204\n",
            "Epoch 3, Batch 201 loss: 7.346166\n",
            "Epoch: 3 \tTraining Loss: 7.333905 \tValidation Loss: 10.376233\n",
            "Validation loss decreased (10.425967 --> 10.376233).  Saving model ...\n",
            "Epoch 4, Batch 1 loss: 5.341564\n",
            "Epoch 4, Batch 101 loss: 7.779778\n",
            "Epoch 4, Batch 201 loss: 7.510220\n",
            "Epoch: 4 \tTraining Loss: 7.272622 \tValidation Loss: 9.994484\n",
            "Validation loss decreased (10.376233 --> 9.994484).  Saving model ...\n",
            "Epoch 5, Batch 1 loss: 7.147795\n",
            "Epoch 5, Batch 101 loss: 7.323694\n",
            "Epoch 5, Batch 201 loss: 7.041798\n",
            "Epoch: 5 \tTraining Loss: 7.027027 \tValidation Loss: 10.134440\n",
            "Epoch 6, Batch 1 loss: 6.064233\n",
            "Epoch 6, Batch 101 loss: 7.018545\n",
            "Epoch 6, Batch 201 loss: 6.985795\n",
            "Epoch: 6 \tTraining Loss: 6.998348 \tValidation Loss: 9.763995\n",
            "Validation loss decreased (9.994484 --> 9.763995).  Saving model ...\n",
            "Epoch 7, Batch 1 loss: 7.862400\n",
            "Epoch 7, Batch 101 loss: 7.007326\n",
            "Epoch 7, Batch 201 loss: 6.583992\n",
            "Epoch: 7 \tTraining Loss: 6.572109 \tValidation Loss: 10.306113\n",
            "Epoch 8, Batch 1 loss: 6.552547\n",
            "Epoch 8, Batch 101 loss: 6.217295\n",
            "Epoch 8, Batch 201 loss: 6.539568\n",
            "Epoch: 8 \tTraining Loss: 6.433669 \tValidation Loss: 9.686583\n",
            "Validation loss decreased (9.763995 --> 9.686583).  Saving model ...\n",
            "Epoch 9, Batch 1 loss: 12.391115\n",
            "Epoch 9, Batch 101 loss: 6.468696\n",
            "Epoch 9, Batch 201 loss: 6.346252\n",
            "Epoch: 9 \tTraining Loss: 6.379375 \tValidation Loss: 9.919181\n",
            "Epoch 10, Batch 1 loss: 7.007981\n",
            "Epoch 10, Batch 101 loss: 6.219584\n",
            "Epoch 10, Batch 201 loss: 6.437597\n",
            "Epoch: 10 \tTraining Loss: 6.315646 \tValidation Loss: 9.538260\n",
            "Validation loss decreased (9.686583 --> 9.538260).  Saving model ...\n",
            "Epoch 11, Batch 1 loss: 3.074905\n",
            "Epoch 11, Batch 101 loss: 5.901832\n",
            "Epoch 11, Batch 201 loss: 6.011088\n",
            "Epoch: 11 \tTraining Loss: 6.054697 \tValidation Loss: 9.852821\n",
            "Epoch 12, Batch 1 loss: 22.342596\n",
            "Epoch 12, Batch 101 loss: 5.583283\n",
            "Epoch 12, Batch 201 loss: 5.868130\n",
            "Epoch: 12 \tTraining Loss: 5.974577 \tValidation Loss: 9.993362\n",
            "Epoch 13, Batch 1 loss: 11.704908\n",
            "Epoch 13, Batch 101 loss: 6.453399\n",
            "Epoch 13, Batch 201 loss: 6.043703\n",
            "Epoch: 13 \tTraining Loss: 6.078558 \tValidation Loss: 9.387059\n",
            "Validation loss decreased (9.538260 --> 9.387059).  Saving model ...\n",
            "Epoch 14, Batch 1 loss: 5.987805\n",
            "Epoch 14, Batch 101 loss: 5.819420\n",
            "Epoch 14, Batch 201 loss: 5.693130\n",
            "Epoch: 14 \tTraining Loss: 5.860973 \tValidation Loss: 9.276259\n",
            "Validation loss decreased (9.387059 --> 9.276259).  Saving model ...\n",
            "Epoch 15, Batch 1 loss: 9.809796\n",
            "Epoch 15, Batch 101 loss: 5.561871\n",
            "Epoch 15, Batch 201 loss: 5.632230\n",
            "Epoch: 15 \tTraining Loss: 5.693517 \tValidation Loss: 9.472921\n",
            "Epoch 16, Batch 1 loss: 4.794374\n",
            "Epoch 16, Batch 101 loss: 5.705625\n",
            "Epoch 16, Batch 201 loss: 5.923999\n",
            "Epoch: 16 \tTraining Loss: 5.785944 \tValidation Loss: 9.961319\n",
            "Epoch 17, Batch 1 loss: 5.147133\n",
            "Epoch 17, Batch 101 loss: 6.374140\n",
            "Epoch 17, Batch 201 loss: 6.104177\n",
            "Epoch: 17 \tTraining Loss: 6.025738 \tValidation Loss: 9.524705\n",
            "Epoch 18, Batch 1 loss: 11.909740\n",
            "Epoch 18, Batch 101 loss: 5.910841\n",
            "Epoch 18, Batch 201 loss: 5.812676\n",
            "Epoch: 18 \tTraining Loss: 5.784179 \tValidation Loss: 9.797052\n",
            "Epoch 19, Batch 1 loss: 9.347097\n",
            "Epoch 19, Batch 101 loss: 5.974038\n",
            "Epoch 19, Batch 201 loss: 5.916104\n",
            "Epoch: 19 \tTraining Loss: 5.774676 \tValidation Loss: 10.598925\n",
            "Epoch 20, Batch 1 loss: 5.158817\n",
            "Epoch 20, Batch 101 loss: 5.579519\n",
            "Epoch 20, Batch 201 loss: 5.433474\n",
            "Epoch: 20 \tTraining Loss: 5.534416 \tValidation Loss: 9.482035\n",
            "CV - Fold  3\n",
            "created folder :  drive/MyDrive/DL_Project/cv/CNN3/1/3/\n",
            "Epoch 1, Batch 1 loss: 3.292153\n",
            "Epoch 1, Batch 101 loss: 13.929162\n",
            "Epoch 1, Batch 201 loss: 12.553607\n",
            "Epoch: 1 \tTraining Loss: 11.894412 \tValidation Loss: 10.136622\n",
            "Validation loss decreased (inf --> 10.136622).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 12.634300\n",
            "Epoch 2, Batch 101 loss: 8.824003\n",
            "Epoch 2, Batch 201 loss: 8.671084\n",
            "Epoch: 2 \tTraining Loss: 8.527638 \tValidation Loss: 9.412283\n",
            "Validation loss decreased (10.136622 --> 9.412283).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 4.923713\n",
            "Epoch 3, Batch 101 loss: 8.418257\n",
            "Epoch 3, Batch 201 loss: 8.110352\n",
            "Epoch: 3 \tTraining Loss: 8.240315 \tValidation Loss: 9.014648\n",
            "Validation loss decreased (9.412283 --> 9.014648).  Saving model ...\n",
            "Epoch 4, Batch 1 loss: 11.640642\n",
            "Epoch 4, Batch 101 loss: 7.946885\n",
            "Epoch 4, Batch 201 loss: 7.825089\n",
            "Epoch: 4 \tTraining Loss: 7.787467 \tValidation Loss: 8.664819\n",
            "Validation loss decreased (9.014648 --> 8.664819).  Saving model ...\n",
            "Epoch 5, Batch 1 loss: 5.954560\n",
            "Epoch 5, Batch 101 loss: 7.947302\n",
            "Epoch 5, Batch 201 loss: 7.555423\n",
            "Epoch: 5 \tTraining Loss: 7.437753 \tValidation Loss: 8.292932\n",
            "Validation loss decreased (8.664819 --> 8.292932).  Saving model ...\n",
            "Epoch 6, Batch 1 loss: 9.678471\n",
            "Epoch 6, Batch 101 loss: 6.952287\n",
            "Epoch 6, Batch 201 loss: 7.394218\n",
            "Epoch: 6 \tTraining Loss: 7.404974 \tValidation Loss: 8.571903\n",
            "Epoch 7, Batch 1 loss: 2.518219\n",
            "Epoch 7, Batch 101 loss: 6.974374\n",
            "Epoch 7, Batch 201 loss: 7.248545\n",
            "Epoch: 7 \tTraining Loss: 7.181171 \tValidation Loss: 8.747760\n",
            "Epoch 8, Batch 1 loss: 5.627639\n",
            "Epoch 8, Batch 101 loss: 6.604627\n",
            "Epoch 8, Batch 201 loss: 7.137872\n",
            "Epoch: 8 \tTraining Loss: 7.007215 \tValidation Loss: 9.616087\n",
            "Epoch 9, Batch 1 loss: 6.897503\n",
            "Epoch 9, Batch 101 loss: 7.191922\n",
            "Epoch 9, Batch 201 loss: 6.991824\n",
            "Epoch: 9 \tTraining Loss: 6.714563 \tValidation Loss: 8.674051\n",
            "Epoch 10, Batch 1 loss: 8.629511\n",
            "Epoch 10, Batch 101 loss: 6.140189\n",
            "Epoch 10, Batch 201 loss: 6.795250\n",
            "Epoch: 10 \tTraining Loss: 6.641150 \tValidation Loss: 11.048570\n",
            "Epoch 11, Batch 1 loss: 14.970027\n",
            "Epoch 11, Batch 101 loss: 7.437531\n",
            "Epoch 11, Batch 201 loss: 7.132486\n",
            "Epoch: 11 \tTraining Loss: 7.006787 \tValidation Loss: 8.360701\n",
            "Epoch 12, Batch 1 loss: 5.434289\n",
            "Epoch 12, Batch 101 loss: 6.221322\n",
            "Epoch 12, Batch 201 loss: 6.461032\n",
            "Epoch: 12 \tTraining Loss: 6.505077 \tValidation Loss: 9.190210\n",
            "Epoch 13, Batch 1 loss: 5.419744\n",
            "Epoch 13, Batch 101 loss: 6.409517\n",
            "Epoch 13, Batch 201 loss: 6.643578\n",
            "Epoch: 13 \tTraining Loss: 6.515417 \tValidation Loss: 8.631203\n",
            "Epoch 14, Batch 1 loss: 2.243330\n",
            "Epoch 14, Batch 101 loss: 6.423366\n",
            "Epoch 14, Batch 201 loss: 6.193023\n",
            "Epoch: 14 \tTraining Loss: 6.341382 \tValidation Loss: 9.577513\n",
            "Epoch 15, Batch 1 loss: 4.898100\n",
            "Epoch 15, Batch 101 loss: 6.661305\n",
            "Epoch 15, Batch 201 loss: 6.339576\n",
            "Epoch: 15 \tTraining Loss: 6.317489 \tValidation Loss: 8.134593\n",
            "Validation loss decreased (8.292932 --> 8.134593).  Saving model ...\n",
            "Epoch 16, Batch 1 loss: 4.804114\n",
            "Epoch 16, Batch 101 loss: 6.771634\n",
            "Epoch 16, Batch 201 loss: 6.179471\n",
            "Epoch: 16 \tTraining Loss: 6.272060 \tValidation Loss: 8.563998\n",
            "Epoch 17, Batch 1 loss: 2.510838\n",
            "Epoch 17, Batch 101 loss: 6.725030\n",
            "Epoch 17, Batch 201 loss: 6.650770\n",
            "Epoch: 17 \tTraining Loss: 6.572847 \tValidation Loss: 8.470005\n",
            "Epoch 18, Batch 1 loss: 16.430859\n",
            "Epoch 18, Batch 101 loss: 6.162516\n",
            "Epoch 18, Batch 201 loss: 6.058902\n",
            "Epoch: 18 \tTraining Loss: 6.071696 \tValidation Loss: 7.865145\n",
            "Validation loss decreased (8.134593 --> 7.865145).  Saving model ...\n",
            "Epoch 19, Batch 1 loss: 5.952505\n",
            "Epoch 19, Batch 101 loss: 6.658424\n",
            "Epoch 19, Batch 201 loss: 6.319182\n",
            "Epoch: 19 \tTraining Loss: 6.266274 \tValidation Loss: 7.948525\n",
            "Epoch 20, Batch 1 loss: 8.779897\n",
            "Epoch 20, Batch 101 loss: 6.581100\n",
            "Epoch 20, Batch 201 loss: 6.186440\n",
            "Epoch: 20 \tTraining Loss: 6.227753 \tValidation Loss: 8.126539\n",
            "----------------------Final CV loss: 7.391855 -----------------------\n",
            "drive/MyDrive/DL_Project/cv/CNN3/1/predictions.zip\n",
            "created folder :  drive/MyDrive/DL_Project/cv/CNN3/2/\n",
            "2 (<class '__main__.CNN33'>, SmoothL1Loss(), 0.0005) drive/MyDrive/DL_Project/cv/CNN3/2/\n",
            "CV - Fold  0\n",
            "created folder :  drive/MyDrive/DL_Project/cv/CNN3/2/0/\n",
            "Epoch 1, Batch 1 loss: 7.607150\n",
            "Epoch 1, Batch 101 loss: 18.436476\n",
            "Epoch 1, Batch 201 loss: 18.298819\n",
            "Epoch: 1 \tTraining Loss: 18.562223 \tValidation Loss: 13.486130\n",
            "Validation loss decreased (inf --> 13.486130).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 6.968251\n",
            "Epoch 2, Batch 101 loss: 18.477365\n",
            "Epoch 2, Batch 201 loss: 18.165077\n",
            "Epoch: 2 \tTraining Loss: 18.479507 \tValidation Loss: 13.397305\n",
            "Validation loss decreased (13.486130 --> 13.397305).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 5.717840\n",
            "Epoch 3, Batch 101 loss: 17.021395\n",
            "Epoch 3, Batch 201 loss: 18.052555\n",
            "Epoch: 3 \tTraining Loss: 18.402569 \tValidation Loss: 13.286529\n",
            "Validation loss decreased (13.397305 --> 13.286529).  Saving model ...\n",
            "Epoch 4, Batch 1 loss: 6.246453\n",
            "Epoch 4, Batch 101 loss: 17.514168\n",
            "Epoch 4, Batch 201 loss: 18.229889\n",
            "Epoch: 4 \tTraining Loss: 18.351076 \tValidation Loss: 13.233280\n",
            "Validation loss decreased (13.286529 --> 13.233280).  Saving model ...\n",
            "Epoch 5, Batch 1 loss: 22.195337\n",
            "Epoch 5, Batch 101 loss: 18.036911\n",
            "Epoch 5, Batch 201 loss: 18.133078\n",
            "Epoch: 5 \tTraining Loss: 18.260271 \tValidation Loss: 13.144996\n",
            "Validation loss decreased (13.233280 --> 13.144996).  Saving model ...\n",
            "Epoch 6, Batch 1 loss: 26.978649\n",
            "Epoch 6, Batch 101 loss: 18.584774\n",
            "Epoch 6, Batch 201 loss: 18.118662\n",
            "Epoch: 6 \tTraining Loss: 18.210104 \tValidation Loss: 13.064281\n",
            "Validation loss decreased (13.144996 --> 13.064281).  Saving model ...\n",
            "Epoch 7, Batch 1 loss: 38.391815\n",
            "Epoch 7, Batch 101 loss: 17.644291\n",
            "Epoch 7, Batch 201 loss: 17.787788\n",
            "Epoch: 7 \tTraining Loss: 18.163465 \tValidation Loss: 12.994510\n",
            "Validation loss decreased (13.064281 --> 12.994510).  Saving model ...\n",
            "Epoch 8, Batch 1 loss: 12.750913\n",
            "Epoch 8, Batch 101 loss: 18.131388\n",
            "Epoch 8, Batch 201 loss: 18.112547\n",
            "Epoch: 8 \tTraining Loss: 18.145605 \tValidation Loss: 12.932921\n",
            "Validation loss decreased (12.994510 --> 12.932921).  Saving model ...\n",
            "Epoch 9, Batch 1 loss: 24.653038\n",
            "Epoch 9, Batch 101 loss: 17.768070\n",
            "Epoch 9, Batch 201 loss: 18.062428\n",
            "Epoch: 9 \tTraining Loss: 18.071407 \tValidation Loss: 12.867722\n",
            "Validation loss decreased (12.932921 --> 12.867722).  Saving model ...\n",
            "Epoch 10, Batch 1 loss: 12.424404\n",
            "Epoch 10, Batch 101 loss: 17.538605\n",
            "Epoch 10, Batch 201 loss: 18.058031\n",
            "Epoch: 10 \tTraining Loss: 18.040869 \tValidation Loss: 12.808157\n",
            "Validation loss decreased (12.867722 --> 12.808157).  Saving model ...\n",
            "Epoch 11, Batch 1 loss: 30.793968\n",
            "Epoch 11, Batch 101 loss: 18.354023\n",
            "Epoch 11, Batch 201 loss: 17.836613\n",
            "Epoch: 11 \tTraining Loss: 17.992563 \tValidation Loss: 12.763204\n",
            "Validation loss decreased (12.808157 --> 12.763204).  Saving model ...\n",
            "Epoch 12, Batch 1 loss: 20.995695\n",
            "Epoch 12, Batch 101 loss: 19.670225\n",
            "Epoch 12, Batch 201 loss: 17.929741\n",
            "Epoch: 12 \tTraining Loss: 17.954229 \tValidation Loss: 12.690530\n",
            "Validation loss decreased (12.763204 --> 12.690530).  Saving model ...\n",
            "Epoch 13, Batch 1 loss: 12.533137\n",
            "Epoch 13, Batch 101 loss: 18.477587\n",
            "Epoch 13, Batch 201 loss: 18.216675\n",
            "Epoch: 13 \tTraining Loss: 17.917454 \tValidation Loss: 12.634403\n",
            "Validation loss decreased (12.690530 --> 12.634403).  Saving model ...\n",
            "Epoch 14, Batch 1 loss: 22.863850\n",
            "Epoch 14, Batch 101 loss: 17.456076\n",
            "Epoch 14, Batch 201 loss: 18.072704\n",
            "Epoch: 14 \tTraining Loss: 17.876297 \tValidation Loss: 12.579732\n",
            "Validation loss decreased (12.634403 --> 12.579732).  Saving model ...\n",
            "Epoch 15, Batch 1 loss: 34.128403\n",
            "Epoch 15, Batch 101 loss: 16.760494\n",
            "Epoch 15, Batch 201 loss: 17.789719\n",
            "Epoch: 15 \tTraining Loss: 17.854263 \tValidation Loss: 12.529599\n",
            "Validation loss decreased (12.579732 --> 12.529599).  Saving model ...\n",
            "Epoch 16, Batch 1 loss: 16.909534\n",
            "Epoch 16, Batch 101 loss: 17.685600\n",
            "Epoch 16, Batch 201 loss: 17.174149\n",
            "Epoch: 16 \tTraining Loss: 17.843384 \tValidation Loss: 12.495604\n",
            "Validation loss decreased (12.529599 --> 12.495604).  Saving model ...\n",
            "Epoch 17, Batch 1 loss: 19.859579\n",
            "Epoch 17, Batch 101 loss: 17.774908\n",
            "Epoch 17, Batch 201 loss: 17.840597\n",
            "Epoch: 17 \tTraining Loss: 17.779783 \tValidation Loss: 12.444567\n",
            "Validation loss decreased (12.495604 --> 12.444567).  Saving model ...\n",
            "Epoch 18, Batch 1 loss: 37.028503\n",
            "Epoch 18, Batch 101 loss: 18.803322\n",
            "Epoch 18, Batch 201 loss: 18.079140\n",
            "Epoch: 18 \tTraining Loss: 17.757925 \tValidation Loss: 12.414689\n",
            "Validation loss decreased (12.444567 --> 12.414689).  Saving model ...\n",
            "Epoch 19, Batch 1 loss: 7.942883\n",
            "Epoch 19, Batch 101 loss: 17.257942\n",
            "Epoch 19, Batch 201 loss: 17.347445\n",
            "Epoch: 19 \tTraining Loss: 17.723106 \tValidation Loss: 12.338521\n",
            "Validation loss decreased (12.414689 --> 12.338521).  Saving model ...\n",
            "Epoch 20, Batch 1 loss: 16.337881\n",
            "Epoch 20, Batch 101 loss: 17.283876\n",
            "Epoch 20, Batch 201 loss: 17.858366\n",
            "Epoch: 20 \tTraining Loss: 17.691988 \tValidation Loss: 12.306212\n",
            "Validation loss decreased (12.338521 --> 12.306212).  Saving model ...\n",
            "CV - Fold  1\n",
            "created folder :  drive/MyDrive/DL_Project/cv/CNN3/2/1/\n",
            "Epoch 1, Batch 1 loss: 3.308037\n",
            "Epoch 1, Batch 101 loss: 12.532096\n",
            "Epoch 1, Batch 201 loss: 11.417360\n",
            "Epoch: 1 \tTraining Loss: 10.587973 \tValidation Loss: 10.050007\n",
            "Validation loss decreased (inf --> 10.050007).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 4.644145\n",
            "Epoch 2, Batch 101 loss: 7.773985\n",
            "Epoch 2, Batch 201 loss: 7.624918\n",
            "Epoch: 2 \tTraining Loss: 7.776984 \tValidation Loss: 11.397605\n",
            "Epoch 3, Batch 1 loss: 16.654354\n",
            "Epoch 3, Batch 101 loss: 7.095720\n",
            "Epoch 3, Batch 201 loss: 7.273433\n",
            "Epoch: 3 \tTraining Loss: 7.178021 \tValidation Loss: 7.715096\n",
            "Validation loss decreased (10.050007 --> 7.715096).  Saving model ...\n",
            "Epoch 4, Batch 1 loss: 9.563824\n",
            "Epoch 4, Batch 101 loss: 6.574262\n",
            "Epoch 4, Batch 201 loss: 6.343560\n",
            "Epoch: 4 \tTraining Loss: 6.520548 \tValidation Loss: 8.980195\n",
            "Epoch 5, Batch 1 loss: 4.149199\n",
            "Epoch 5, Batch 101 loss: 6.813119\n",
            "Epoch 5, Batch 201 loss: 6.503834\n",
            "Epoch: 5 \tTraining Loss: 6.313630 \tValidation Loss: 8.323064\n",
            "Epoch 6, Batch 1 loss: 9.862155\n",
            "Epoch 6, Batch 101 loss: 6.087932\n",
            "Epoch 6, Batch 201 loss: 6.090702\n",
            "Epoch: 6 \tTraining Loss: 6.211120 \tValidation Loss: 9.177516\n",
            "Epoch 7, Batch 1 loss: 4.332075\n",
            "Epoch 7, Batch 101 loss: 5.793163\n",
            "Epoch 7, Batch 201 loss: 5.792747\n",
            "Epoch: 7 \tTraining Loss: 5.773562 \tValidation Loss: 8.416806\n",
            "Epoch 8, Batch 1 loss: 4.917536\n",
            "Epoch 8, Batch 101 loss: 5.810724\n",
            "Epoch 8, Batch 201 loss: 5.642778\n",
            "Epoch: 8 \tTraining Loss: 5.674206 \tValidation Loss: 8.060479\n",
            "Epoch 9, Batch 1 loss: 5.403722\n",
            "Epoch 9, Batch 101 loss: 5.736001\n",
            "Epoch 9, Batch 201 loss: 5.599038\n",
            "Epoch: 9 \tTraining Loss: 5.660905 \tValidation Loss: 9.714046\n",
            "Epoch 10, Batch 1 loss: 4.310784\n",
            "Epoch 10, Batch 101 loss: 5.454872\n",
            "Epoch 10, Batch 201 loss: 5.221383\n",
            "Epoch: 10 \tTraining Loss: 5.195611 \tValidation Loss: 7.263187\n",
            "Validation loss decreased (7.715096 --> 7.263187).  Saving model ...\n",
            "Epoch 11, Batch 1 loss: 4.705049\n",
            "Epoch 11, Batch 101 loss: 5.484141\n",
            "Epoch 11, Batch 201 loss: 5.025322\n",
            "Epoch: 11 \tTraining Loss: 5.156179 \tValidation Loss: 7.795452\n",
            "Epoch 12, Batch 1 loss: 3.184700\n",
            "Epoch 12, Batch 101 loss: 5.051600\n",
            "Epoch 12, Batch 201 loss: 5.076817\n",
            "Epoch: 12 \tTraining Loss: 4.944866 \tValidation Loss: 7.717385\n",
            "Epoch 13, Batch 1 loss: 3.983948\n",
            "Epoch 13, Batch 101 loss: 4.950686\n",
            "Epoch 13, Batch 201 loss: 4.748396\n",
            "Epoch: 13 \tTraining Loss: 4.859886 \tValidation Loss: 7.805013\n",
            "Epoch 14, Batch 1 loss: 6.809325\n",
            "Epoch 14, Batch 101 loss: 4.478788\n",
            "Epoch 14, Batch 201 loss: 4.677562\n",
            "Epoch: 14 \tTraining Loss: 4.608011 \tValidation Loss: 7.174686\n",
            "Validation loss decreased (7.263187 --> 7.174686).  Saving model ...\n",
            "Epoch 15, Batch 1 loss: 4.766993\n",
            "Epoch 15, Batch 101 loss: 4.389090\n",
            "Epoch 15, Batch 201 loss: 4.683218\n",
            "Epoch: 15 \tTraining Loss: 4.707700 \tValidation Loss: 7.249834\n",
            "Epoch 16, Batch 1 loss: 2.844501\n",
            "Epoch 16, Batch 101 loss: 4.406159\n",
            "Epoch 16, Batch 201 loss: 4.406854\n",
            "Epoch: 16 \tTraining Loss: 4.444894 \tValidation Loss: 7.461526\n",
            "Epoch 17, Batch 1 loss: 3.817226\n",
            "Epoch 17, Batch 101 loss: 4.338383\n",
            "Epoch 17, Batch 201 loss: 4.378891\n",
            "Epoch: 17 \tTraining Loss: 4.367906 \tValidation Loss: 9.473565\n",
            "Epoch 18, Batch 1 loss: 2.662032\n",
            "Epoch 18, Batch 101 loss: 4.079799\n",
            "Epoch 18, Batch 201 loss: 4.208010\n",
            "Epoch: 18 \tTraining Loss: 4.334711 \tValidation Loss: 7.429224\n",
            "Epoch 19, Batch 1 loss: 4.763186\n",
            "Epoch 19, Batch 101 loss: 4.009800\n",
            "Epoch 19, Batch 201 loss: 4.160132\n",
            "Epoch: 19 \tTraining Loss: 4.117388 \tValidation Loss: 7.490175\n",
            "Epoch 20, Batch 1 loss: 2.741595\n",
            "Epoch 20, Batch 101 loss: 4.091931\n",
            "Epoch 20, Batch 201 loss: 4.270727\n",
            "Epoch: 20 \tTraining Loss: 4.252651 \tValidation Loss: 7.654941\n",
            "CV - Fold  2\n",
            "created folder :  drive/MyDrive/DL_Project/cv/CNN3/2/2/\n",
            "Epoch 1, Batch 1 loss: 25.451153\n",
            "Epoch 1, Batch 101 loss: 14.021387\n",
            "Epoch 1, Batch 201 loss: 12.233141\n",
            "Epoch: 1 \tTraining Loss: 11.400766 \tValidation Loss: 7.560127\n",
            "Validation loss decreased (inf --> 7.560127).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 10.887506\n",
            "Epoch 2, Batch 101 loss: 9.390759\n",
            "Epoch 2, Batch 201 loss: 9.269036\n",
            "Epoch: 2 \tTraining Loss: 9.310095 \tValidation Loss: 8.636243\n",
            "Epoch 3, Batch 1 loss: 6.111086\n",
            "Epoch 3, Batch 101 loss: 8.240684\n",
            "Epoch 3, Batch 201 loss: 8.321894\n",
            "Epoch: 3 \tTraining Loss: 8.213692 \tValidation Loss: 7.862575\n",
            "Epoch 4, Batch 1 loss: 16.606951\n",
            "Epoch 4, Batch 101 loss: 8.838013\n",
            "Epoch 4, Batch 201 loss: 8.729440\n",
            "Epoch: 4 \tTraining Loss: 8.575284 \tValidation Loss: 8.330268\n",
            "Epoch 5, Batch 1 loss: 9.561934\n",
            "Epoch 5, Batch 101 loss: 8.001065\n",
            "Epoch 5, Batch 201 loss: 7.889750\n",
            "Epoch: 5 \tTraining Loss: 7.903161 \tValidation Loss: 8.356366\n",
            "Epoch 6, Batch 1 loss: 9.014893\n",
            "Epoch 6, Batch 101 loss: 7.343776\n",
            "Epoch 6, Batch 201 loss: 7.698451\n",
            "Epoch: 6 \tTraining Loss: 7.637929 \tValidation Loss: 8.028286\n",
            "Epoch 7, Batch 1 loss: 4.163202\n",
            "Epoch 7, Batch 101 loss: 7.825935\n",
            "Epoch 7, Batch 201 loss: 7.906223\n",
            "Epoch: 7 \tTraining Loss: 7.943171 \tValidation Loss: 7.962297\n",
            "Epoch 8, Batch 1 loss: 3.275475\n",
            "Epoch 8, Batch 101 loss: 7.562486\n",
            "Epoch 8, Batch 201 loss: 7.224780\n",
            "Epoch: 8 \tTraining Loss: 7.138212 \tValidation Loss: 7.204629\n",
            "Validation loss decreased (7.560127 --> 7.204629).  Saving model ...\n",
            "Epoch 9, Batch 1 loss: 8.382852\n",
            "Epoch 9, Batch 101 loss: 7.214949\n",
            "Epoch 9, Batch 201 loss: 7.289480\n",
            "Epoch: 9 \tTraining Loss: 7.409076 \tValidation Loss: 8.082766\n",
            "Epoch 10, Batch 1 loss: 8.848352\n",
            "Epoch 10, Batch 101 loss: 7.358541\n",
            "Epoch 10, Batch 201 loss: 7.329612\n",
            "Epoch: 10 \tTraining Loss: 7.356255 \tValidation Loss: 7.428028\n",
            "Epoch 11, Batch 1 loss: 4.700340\n",
            "Epoch 11, Batch 101 loss: 6.738028\n",
            "Epoch 11, Batch 201 loss: 6.848214\n",
            "Epoch: 11 \tTraining Loss: 7.105148 \tValidation Loss: 8.062661\n",
            "Epoch 12, Batch 1 loss: 8.534622\n",
            "Epoch 12, Batch 101 loss: 6.866436\n",
            "Epoch 12, Batch 201 loss: 6.928359\n",
            "Epoch: 12 \tTraining Loss: 6.896888 \tValidation Loss: 7.318633\n",
            "Epoch 13, Batch 1 loss: 9.171532\n",
            "Epoch 13, Batch 101 loss: 6.601760\n",
            "Epoch 13, Batch 201 loss: 7.137354\n",
            "Epoch: 13 \tTraining Loss: 6.906942 \tValidation Loss: 7.150988\n",
            "Validation loss decreased (7.204629 --> 7.150988).  Saving model ...\n",
            "Epoch 14, Batch 1 loss: 5.207014\n",
            "Epoch 14, Batch 101 loss: 6.908868\n",
            "Epoch 14, Batch 201 loss: 6.894190\n",
            "Epoch: 14 \tTraining Loss: 7.075930 \tValidation Loss: 7.560598\n",
            "Epoch 15, Batch 1 loss: 5.294736\n",
            "Epoch 15, Batch 101 loss: 6.697254\n",
            "Epoch 15, Batch 201 loss: 6.820194\n",
            "Epoch: 15 \tTraining Loss: 6.740881 \tValidation Loss: 7.539942\n",
            "Epoch 16, Batch 1 loss: 8.864227\n",
            "Epoch 16, Batch 101 loss: 6.541416\n",
            "Epoch 16, Batch 201 loss: 6.892359\n",
            "Epoch: 16 \tTraining Loss: 6.854926 \tValidation Loss: 6.880121\n",
            "Validation loss decreased (7.150988 --> 6.880121).  Saving model ...\n",
            "Epoch 17, Batch 1 loss: 5.923707\n",
            "Epoch 17, Batch 101 loss: 7.274268\n",
            "Epoch 17, Batch 201 loss: 7.317198\n",
            "Epoch: 17 \tTraining Loss: 6.993947 \tValidation Loss: 7.419395\n",
            "Epoch 18, Batch 1 loss: 8.557487\n",
            "Epoch 18, Batch 101 loss: 6.271871\n",
            "Epoch 18, Batch 201 loss: 6.766466\n",
            "Epoch: 18 \tTraining Loss: 6.700651 \tValidation Loss: 7.209953\n",
            "Epoch 19, Batch 1 loss: 4.881717\n",
            "Epoch 19, Batch 101 loss: 6.681272\n",
            "Epoch 19, Batch 201 loss: 6.611913\n",
            "Epoch: 19 \tTraining Loss: 6.725031 \tValidation Loss: 7.994303\n",
            "Epoch 20, Batch 1 loss: 6.309397\n",
            "Epoch 20, Batch 101 loss: 6.373213\n",
            "Epoch 20, Batch 201 loss: 6.335532\n",
            "Epoch: 20 \tTraining Loss: 6.391642 \tValidation Loss: 7.540189\n",
            "CV - Fold  3\n",
            "created folder :  drive/MyDrive/DL_Project/cv/CNN3/2/3/\n",
            "Epoch 1, Batch 1 loss: 7.100471\n",
            "Epoch 1, Batch 101 loss: 14.926872\n",
            "Epoch 1, Batch 201 loss: 12.450608\n",
            "Epoch: 1 \tTraining Loss: 11.840315 \tValidation Loss: 9.520733\n",
            "Validation loss decreased (inf --> 9.520733).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 6.173717\n",
            "Epoch 2, Batch 101 loss: 8.161250\n",
            "Epoch 2, Batch 201 loss: 8.388300\n",
            "Epoch: 2 \tTraining Loss: 8.501557 \tValidation Loss: 10.256221\n",
            "Epoch 3, Batch 1 loss: 2.980241\n",
            "Epoch 3, Batch 101 loss: 7.859693\n",
            "Epoch 3, Batch 201 loss: 8.078331\n",
            "Epoch: 3 \tTraining Loss: 7.854054 \tValidation Loss: 10.804815\n",
            "Epoch 4, Batch 1 loss: 5.218072\n",
            "Epoch 4, Batch 101 loss: 8.534049\n",
            "Epoch 4, Batch 201 loss: 8.127378\n",
            "Epoch: 4 \tTraining Loss: 7.806715 \tValidation Loss: 9.948349\n",
            "Epoch 5, Batch 1 loss: 19.694818\n",
            "Epoch 5, Batch 101 loss: 8.249559\n",
            "Epoch 5, Batch 201 loss: 7.910193\n",
            "Epoch: 5 \tTraining Loss: 7.858617 \tValidation Loss: 8.784891\n",
            "Validation loss decreased (9.520733 --> 8.784891).  Saving model ...\n",
            "Epoch 6, Batch 1 loss: 10.782656\n",
            "Epoch 6, Batch 101 loss: 7.320685\n",
            "Epoch 6, Batch 201 loss: 7.408103\n",
            "Epoch: 6 \tTraining Loss: 7.379662 \tValidation Loss: 9.159898\n",
            "Epoch 7, Batch 1 loss: 4.932543\n",
            "Epoch 7, Batch 101 loss: 6.712319\n",
            "Epoch 7, Batch 201 loss: 6.732713\n",
            "Epoch: 7 \tTraining Loss: 6.961010 \tValidation Loss: 10.517935\n",
            "Epoch 8, Batch 1 loss: 6.979456\n",
            "Epoch 8, Batch 101 loss: 6.649052\n",
            "Epoch 8, Batch 201 loss: 7.016613\n",
            "Epoch: 8 \tTraining Loss: 6.852530 \tValidation Loss: 9.777728\n",
            "Epoch 9, Batch 1 loss: 20.379211\n",
            "Epoch 9, Batch 101 loss: 7.000218\n",
            "Epoch 9, Batch 201 loss: 7.373010\n",
            "Epoch: 9 \tTraining Loss: 7.188993 \tValidation Loss: 9.203380\n",
            "Epoch 10, Batch 1 loss: 7.041855\n",
            "Epoch 10, Batch 101 loss: 7.352320\n",
            "Epoch 10, Batch 201 loss: 6.844093\n",
            "Epoch: 10 \tTraining Loss: 7.055724 \tValidation Loss: 11.787147\n",
            "Epoch 11, Batch 1 loss: 9.249429\n",
            "Epoch 11, Batch 101 loss: 6.931211\n",
            "Epoch 11, Batch 201 loss: 6.711362\n",
            "Epoch: 11 \tTraining Loss: 6.730347 \tValidation Loss: 8.429786\n",
            "Validation loss decreased (8.784891 --> 8.429786).  Saving model ...\n",
            "Epoch 12, Batch 1 loss: 4.439193\n",
            "Epoch 12, Batch 101 loss: 6.645477\n",
            "Epoch 12, Batch 201 loss: 6.623876\n",
            "Epoch: 12 \tTraining Loss: 6.594166 \tValidation Loss: 8.490376\n",
            "Epoch 13, Batch 1 loss: 10.309763\n",
            "Epoch 13, Batch 101 loss: 6.165119\n",
            "Epoch 13, Batch 201 loss: 6.350636\n",
            "Epoch: 13 \tTraining Loss: 6.286307 \tValidation Loss: 8.729650\n",
            "Epoch 14, Batch 1 loss: 5.235849\n",
            "Epoch 14, Batch 101 loss: 6.417576\n",
            "Epoch 14, Batch 201 loss: 6.488291\n",
            "Epoch: 14 \tTraining Loss: 6.627540 \tValidation Loss: 8.623361\n",
            "Epoch 15, Batch 1 loss: 5.178700\n",
            "Epoch 15, Batch 101 loss: 6.491879\n",
            "Epoch 15, Batch 201 loss: 6.564466\n",
            "Epoch: 15 \tTraining Loss: 6.366902 \tValidation Loss: 9.090889\n",
            "Epoch 16, Batch 1 loss: 9.330474\n",
            "Epoch 16, Batch 101 loss: 6.547018\n",
            "Epoch 16, Batch 201 loss: 6.451585\n",
            "Epoch: 16 \tTraining Loss: 6.468217 \tValidation Loss: 8.523039\n",
            "Epoch 17, Batch 1 loss: 6.006043\n",
            "Epoch 17, Batch 101 loss: 6.184528\n",
            "Epoch 17, Batch 201 loss: 6.143822\n",
            "Epoch: 17 \tTraining Loss: 6.205194 \tValidation Loss: 8.712996\n",
            "Epoch 18, Batch 1 loss: 2.587300\n",
            "Epoch 18, Batch 101 loss: 6.822632\n",
            "Epoch 18, Batch 201 loss: 6.351913\n",
            "Epoch: 18 \tTraining Loss: 6.335761 \tValidation Loss: 8.126009\n",
            "Validation loss decreased (8.429786 --> 8.126009).  Saving model ...\n",
            "Epoch 19, Batch 1 loss: 5.541461\n",
            "Epoch 19, Batch 101 loss: 6.324796\n",
            "Epoch 19, Batch 201 loss: 6.570109\n",
            "Epoch: 19 \tTraining Loss: 6.426588 \tValidation Loss: 9.307176\n",
            "Epoch 20, Batch 1 loss: 3.474709\n",
            "Epoch 20, Batch 101 loss: 6.168791\n",
            "Epoch 20, Batch 201 loss: 5.933017\n",
            "Epoch: 20 \tTraining Loss: 5.918073 \tValidation Loss: 8.568716\n",
            "----------------------Final CV loss: 8.621758 -----------------------\n",
            "drive/MyDrive/DL_Project/cv/CNN3/2/predictions.zip\n"
          ]
        }
      ],
      "source": [
        "from itertools import product, chain\n",
        "import os\n",
        "\n",
        "comp_model = []\n",
        "comp_valid_loss = []\n",
        "comp_valid_trend = []\n",
        "log = pd.DataFrame(columns=['num','model','criterion','adam_lr','directory'])\n",
        "root = 'drive/MyDrive/DL_Project/cv/CNN3/'\n",
        "\n",
        "# for n, (model,cri,lr) in enumerate(product(model_set,cri_set, optim_lr))[1:]:\n",
        "for n, pars in enumerate(product(model_set,cri_set, optim_lr)):\n",
        "    # if n ==0:\n",
        "    #   continue\n",
        "\n",
        "    # freeze_stat = True\n",
        "    # model_CNN = model(pretrained=True,freeze=freeze_stat).to(device)\n",
        "    # criterion = cri\n",
        "    # model_CNN_grad_paramaters = filter(lambda p: p.requires_grad, model_CNN.parameters())\n",
        "    # optimizer = optim.Adam(model_CNN_grad_paramaters, lr=lr)\n",
        "\n",
        "    dir = root+str(n)+'/'\n",
        "    if not os.path.isdir(dir):\n",
        "      os.makedirs(dir)\n",
        "      print(\"created folder : \", dir)\n",
        "    else:\n",
        "      print(dir, \"folder already exists.\")\n",
        "\n",
        "    print(n,pars,dir)\n",
        "\n",
        "    model_conv, valid_loss_min, valid_loss_trend = cv_train(pars,k=4,dir = dir,n_epochs=20)\n",
        "\n",
        "    # save test result\n",
        "    save_test_cv(model_conv,dir)\n",
        "    \n",
        "    # value_val_loss = valid_loss_min.cpu().data()\n",
        "    model,cri,lr = pars\n",
        "    row = pd.Series([n,model,cri,lr,dir],index=log.columns)\n",
        "    log = log.append(row,ignore_index=True)\n",
        "\n",
        "    # comp_idx = comp_idx.append(n)\n",
        "    # comp_idx_model = comp_idx_model.append(model)\n",
        "    # comp_cri = comp_cri.append(cri)\n",
        "    # comp_optim = comp_optim.append(optim)\n",
        "\n",
        "    comp_model.append(model_conv)\n",
        "    comp_valid_loss.append(valid_loss_min)\n",
        "    comp_valid_trend.append(valid_loss_trend)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Uk6wbvSwWAv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "247c179e-c3a0-478c-ddb4-345a775aa78d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  num                     model       criterion  adam_lr  \\\n",
              "0   0  <class '__main__.CNN31'>  SmoothL1Loss()   0.0005   \n",
              "1   1  <class '__main__.CNN32'>  SmoothL1Loss()   0.0005   \n",
              "2   2  <class '__main__.CNN33'>  SmoothL1Loss()   0.0005   \n",
              "\n",
              "                             directory  mean_val_loss  \n",
              "0  drive/MyDrive/DL_Project/cv/CNN3/0/       7.187867  \n",
              "1  drive/MyDrive/DL_Project/cv/CNN3/1/       7.391855  \n",
              "2  drive/MyDrive/DL_Project/cv/CNN3/2/       8.621758  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81c5d546-67a7-4f40-953f-cf1ed60dbf53\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num</th>\n",
              "      <th>model</th>\n",
              "      <th>criterion</th>\n",
              "      <th>adam_lr</th>\n",
              "      <th>directory</th>\n",
              "      <th>mean_val_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>&lt;class '__main__.CNN31'&gt;</td>\n",
              "      <td>SmoothL1Loss()</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>drive/MyDrive/DL_Project/cv/CNN3/0/</td>\n",
              "      <td>7.187867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>&lt;class '__main__.CNN32'&gt;</td>\n",
              "      <td>SmoothL1Loss()</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>drive/MyDrive/DL_Project/cv/CNN3/1/</td>\n",
              "      <td>7.391855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>&lt;class '__main__.CNN33'&gt;</td>\n",
              "      <td>SmoothL1Loss()</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>drive/MyDrive/DL_Project/cv/CNN3/2/</td>\n",
              "      <td>8.621758</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81c5d546-67a7-4f40-953f-cf1ed60dbf53')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81c5d546-67a7-4f40-953f-cf1ed60dbf53 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81c5d546-67a7-4f40-953f-cf1ed60dbf53');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "val_loss = []\n",
        "for idx in range(len(comp_valid_loss)):\n",
        "  mean_val_loss = torch.stack(comp_valid_loss[idx]).cpu().data.mean()\n",
        "  val_loss.append(mean_val_loss)\n",
        "log['mean_val_loss'] = torch.stack(val_loss).tolist()\n",
        "log_path = root+'log.csv'\n",
        "log.to_csv(root+'log.csv')\n",
        "log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMJCiCG-M1Ut"
      },
      "source": [
        "## Points to note:\n",
        "\n",
        "General Rules: Participants should estimate the percentage of Covid-19 infection from each slice using Machine Learning. **Only ImageNet's pre-trained models and Lung Nodule Segmentation models are allowed**. The use of external data or other pre-trained models is not allowed. The models must be trained using the training data and evaluated using the validation data.\n",
        "\n",
        "##Things you can try:\n",
        "\n",
        "- The dataset is not as big and especially negative covid images are very few.\n",
        "It would be better to use k-fold cross validation rather than conventional splitting.\n",
        "- How would you split image splices from the same patient subject into train & val set?\n",
        "- How would the information on the patient (subject #) help your prediction?\n",
        "- What kind of preprocessing/data augmentation method help your model? What kind of methods would actually make your model perform worse?\n",
        "- What other different CNN architectures could you explore to acheive lower MAE?\n",
        "- Explore different optimizers, loss combinations, etc\n",
        "- Explore different regularization methods\n",
        "\n",
        "This is no way an exhaustive list. You might get a better idea by reading relevant research papers. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVwLtw1piBcj"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "competition_compare.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}