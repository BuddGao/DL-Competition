{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BuddGao/DL-Competition/blob/main/Competition_decoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLmZdwaRm_oK",
        "outputId": "69cb0a58-5837-42bb-d374-efdf25b47669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGwPSGYhqlV8"
      },
      "outputs": [],
      "source": [
        "#!unzip \"drive/MyDrive/DL_Project/Train.zip\" -d  \"drive/MyDrive/DL_Project/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aXA-pNEqoMn",
        "outputId": "d2591f84-38b5-4d23-815c-a8d51a808531"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: /opt/bin/nvidia-smi: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "#!unzip \"drive/MyDrive/DL_Project/Val Blind.zip\" -d  \"drive/MyDrive/DL_Project/\"\n",
        "!/opt/bin/nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "95O_gDz_qtRL"
      },
      "outputs": [],
      "source": [
        "## preprocess data\n",
        "## create custom data class\n",
        "from sklearn.model_selection import GridSearchCV, cross_validate\n",
        "from sklearn.model_selection import KFold\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "class CovidDataset(Dataset):\n",
        "    \"\"\"Covid CT dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.label_data = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        ## you can apply custom transformation on the image for data augmentation\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = os.path.join(self.root_dir, self.label_data.iloc[idx, 0])\n",
        "        image = io.imread(img_name)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR)\n",
        "        image = torchvision.transforms.functional.to_tensor(image)\n",
        "        p = self.label_data.iloc[idx, 1]\n",
        "        subject_num = self.label_data.iloc[idx, 2]\n",
        "        sample = {'image': image, 'percentage': p, 'subject': subject_num, 'img_name':img_name}\n",
        "\n",
        "        # should be only applied on image, not percentage or subject #\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mLJWR3q3rDhV"
      },
      "outputs": [],
      "source": [
        "class CovidTestDataset(Dataset):\n",
        "    \"\"\"Covid CT TEST dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.image_list = []\n",
        "        for filename in glob.glob(self.root_dir+\"/*.png\"): #assuming png\n",
        "          self.image_list.append(filename)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = self.image_list[idx]\n",
        "        image = io.imread(img_name)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR)\n",
        "        image = torchvision.transforms.functional.to_tensor(image)\n",
        "        sample = {'image': image, 'img_name':img_name}\n",
        "\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1_7VyeU-rHx3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "b47b7d56-c5d5-49da-c55b-4b954c694536"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-dc20f4329b9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m covid_dataset_train_val = CovidDataset(csv_file='drive/MyDrive/DL_Project/Train.csv',\n\u001b[0;32m----> 3\u001b[0;31m                                     \u001b[0mroot_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'drive/MyDrive/DL_Project/Train'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m                                     \u001b[0;31m#, transform = transforms.Compose([\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                     \u001b[0;31m#           Rescale(256),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-1b32b8566caf>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, csv_file, root_dir, transform)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \"\"\"\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m## you can apply custom transformation on the image for data augmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/MyDrive/DL_Project/Train.csv'"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "covid_dataset_train_val = CovidDataset(csv_file='drive/MyDrive/DL_Project/Train.csv',\n",
        "                                    root_dir='drive/MyDrive/DL_Project/Train'\n",
        "                                    #, transform = transforms.Compose([\n",
        "                                    #           Rescale(256),\n",
        "                                    #           RandomCrop(224),\n",
        "                                    #           ToTensor()\n",
        "                                    #       ])\n",
        "                                    )\n",
        "\n",
        "covid_dataset_test = CovidTestDataset(root_dir='drive/MyDrive/DL_Project/Val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "_sUEYc2trJ3x",
        "outputId": "06a56063-01db-46b8-bcb7-305c7b6508ed"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-89ac60b910e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## plot training example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovid_dataset_train_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovid_dataset_train_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'percentage'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subject'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'covid_dataset_train_val' is not defined"
          ]
        }
      ],
      "source": [
        "## plot training example\n",
        "for i in range(len(covid_dataset_train_val)):\n",
        "    sample = covid_dataset_train_val[i]\n",
        "    print(i, sample['image'].shape, sample['percentage'], sample['subject'])\n",
        "    ax = plt.subplot(1, 4, i + 1)\n",
        "    plt.tight_layout()\n",
        "    ax.set_title('Sample #{}'.format(i))\n",
        "    ax.axis('off')\n",
        "    plt.imshow(sample['image'].numpy().transpose(1,2,0))\n",
        "    if i == 3:\n",
        "        plt.show()\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "X9YhBC4BrLz5",
        "outputId": "4e794705-076f-4f80-834b-5ea0064a299c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-0488dbec08e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## plot test examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovid_dataset_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovid_dataset_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'covid_dataset_test' is not defined"
          ]
        }
      ],
      "source": [
        "## plot test examples\n",
        "for i in range(len(covid_dataset_test)):\n",
        "    sample = covid_dataset_test[i]\n",
        "    print(i, sample['image'].shape, sample['img_name'])\n",
        "    ax = plt.subplot(1, 4, i + 1)\n",
        "    plt.tight_layout()\n",
        "    ax.set_title('Sample #{}'.format(i))\n",
        "    ax.axis('off')\n",
        "    plt.imshow(sample['image'].numpy().transpose(1,2,0))\n",
        "    if i == 3:\n",
        "        plt.show()\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Frop9y5KaDU_"
      },
      "outputs": [],
      "source": [
        "# generate the index of subjects for k-fold cross validation\n",
        "def generate_index(dat,k):\n",
        "    \n",
        "    Y = list(range(0,dat[-1]['subject']+1))\n",
        "    kf = KFold(n_splits=k, shuffle=True)\n",
        "\n",
        "    n = len(Y)\n",
        "    index = {'train_index':[],\n",
        "             'val_index':[]}\n",
        "\n",
        "    for train_index, val_index in kf.split(np.zeros(n), Y):\n",
        "        index['train_index'].append(train_index)\n",
        "        index['val_index'].append(val_index)\n",
        "        \n",
        "    \n",
        "    return pd.DataFrame(index['train_index']).T,pd.DataFrame(index['val_index']).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6HvaOrrVs5sd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "5361dc57-cc2d-41d2-c88d-a864fef46e15"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-5c47cc4d3bd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get links form subjects to images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/MyDrive/DL_Project/Train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msubtoimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msub\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcovid_dataset_train_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subject'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/MyDrive/DL_Project/Train.csv'"
          ]
        }
      ],
      "source": [
        "# get links form subjects to images\n",
        "df = pd.read_csv('drive/MyDrive/DL_Project/Train.csv')\n",
        "subtoimage = []\n",
        "le = []\n",
        "for sub in range(0,covid_dataset_train_val[-1]['subject']+1):\n",
        "  subtoimage.append(df[df['0'] == sub].index.tolist())\n",
        "  le.append(len(df[df['0'] == sub].index.tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "UatrtHxvxXrG"
      },
      "outputs": [],
      "source": [
        "# get images' index form subjects' index\n",
        "def get_image_index(subindex,subtoimage):\n",
        "    imageindex = []\n",
        "    for sub in range(0,len(subindex)):\n",
        "        imageindex.extend(subtoimage[subindex[sub]])\n",
        "    return imageindex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DRgrZrWrPD4",
        "outputId": "e8231d83-e3bc-481e-83ec-d63c80757a4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pretrainedmodels in /usr/local/lib/python3.7/dist-packages (0.7.4)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels) (2.5.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels) (1.10.0+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels) (4.63.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels) (0.11.1+cu111)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from munch->pretrainedmodels) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pretrainedmodels) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->pretrainedmodels) (1.21.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->pretrainedmodels) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "## use imagenet pretrained model\n",
        "## let's start with resnet34\n",
        "!pip install pretrainedmodels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EJvpp8X3zxWo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b0734f8-f928-430f-be3f-c48ce70f5b95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'__builtins__': {'ArithmeticError': ArithmeticError,\n",
              "  'AssertionError': AssertionError,\n",
              "  'AttributeError': AttributeError,\n",
              "  'BaseException': BaseException,\n",
              "  'BlockingIOError': BlockingIOError,\n",
              "  'BrokenPipeError': BrokenPipeError,\n",
              "  'BufferError': BufferError,\n",
              "  'BytesWarning': BytesWarning,\n",
              "  'ChildProcessError': ChildProcessError,\n",
              "  'ConnectionAbortedError': ConnectionAbortedError,\n",
              "  'ConnectionError': ConnectionError,\n",
              "  'ConnectionRefusedError': ConnectionRefusedError,\n",
              "  'ConnectionResetError': ConnectionResetError,\n",
              "  'DeprecationWarning': DeprecationWarning,\n",
              "  'EOFError': EOFError,\n",
              "  'Ellipsis': Ellipsis,\n",
              "  'EnvironmentError': OSError,\n",
              "  'Exception': Exception,\n",
              "  'False': False,\n",
              "  'FileExistsError': FileExistsError,\n",
              "  'FileNotFoundError': FileNotFoundError,\n",
              "  'FloatingPointError': FloatingPointError,\n",
              "  'FutureWarning': FutureWarning,\n",
              "  'GeneratorExit': GeneratorExit,\n",
              "  'IOError': OSError,\n",
              "  'ImportError': ImportError,\n",
              "  'ImportWarning': ImportWarning,\n",
              "  'IndentationError': IndentationError,\n",
              "  'IndexError': IndexError,\n",
              "  'InterruptedError': InterruptedError,\n",
              "  'IsADirectoryError': IsADirectoryError,\n",
              "  'KeyError': KeyError,\n",
              "  'KeyboardInterrupt': KeyboardInterrupt,\n",
              "  'LookupError': LookupError,\n",
              "  'MemoryError': MemoryError,\n",
              "  'ModuleNotFoundError': ModuleNotFoundError,\n",
              "  'NameError': NameError,\n",
              "  'None': None,\n",
              "  'NotADirectoryError': NotADirectoryError,\n",
              "  'NotImplemented': NotImplemented,\n",
              "  'NotImplementedError': NotImplementedError,\n",
              "  'OSError': OSError,\n",
              "  'OverflowError': OverflowError,\n",
              "  'PendingDeprecationWarning': PendingDeprecationWarning,\n",
              "  'PermissionError': PermissionError,\n",
              "  'ProcessLookupError': ProcessLookupError,\n",
              "  'RecursionError': RecursionError,\n",
              "  'ReferenceError': ReferenceError,\n",
              "  'ResourceWarning': ResourceWarning,\n",
              "  'RuntimeError': RuntimeError,\n",
              "  'RuntimeWarning': RuntimeWarning,\n",
              "  'StopAsyncIteration': StopAsyncIteration,\n",
              "  'StopIteration': StopIteration,\n",
              "  'SyntaxError': SyntaxError,\n",
              "  'SyntaxWarning': SyntaxWarning,\n",
              "  'SystemError': SystemError,\n",
              "  'SystemExit': SystemExit,\n",
              "  'TabError': TabError,\n",
              "  'TimeoutError': TimeoutError,\n",
              "  'True': True,\n",
              "  'TypeError': TypeError,\n",
              "  'UnboundLocalError': UnboundLocalError,\n",
              "  'UnicodeDecodeError': UnicodeDecodeError,\n",
              "  'UnicodeEncodeError': UnicodeEncodeError,\n",
              "  'UnicodeError': UnicodeError,\n",
              "  'UnicodeTranslateError': UnicodeTranslateError,\n",
              "  'UnicodeWarning': UnicodeWarning,\n",
              "  'UserWarning': UserWarning,\n",
              "  'ValueError': ValueError,\n",
              "  'Warning': Warning,\n",
              "  'ZeroDivisionError': ZeroDivisionError,\n",
              "  '__IPYTHON__': True,\n",
              "  '__build_class__': <function __build_class__>,\n",
              "  '__debug__': True,\n",
              "  '__doc__': \"Built-in functions, exceptions, and other objects.\\n\\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\",\n",
              "  '__import__': <function __import__>,\n",
              "  '__loader__': _frozen_importlib.BuiltinImporter,\n",
              "  '__name__': 'builtins',\n",
              "  '__package__': '',\n",
              "  '__pybind11_internals_v3_gcc_libstdcpp_cxxabi1002__': <capsule object NULL at 0x7ff761660240>,\n",
              "  '__pybind11_internals_v4_gcc_libstdcpp_cxxabi1011__': <capsule object NULL at 0x7ff7536817e0>,\n",
              "  '__spec__': ModuleSpec(name='builtins', loader=<class '_frozen_importlib.BuiltinImporter'>),\n",
              "  'abs': <function abs>,\n",
              "  'all': <function all>,\n",
              "  'any': <function any>,\n",
              "  'ascii': <function ascii>,\n",
              "  'bin': <function bin>,\n",
              "  'bool': bool,\n",
              "  'breakpoint': <function breakpoint>,\n",
              "  'bytearray': bytearray,\n",
              "  'bytes': bytes,\n",
              "  'callable': <function callable>,\n",
              "  'chr': <function chr>,\n",
              "  'classmethod': classmethod,\n",
              "  'compile': <function compile>,\n",
              "  'complex': complex,\n",
              "  'copyright': Copyright (c) 2001-2021 Python Software Foundation.\n",
              "  All Rights Reserved.\n",
              "  \n",
              "  Copyright (c) 2000 BeOpen.com.\n",
              "  All Rights Reserved.\n",
              "  \n",
              "  Copyright (c) 1995-2001 Corporation for National Research Initiatives.\n",
              "  All Rights Reserved.\n",
              "  \n",
              "  Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\n",
              "  All Rights Reserved.,\n",
              "  'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n",
              "      for supporting Python development.  See www.python.org for more information.,\n",
              "  'delattr': <function delattr>,\n",
              "  'dict': dict,\n",
              "  'dir': <function dir>,\n",
              "  'display': <function IPython.core.display.display>,\n",
              "  'divmod': <function divmod>,\n",
              "  'dreload': <function IPython.lib.deepreload._dreload>,\n",
              "  'enumerate': enumerate,\n",
              "  'eval': <function eval>,\n",
              "  'exec': <function exec>,\n",
              "  'execfile': <function _pydev_imps._pydev_execfile.execfile>,\n",
              "  'filter': filter,\n",
              "  'float': float,\n",
              "  'format': <function format>,\n",
              "  'frozenset': frozenset,\n",
              "  'get_ipython': <bound method InteractiveShell.get_ipython of <google.colab._shell.Shell object at 0x7ff7711ce0d0>>,\n",
              "  'getattr': <function getattr>,\n",
              "  'globals': <function globals>,\n",
              "  'hasattr': <function hasattr>,\n",
              "  'hash': <function hash>,\n",
              "  'help': Type help() for interactive help, or help(object) for help about object.,\n",
              "  'hex': <function hex>,\n",
              "  'id': <function id>,\n",
              "  'input': <bound method Kernel.raw_input of <google.colab._kernel.Kernel object at 0x7ff773c2d110>>,\n",
              "  'int': int,\n",
              "  'isinstance': <function isinstance>,\n",
              "  'issubclass': <function issubclass>,\n",
              "  'iter': <function iter>,\n",
              "  'len': <function len>,\n",
              "  'license': Type license() to see the full license text,\n",
              "  'list': list,\n",
              "  'locals': <function locals>,\n",
              "  'map': map,\n",
              "  'max': <function max>,\n",
              "  'memoryview': memoryview,\n",
              "  'min': <function min>,\n",
              "  'next': <function next>,\n",
              "  'object': object,\n",
              "  'oct': <function oct>,\n",
              "  'open': <function io.open>,\n",
              "  'ord': <function ord>,\n",
              "  'pow': <function pow>,\n",
              "  'print': <function print>,\n",
              "  'property': property,\n",
              "  'range': range,\n",
              "  'repr': <function repr>,\n",
              "  'reversed': reversed,\n",
              "  'round': <function round>,\n",
              "  'runfile': <function _pydev_bundle.pydev_umd.runfile>,\n",
              "  'set': set,\n",
              "  'setattr': <function setattr>,\n",
              "  'slice': slice,\n",
              "  'sorted': <function sorted>,\n",
              "  'staticmethod': staticmethod,\n",
              "  'str': str,\n",
              "  'sum': <function sum>,\n",
              "  'super': super,\n",
              "  'tuple': tuple,\n",
              "  'type': type,\n",
              "  'vars': <function vars>,\n",
              "  'zip': zip},\n",
              " '__cached__': '/usr/local/lib/python3.7/dist-packages/pretrainedmodels/__pycache__/__init__.cpython-37.pyc',\n",
              " '__doc__': None,\n",
              " '__file__': '/usr/local/lib/python3.7/dist-packages/pretrainedmodels/__init__.py',\n",
              " '__loader__': <_frozen_importlib_external.SourceFileLoader at 0x7ff63d909ed0>,\n",
              " '__name__': 'pretrainedmodels',\n",
              " '__package__': 'pretrainedmodels',\n",
              " '__path__': ['/usr/local/lib/python3.7/dist-packages/pretrainedmodels'],\n",
              " '__spec__': ModuleSpec(name='pretrainedmodels', loader=<_frozen_importlib_external.SourceFileLoader object at 0x7ff63d909ed0>, origin='/usr/local/lib/python3.7/dist-packages/pretrainedmodels/__init__.py', submodule_search_locations=['/usr/local/lib/python3.7/dist-packages/pretrainedmodels']),\n",
              " '__version__': '0.7.4',\n",
              " 'alexnet': <function pretrainedmodels.models.torchvision_models.alexnet>,\n",
              " 'bninception': <function pretrainedmodels.models.bninception.bninception>,\n",
              " 'cafferesnet101': <function pretrainedmodels.models.cafferesnet.cafferesnet101>,\n",
              " 'datasets': <module 'pretrainedmodels.datasets' from '/usr/local/lib/python3.7/dist-packages/pretrainedmodels/datasets/__init__.py'>,\n",
              " 'densenet121': <function pretrainedmodels.models.torchvision_models.densenet121>,\n",
              " 'densenet161': <function pretrainedmodels.models.torchvision_models.densenet161>,\n",
              " 'densenet169': <function pretrainedmodels.models.torchvision_models.densenet169>,\n",
              " 'densenet201': <function pretrainedmodels.models.torchvision_models.densenet201>,\n",
              " 'dpn107': <function pretrainedmodels.models.dpn.dpn107>,\n",
              " 'dpn131': <function pretrainedmodels.models.dpn.dpn131>,\n",
              " 'dpn68': <function pretrainedmodels.models.dpn.dpn68>,\n",
              " 'dpn68b': <function pretrainedmodels.models.dpn.dpn68b>,\n",
              " 'dpn92': <function pretrainedmodels.models.dpn.dpn92>,\n",
              " 'dpn98': <function pretrainedmodels.models.dpn.dpn98>,\n",
              " 'fbresnet152': <function pretrainedmodels.models.fbresnet.fbresnet152>,\n",
              " 'inceptionresnetv2': <function pretrainedmodels.models.inceptionresnetv2.inceptionresnetv2>,\n",
              " 'inceptionv3': <function pretrainedmodels.models.torchvision_models.inceptionv3>,\n",
              " 'inceptionv4': <function pretrainedmodels.models.inceptionv4.inceptionv4>,\n",
              " 'model_names': ['fbresnet152',\n",
              "  'bninception',\n",
              "  'resnext101_32x4d',\n",
              "  'resnext101_64x4d',\n",
              "  'inceptionv4',\n",
              "  'inceptionresnetv2',\n",
              "  'alexnet',\n",
              "  'densenet121',\n",
              "  'densenet169',\n",
              "  'densenet201',\n",
              "  'densenet161',\n",
              "  'resnet18',\n",
              "  'resnet34',\n",
              "  'resnet50',\n",
              "  'resnet101',\n",
              "  'resnet152',\n",
              "  'inceptionv3',\n",
              "  'squeezenet1_0',\n",
              "  'squeezenet1_1',\n",
              "  'vgg11',\n",
              "  'vgg11_bn',\n",
              "  'vgg13',\n",
              "  'vgg13_bn',\n",
              "  'vgg16',\n",
              "  'vgg16_bn',\n",
              "  'vgg19_bn',\n",
              "  'vgg19',\n",
              "  'nasnetamobile',\n",
              "  'nasnetalarge',\n",
              "  'dpn68',\n",
              "  'dpn68b',\n",
              "  'dpn92',\n",
              "  'dpn98',\n",
              "  'dpn131',\n",
              "  'dpn107',\n",
              "  'xception',\n",
              "  'senet154',\n",
              "  'se_resnet50',\n",
              "  'se_resnet101',\n",
              "  'se_resnet152',\n",
              "  'se_resnext50_32x4d',\n",
              "  'se_resnext101_32x4d',\n",
              "  'cafferesnet101',\n",
              "  'pnasnet5large',\n",
              "  'polynet'],\n",
              " 'models': <module 'pretrainedmodels.models' from '/usr/local/lib/python3.7/dist-packages/pretrainedmodels/models/__init__.py'>,\n",
              " 'nasnetalarge': <function pretrainedmodels.models.nasnet.nasnetalarge>,\n",
              " 'nasnetamobile': <function pretrainedmodels.models.nasnet_mobile.nasnetamobile>,\n",
              " 'pnasnet5large': <function pretrainedmodels.models.pnasnet.pnasnet5large>,\n",
              " 'polynet': <function pretrainedmodels.models.polynet.polynet>,\n",
              " 'pretrained_settings': {'alexnet': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth'}},\n",
              "  'bninception': {'imagenet': {'input_range': [0, 255],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'BGR',\n",
              "    'mean': [104, 117, 128],\n",
              "    'num_classes': 1000,\n",
              "    'std': [1, 1, 1],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/bn_inception-52deb4733.pth'}},\n",
              "  'cafferesnet101': {'imagenet': {'input_range': [0, 255],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'BGR',\n",
              "    'mean': [102.9801, 115.9465, 122.7717],\n",
              "    'num_classes': 1000,\n",
              "    'std': [1, 1, 1],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/cafferesnet101-9d633cc0.pth'}},\n",
              "  'densenet121': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/densenet121-fbdb23505.pth'}},\n",
              "  'densenet161': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/densenet161-347e6b360.pth'}},\n",
              "  'densenet169': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/densenet169-f470b90a4.pth'}},\n",
              "  'densenet201': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/densenet201-5750cbb1e.pth'}},\n",
              "  'dpn107': {'imagenet+5k': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.48627450980392156, 0.4588235294117647, 0.40784313725490196],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.23482446870963955, 0.23482446870963955, 0.23482446870963955],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn107_extra-b7f9f4cc9.pth'}},\n",
              "  'dpn131': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.48627450980392156, 0.4588235294117647, 0.40784313725490196],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.23482446870963955, 0.23482446870963955, 0.23482446870963955],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn131-7af84be88.pth'}},\n",
              "  'dpn68': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.48627450980392156, 0.4588235294117647, 0.40784313725490196],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.23482446870963955, 0.23482446870963955, 0.23482446870963955],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn68-4af7d88d2.pth'}},\n",
              "  'dpn68b': {'imagenet+5k': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.48627450980392156, 0.4588235294117647, 0.40784313725490196],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.23482446870963955, 0.23482446870963955, 0.23482446870963955],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn68b_extra-363ab9c19.pth'}},\n",
              "  'dpn92': {'imagenet+5k': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.48627450980392156, 0.4588235294117647, 0.40784313725490196],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.23482446870963955, 0.23482446870963955, 0.23482446870963955],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn92_extra-fda993c95.pth'}},\n",
              "  'dpn98': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.48627450980392156, 0.4588235294117647, 0.40784313725490196],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.23482446870963955, 0.23482446870963955, 0.23482446870963955],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn98-722954780.pth'}},\n",
              "  'fbresnet152': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/fbresnet152-2e20f6b4.pth'}},\n",
              "  'inceptionresnetv2': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 299, 299],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.5, 0.5, 0.5],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.5, 0.5, 0.5],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/inceptionresnetv2-520b38e4.pth'},\n",
              "   'imagenet+background': {'input_range': [0, 1],\n",
              "    'input_size': [3, 299, 299],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.5, 0.5, 0.5],\n",
              "    'num_classes': 1001,\n",
              "    'std': [0.5, 0.5, 0.5],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/inceptionresnetv2-520b38e4.pth'}},\n",
              "  'inceptionv3': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 299, 299],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.5, 0.5, 0.5],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.5, 0.5, 0.5],\n",
              "    'url': 'https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth'}},\n",
              "  'inceptionv4': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 299, 299],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.5, 0.5, 0.5],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.5, 0.5, 0.5],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/inceptionv4-8e4777a0.pth'},\n",
              "   'imagenet+background': {'input_range': [0, 1],\n",
              "    'input_size': [3, 299, 299],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.5, 0.5, 0.5],\n",
              "    'num_classes': 1001,\n",
              "    'std': [0.5, 0.5, 0.5],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/inceptionv4-8e4777a0.pth'}},\n",
              "  'nasnetalarge': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 331, 331],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.5, 0.5, 0.5],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.5, 0.5, 0.5],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth'},\n",
              "   'imagenet+background': {'input_range': [0, 1],\n",
              "    'input_size': [3, 331, 331],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.5, 0.5, 0.5],\n",
              "    'num_classes': 1001,\n",
              "    'std': [0.5, 0.5, 0.5],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth'}},\n",
              "  'nasnetamobile': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.5, 0.5, 0.5],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.5, 0.5, 0.5],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/nasnetamobile-7e03cead.pth'}},\n",
              "  'pnasnet5large': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 331, 331],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.5, 0.5, 0.5],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.5, 0.5, 0.5],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/pnasnet5large-bf079911.pth'},\n",
              "   'imagenet+background': {'input_range': [0, 1],\n",
              "    'input_size': [3, 331, 331],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.5, 0.5, 0.5],\n",
              "    'num_classes': 1001,\n",
              "    'std': [0.5, 0.5, 0.5],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/pnasnet5large-bf079911.pth'}},\n",
              "  'polynet': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 331, 331],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/polynet-f71d82a5.pth'}},\n",
              "  'resnet101': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth'}},\n",
              "  'resnet152': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth'}},\n",
              "  'resnet18': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'https://download.pytorch.org/models/resnet18-5c106cde.pth'}},\n",
              "  'resnet34': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth'}},\n",
              "  'resnet50': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'https://download.pytorch.org/models/resnet50-19c8e357.pth'}},\n",
              "  'resnext101_32x4d': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/resnext101_32x4d-29e315fa.pth'}},\n",
              "  'resnext101_64x4d': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/resnext101_64x4d-e77a0586.pth'}},\n",
              "  'se_resnet101': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet101-7e38fcc6.pth'}},\n",
              "  'se_resnet152': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet152-d17c99b7.pth'}},\n",
              "  'se_resnet50': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet50-ce0d4300.pth'}},\n",
              "  'se_resnext101_32x4d': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext101_32x4d-3b2fe3d8.pth'}},\n",
              "  'se_resnext50_32x4d': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth'}},\n",
              "  'senet154': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/senet154-c7b49a05.pth'}},\n",
              "  'squeezenet1_0': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'https://download.pytorch.org/models/squeezenet1_0-a815701f.pth'}},\n",
              "  'squeezenet1_1': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth'}},\n",
              "  'vgg11': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth'}},\n",
              "  'vgg11_bn': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth'}},\n",
              "  'vgg13': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'https://download.pytorch.org/models/vgg13-c768596a.pth'}},\n",
              "  'vgg13_bn': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth'}},\n",
              "  'vgg16': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'https://download.pytorch.org/models/vgg16-397923af.pth'}},\n",
              "  'vgg16_bn': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth'}},\n",
              "  'vgg19': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth'}},\n",
              "  'vgg19_bn': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 224, 224],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.485, 0.456, 0.406],\n",
              "    'num_classes': 1000,\n",
              "    'std': [0.229, 0.224, 0.225],\n",
              "    'url': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth'}},\n",
              "  'xception': {'imagenet': {'input_range': [0, 1],\n",
              "    'input_size': [3, 299, 299],\n",
              "    'input_space': 'RGB',\n",
              "    'mean': [0.5, 0.5, 0.5],\n",
              "    'num_classes': 1000,\n",
              "    'scale': 0.8975,\n",
              "    'std': [0.5, 0.5, 0.5],\n",
              "    'url': 'http://data.lip6.fr/cadene/pretrainedmodels/xception-43020ad28.pth'}}},\n",
              " 'resnet101': <function pretrainedmodels.models.torchvision_models.resnet101>,\n",
              " 'resnet152': <function pretrainedmodels.models.torchvision_models.resnet152>,\n",
              " 'resnet18': <function pretrainedmodels.models.torchvision_models.resnet18>,\n",
              " 'resnet34': <function pretrainedmodels.models.torchvision_models.resnet34>,\n",
              " 'resnet50': <function pretrainedmodels.models.torchvision_models.resnet50>,\n",
              " 'resnext101_32x4d': <function pretrainedmodels.models.resnext.resnext101_32x4d>,\n",
              " 'resnext101_64x4d': <function pretrainedmodels.models.resnext.resnext101_64x4d>,\n",
              " 'se_resnet101': <function pretrainedmodels.models.senet.se_resnet101>,\n",
              " 'se_resnet152': <function pretrainedmodels.models.senet.se_resnet152>,\n",
              " 'se_resnet50': <function pretrainedmodels.models.senet.se_resnet50>,\n",
              " 'se_resnext101_32x4d': <function pretrainedmodels.models.senet.se_resnext101_32x4d>,\n",
              " 'se_resnext50_32x4d': <function pretrainedmodels.models.senet.se_resnext50_32x4d>,\n",
              " 'senet154': <function pretrainedmodels.models.senet.senet154>,\n",
              " 'squeezenet1_0': <function pretrainedmodels.models.torchvision_models.squeezenet1_0>,\n",
              " 'squeezenet1_1': <function pretrainedmodels.models.torchvision_models.squeezenet1_1>,\n",
              " 'version': <module 'pretrainedmodels.version' from '/usr/local/lib/python3.7/dist-packages/pretrainedmodels/version.py'>,\n",
              " 'vgg11': <function pretrainedmodels.models.torchvision_models.vgg11>,\n",
              " 'vgg11_bn': <function pretrainedmodels.models.torchvision_models.vgg11_bn>,\n",
              " 'vgg13': <function pretrainedmodels.models.torchvision_models.vgg13>,\n",
              " 'vgg13_bn': <function pretrainedmodels.models.torchvision_models.vgg13_bn>,\n",
              " 'vgg16': <function pretrainedmodels.models.torchvision_models.vgg16>,\n",
              " 'vgg16_bn': <function pretrainedmodels.models.torchvision_models.vgg16_bn>,\n",
              " 'vgg19': <function pretrainedmodels.models.torchvision_models.vgg19>,\n",
              " 'vgg19_bn': <function pretrainedmodels.models.torchvision_models.vgg19_bn>,\n",
              " 'xception': <function pretrainedmodels.models.xception.xception>}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import pretrainedmodels\n",
        "pretrainedmodels.__dict__\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTx5UAUnrRbG",
        "outputId": "3854c237-61dd-4dce-f9a0-8484e604e942"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "U5qLr70WrUG-"
      },
      "outputs": [],
      "source": [
        "import pretrainedmodels\n",
        "#For model building\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torchvision\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class CNN1(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super(CNN1, self).__init__()\n",
        "        if pretrained is True:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet34\"](pretrained=\"imagenet\")\n",
        "        else:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet34\"](pretrained=None)\n",
        "        #self.fc1 = nn.Linear(512, 256)\n",
        "        self.conv1 = nn.Conv2d(512, 128, (5,5), stride=1, padding =0)\n",
        "        self.conv2 = nn.Conv2d(128, 32, (5,5), stride=1, padding =0)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.conv3 = nn.Conv2d(32, 8, (5,5), stride=1, padding =0)\n",
        "        self.fc1 = nn.Linear(128, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        bs, _, _, _ = x.shape\n",
        "        x = self.model.features(x)\n",
        "        #x = F.adaptive_avg_pool2d(x) #.reshape(bs, -1)\n",
        "        #x = F.relu(self.fc1(x))\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv3(F.relu(x))\n",
        "        #print(x.size()) # [8, 8, 4, 4]\n",
        "        label = self.fc1(x.reshape(bs, -1))  # [8, 128]\n",
        "        return label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzocVN8of41t"
      },
      "outputs": [],
      "source": [
        "class CNN11(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super(CNN11, self).__init__()\n",
        "        if pretrained is True:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet34\"](pretrained=\"imagenet\")\n",
        "        else:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet34\"](pretrained=None)\n",
        "        #self.fc1 = nn.Linear(512, 256)\n",
        "        self.pool1 = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "        self.fc1 = nn.Linear(in_features=512, out_features=1, bias=True)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        bs, _, _, _ = x.shape\n",
        "        x = self.model.features(x)\n",
        "        x = self.pool1(x)\n",
        "        label = self.fc1(x.reshape(bs, -1))  # [8, 128]\n",
        "        return label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7FcjzDkVCxV"
      },
      "outputs": [],
      "source": [
        "class CNN2(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super(CNN2, self).__init__()\n",
        "        if pretrained is True:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet18\"](pretrained=\"imagenet\")\n",
        "        else:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet18\"](pretrained=None)\n",
        "        #self.fc1 = nn.Linear(512, 256)\n",
        "        self.conv1 = nn.Conv2d(512, 128, (5,5), stride=1, padding =0)\n",
        "        self.conv2 = nn.Conv2d(128, 32, (5,5), stride=1, padding =0)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.conv3 = nn.Conv2d(32, 8, (5,5), stride=1, padding =0)\n",
        "        self.fc1 = nn.Linear(128, 16)\n",
        "        self.fc2 = nn.Linear(16, 8)\n",
        "        self.fc3 = nn.Linear(8, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        bs, _, _, _ = x.shape\n",
        "        x = self.model.features(x)\n",
        "        #x = F.adaptive_avg_pool2d(x) #.reshape(bs, -1)\n",
        "        #x = F.relu(self.fc1(x))\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv3(F.relu(x))\n",
        "        # print(x.size()) # [8, 8, 4, 4]\n",
        "        label = self.fc1(x.reshape(bs, -1))  # [8, 128]\n",
        "        label = self.fc2(label)\n",
        "        label = self.fc3(label)\n",
        "        return label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "przjgpumIEoT"
      },
      "outputs": [],
      "source": [
        "# reference: https://github.com/mr7495/COVID-CT-Code/blob/master/COVID_Train%26Validation.ipynb\n",
        "class CNN3(nn.Module):\n",
        "    def __init__(self, pretrained=True,freeze=True):\n",
        "        super(CNN3, self).__init__()\n",
        "        if pretrained is True:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet50\"](pretrained=\"imagenet\")\n",
        "        else:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet50\"](pretrained=None)\n",
        "        if freeze is True:\n",
        "            for param in self.model.parameters():\n",
        "              param.requires_grad = False\n",
        "        #self.fc1 = nn.Linear(512, 256)\n",
        "        self.conv1 = nn.Conv2d(512, 128, (5,5), stride=1, padding =0)\n",
        "        self.conv2 = nn.Conv2d(128, 32, (5,5), stride=1, padding =0)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.conv3 = nn.Conv2d(32, 8, (5,5), stride=1, padding =0)\n",
        "        self.fc1 = nn.Linear(128, 16)\n",
        "        self.fc2 = nn.Linear(16, 8)\n",
        "        self.fc3 = nn.Linear(8, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        bs, _, _, _ = x.shape\n",
        "        x = self.model.features(x)\n",
        "        #x = F.adaptive_avg_pool2d(x) #.reshape(bs, -1)\n",
        "        #x = F.relu(self.fc1(x))\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv3(F.relu(x))\n",
        "        # print(x.size()) # [8, 8, 4, 4]\n",
        "        label = self.fc1(x.reshape(bs, -1))  # [8, 128]\n",
        "        label = self.fc2(label)\n",
        "        label = self.fc3(label)\n",
        "        return label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5w1p6y-VORP"
      },
      "outputs": [],
      "source": [
        "# reference: https://www.researchsquare.com/article/rs-32957/v1\n",
        "class CNN4(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super(CNN4, self).__init__()\n",
        "        if pretrained is True:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet18\"](pretrained=\"imagenet\")\n",
        "        else:\n",
        "            self.model = pretrainedmodels.__dict__[\"resnet18\"](pretrained=None)\n",
        "        self.conv1 = nn.Conv2d(512, 128, (5,5), stride=1, padding =0)\n",
        "        self.conv2 = nn.Conv2d(128, 32, (5,5), stride=1, padding =0)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.conv3 = nn.Conv2d(32, 8, (5,5), stride=1, padding =0)\n",
        "        self.fc1 = nn.Linear(128, 16)\n",
        "        self.fc2 = nn.Linear(16, 8)\n",
        "        self.fc3 = nn.Linear(20, 1)\n",
        "\n",
        "        self.conv4 = nn.Conv1d(1,1,kernel_size=5)\n",
        "        self.bn = nn.BatchNorm1d(1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        bs, _, _, _ = x.shape\n",
        "        x = self.model.features(x)\n",
        "        #x = F.adaptive_avg_pool2d(x) #.reshape(bs, -1)\n",
        "        #x = F.relu(self.fc1(x))\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv3(F.relu(x))\n",
        "        x = F.adaptive_avg_pool2d(x, x.shape[3])\n",
        "        # print(x.reshape(bs,-1).size())\n",
        "\n",
        "        l = self.fc1(x.reshape(bs, -1))\n",
        "        c = self.conv4(l.reshape(bs,1,-1))\n",
        "        c = self.bn(c)\n",
        "        c = F.relu(c)\n",
        "        l = self.fc2(l)\n",
        "        \n",
        "        # print(c.size()) # [8, 8, 4, 4]\n",
        "        # print(l.size())\n",
        "\n",
        "        x = torch.cat((c.reshape(bs,-1), l),1)\n",
        "        label = self.fc3(x)\n",
        "\n",
        "        return label"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = pretrainedmodels.__dict__[\"vgg16\"](pretrained=\"imagenet\")\n",
        "x = torch.zeros([2, 3, 512, 512])\n",
        "x.view(x.size(0), -1).size()\n",
        "model.features(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "VVfTIioox511",
        "outputId": "a03b7cbc-26c5-4d41-9ec7-023129943d9e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-96fd62ec7c56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pretrainedmodels/models/torchvision_models.py\u001b[0m in \u001b[0;36mfeatures\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x131072 and 25088x4096)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reference: https://towardsdatascience.com/using-pretrained-deep-convolutional-neural-networks-for-binary-classification-of-covid-19-ct-scans-3a7f7ea8b543\n",
        "class CNN5(nn.Module):\n",
        "    def __init__(self, pretrained=True,freeze=True):\n",
        "        super(CNN5, self).__init__()\n",
        "        if pretrained is True:\n",
        "            self.model = pretrainedmodels.__dict__[\"vgg16\"](pretrained=\"imagenet\")\n",
        "        else:\n",
        "            self.model = pretrainedmodels.__dict__[\"vgg16\"](pretrained=None)\n",
        "        if freeze is True:\n",
        "            for param in self.model.parameters():\n",
        "                param.requires_grad = False\n",
        "        self.fc1 = nn.Linear(131072, 512)\n",
        "        self.activation1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout()\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.activation2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout()\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.activation3 = nn.ReLU()\n",
        "        self.dropout3 = nn.Dropout()\n",
        "        self.fc4 = nn.Linear(128, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        bs, _, _, _ = x.shape\n",
        "        print(x.size(0))\n",
        "        x = self.model._features(x)\n",
        "        x = self.fc1(x.reshape(bs,-1))\n",
        "        x = self.activation1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.activation2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.activation3(x)\n",
        "        x = self.dropout3(x)\n",
        "        label = self.fc4(x)\n",
        "        return label"
      ],
      "metadata": {
        "id": "UpV09wjVrMC1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4fc93fUsR41"
      },
      "outputs": [],
      "source": [
        "# #Setting model and moving to device\n",
        "# model_CNN = CNN1(True).to(device)\n",
        "\n",
        "# criterion = nn.SmoothL1Loss()\n",
        "# #optimizer = optim.SGD(model_CNN.parameters(), lr=0.001, momentum=0.9)\n",
        "# optimizer = optim.Adam(model_CNN.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "5OkU4DZtd6C8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a3b3191-7cb5-4116-b74c-6b6f9ad9c52c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN5(\n",
              "  (model): VGG(\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "    (_features): Sequential(\n",
              "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (6): ReLU(inplace=True)\n",
              "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (8): ReLU(inplace=True)\n",
              "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (11): ReLU(inplace=True)\n",
              "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (13): ReLU(inplace=True)\n",
              "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (15): ReLU(inplace=True)\n",
              "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (18): ReLU(inplace=True)\n",
              "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (20): ReLU(inplace=True)\n",
              "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (22): ReLU(inplace=True)\n",
              "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (25): ReLU(inplace=True)\n",
              "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (27): ReLU(inplace=True)\n",
              "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (29): ReLU(inplace=True)\n",
              "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (linear0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (relu0): ReLU(inplace=True)\n",
              "    (dropout0): Dropout(p=0.5, inplace=False)\n",
              "    (linear1): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (dropout1): Dropout(p=0.5, inplace=False)\n",
              "    (last_linear): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              "  (fc1): Linear(in_features=131072, out_features=512, bias=True)\n",
              "  (activation1): ReLU()\n",
              "  (dropout1): Dropout(p=0.5, inplace=False)\n",
              "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (activation2): ReLU()\n",
              "  (dropout2): Dropout(p=0.5, inplace=False)\n",
              "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (activation3): ReLU()\n",
              "  (dropout3): Dropout(p=0.5, inplace=False)\n",
              "  (fc4): Linear(in_features=128, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "model_CNN = CNN5(pretrained=True,freeze=True).to(device)\n",
        "model_CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "on0ELkMyzv5Z",
        "outputId": "948bed2f-0080-4b15-a176-1c8efe26286c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 512, 512]           1,792\n",
            "              ReLU-2         [-1, 64, 512, 512]               0\n",
            "            Conv2d-3         [-1, 64, 512, 512]          36,928\n",
            "              ReLU-4         [-1, 64, 512, 512]               0\n",
            "         MaxPool2d-5         [-1, 64, 256, 256]               0\n",
            "            Conv2d-6        [-1, 128, 256, 256]          73,856\n",
            "              ReLU-7        [-1, 128, 256, 256]               0\n",
            "            Conv2d-8        [-1, 128, 256, 256]         147,584\n",
            "              ReLU-9        [-1, 128, 256, 256]               0\n",
            "        MaxPool2d-10        [-1, 128, 128, 128]               0\n",
            "           Conv2d-11        [-1, 256, 128, 128]         295,168\n",
            "             ReLU-12        [-1, 256, 128, 128]               0\n",
            "           Conv2d-13        [-1, 256, 128, 128]         590,080\n",
            "             ReLU-14        [-1, 256, 128, 128]               0\n",
            "           Conv2d-15        [-1, 256, 128, 128]         590,080\n",
            "             ReLU-16        [-1, 256, 128, 128]               0\n",
            "        MaxPool2d-17          [-1, 256, 64, 64]               0\n",
            "           Conv2d-18          [-1, 512, 64, 64]       1,180,160\n",
            "             ReLU-19          [-1, 512, 64, 64]               0\n",
            "           Conv2d-20          [-1, 512, 64, 64]       2,359,808\n",
            "             ReLU-21          [-1, 512, 64, 64]               0\n",
            "           Conv2d-22          [-1, 512, 64, 64]       2,359,808\n",
            "             ReLU-23          [-1, 512, 64, 64]               0\n",
            "        MaxPool2d-24          [-1, 512, 32, 32]               0\n",
            "           Conv2d-25          [-1, 512, 32, 32]       2,359,808\n",
            "             ReLU-26          [-1, 512, 32, 32]               0\n",
            "           Conv2d-27          [-1, 512, 32, 32]       2,359,808\n",
            "             ReLU-28          [-1, 512, 32, 32]               0\n",
            "           Conv2d-29          [-1, 512, 32, 32]       2,359,808\n",
            "             ReLU-30          [-1, 512, 32, 32]               0\n",
            "        MaxPool2d-31          [-1, 512, 16, 16]               0\n",
            "           Linear-32                  [-1, 512]      67,109,376\n",
            "             ReLU-33                  [-1, 512]               0\n",
            "          Dropout-34                  [-1, 512]               0\n",
            "           Linear-35                  [-1, 256]         131,328\n",
            "             ReLU-36                  [-1, 256]               0\n",
            "          Dropout-37                  [-1, 256]               0\n",
            "           Linear-38                  [-1, 128]          32,896\n",
            "             ReLU-39                  [-1, 128]               0\n",
            "          Dropout-40                  [-1, 128]               0\n",
            "           Linear-41                    [-1, 1]             129\n",
            "================================================================\n",
            "Total params: 81,988,417\n",
            "Trainable params: 81,988,417\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 3.00\n",
            "Forward/backward pass size (MB): 1141.02\n",
            "Params size (MB): 312.76\n",
            "Estimated Total Size (MB): 1456.78\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "summary(model_CNN, input_size=(3, 512, 512))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKEOiFbtsJ7C"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, train_dataloader, val_dataloader, n_epochs=15):\n",
        "    \"\"\"returns trained model\"\"\"\n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf\n",
        "    for epoch in range(1, n_epochs):\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        # train the model #\n",
        "        model.train()\n",
        "        for batch_idx, sample_batched in enumerate(train_dataloader):\n",
        "            # importing data and moving to GPU\n",
        "            image, label = sample_batched['image'].to(device), sample_batched['percentage'].to(device)\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            output=model(image).reshape(-1)\n",
        "            # calculate loss\n",
        "            loss = criterion((output).type(torch.FloatTensor).to(device), label.type(torch.FloatTensor).to(device))\n",
        "            # back prop\n",
        "            loss.backward()\n",
        "            # grad\n",
        "            optimizer.step()\n",
        "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "            if batch_idx % 100 == 0:\n",
        "                print('Epoch %d, Batch %d loss: %.6f' %\n",
        "                  (epoch, batch_idx + 1, train_loss))\n",
        "        # validate the model #\n",
        "        model.eval()\n",
        "        for batch_idx, sample_batched in enumerate(val_dataloader):\n",
        "            image, label = sample_batched['image'].to(device), sample_batched['percentage'].to(device)  \n",
        "            output = model(image).reshape(-1)\n",
        "            # calculate loss\n",
        "            loss=criterion((output).type(torch.FloatTensor).to(device), label.type(torch.FloatTensor).to(device))\n",
        "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
        "        \n",
        "        # print training/validation statistics \n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "            epoch, train_loss, valid_loss))\n",
        "        \n",
        "        ## TODO: save the model if validation loss has decreased\n",
        "        if valid_loss < valid_loss_min:\n",
        "            torch.save(model, 'drive/MyDrive/DL_Project/model.pt')\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "            valid_loss_min,\n",
        "            valid_loss))\n",
        "            valid_loss_min = valid_loss\n",
        "    # return trained model\n",
        "    return model,valid_loss_min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zE5E7Cu8cGio"
      },
      "outputs": [],
      "source": [
        "# k = 4\n",
        "# train_index,val_index = generate_index(covid_dataset_train_val,k)\n",
        "# test_dataloader = DataLoader(covid_dataset_test, batch_size=8, shuffle=True, num_workers=0)\n",
        "# model_cv = []\n",
        "# valid_cvloss = []\n",
        "# for split_i in range(0,k):\n",
        "#   ## split given train set to train & val set by subjects\n",
        "#   train_imageindex = get_image_index(train_index.iloc[:,split_i],subtoimage)\n",
        "#   val_imageindex = get_image_index(val_index.iloc[:,split_i],subtoimage)\n",
        "#   train_dataset = torch.utils.data.Subset(covid_dataset_train_val,train_imageindex)\n",
        "#   val_dataset = torch.utils.data.Subset(covid_dataset_train_val,val_imageindex)\n",
        "#   train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
        "#   val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
        " \n",
        "#   #Setting model and moving to device\n",
        "#   model_CNN = CNN1(True).to(device)\n",
        "\n",
        "#   criterion = nn.SmoothL1Loss()\n",
        "#   #optimizer = optim.SGD(model_CNN.parameters(), lr=0.001, momentum=0.9)\n",
        "#   optimizer = optim.Adam(model_CNN.parameters(), lr=0.0005)\n",
        "\n",
        "#   ## training model\n",
        "#   model_conv,valid_loss_min=train_model(model_CNN, criterion, optimizer)\n",
        "\n",
        "#   model_cv.append(model_conv)\n",
        "#   valid_cvloss.append(valid_loss_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvS7yOuiFEKy"
      },
      "outputs": [],
      "source": [
        "def cv_train(model_CNN_cv,k=4):\n",
        "  train_index,val_index = generate_index(covid_dataset_train_val,k)\n",
        "  test_dataloader = DataLoader(covid_dataset_test, batch_size=8, shuffle=True, num_workers=0)\n",
        "  model_cv = []\n",
        "  valid_cvloss = []\n",
        "  for split_i in range(0,k):\n",
        "    print(split_i)\n",
        "\n",
        "    ## split given train set to train & val set by subjects\n",
        "    train_imageindex = get_image_index(train_index.iloc[:,split_i],subtoimage)\n",
        "    val_imageindex = get_image_index(val_index.iloc[:,split_i],subtoimage)\n",
        "    train_dataset = torch.utils.data.Subset(covid_dataset_train_val,train_imageindex)\n",
        "    val_dataset = torch.utils.data.Subset(covid_dataset_train_val,val_imageindex)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
        "\n",
        "    ## training model\n",
        "    model_conv, valid_loss_min = train_model(model_CNN_cv, criterion, optimizer,train_dataloader,val_dataloader)\n",
        "\n",
        "    model_cv.append(model_conv)\n",
        "    valid_cvloss.append(valid_loss_min)\n",
        "  \n",
        "  return model_cv, valid_cvloss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui7d7oFoFwLH"
      },
      "source": [
        "#### Original version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCresDWjFvHX",
        "outputId": "ec8dd771-3eb0-4326-ea70-b2db094c9be6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3053\n",
            "2137 916\n"
          ]
        }
      ],
      "source": [
        "## split given train set to train & val set\n",
        "\n",
        "#dataloader = DataLoader(covid_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
        "print(len(covid_dataset_train_val))\n",
        "train_size = int(0.7 * len(covid_dataset_train_val))\n",
        "val_size = len(covid_dataset_train_val) - train_size\n",
        "print(train_size, val_size)\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(covid_dataset_train_val, [train_size, val_size])\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
        "\n",
        "## test set\n",
        "test_dataloader = DataLoader(covid_dataset_test, batch_size=8, shuffle=True, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "ffda023e33ca45bfb72bd87bc878e847",
            "0b98173bafa145d6b4177980dbcc8e28",
            "f74ca6a37b2146799c5fcb5b152fb607",
            "ef461751c81746a0beb9254782b89ad5",
            "0896d0cd9c4748bcb97a2d62ddbbb4b1",
            "fc64b23ee7e347b88c382f04ed060ecf",
            "bd7f5b63ebd5454ea06d65a56c7494a3",
            "7bc572e934ba405bbe39a2fd44c02d2c",
            "e84546b433f1415ea6287656adf1703b",
            "cc6d157f800f4c96b8da64a32a1298ec",
            "bf3333241e054d0fa2a46657cdacbed6"
          ]
        },
        "id": "pij8zgLZFKq8",
        "outputId": "023e3177-7132-4494-9187-7449ae2f621e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ffda023e33ca45bfb72bd87bc878e847",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/83.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Setting model and moving to device\n",
        "model_CNN = CNN1(True).to(device)\n",
        "\n",
        "criterion = nn.SmoothL1Loss()\n",
        "#optimizer = optim.SGD(model_CNN.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = optim.Adam(model_CNN.parameters(), lr=0.0005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIN_2v7esLnN",
        "outputId": "ee7bdce9-da02-40f1-c3a0-cc085d750701"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Batch 1 loss: 36.732868\n",
            "Epoch 1, Batch 101 loss: 15.221863\n",
            "Epoch 1, Batch 201 loss: 14.409155\n",
            "Epoch: 1 \tTraining Loss: 13.786035 \tValidation Loss: 7.870570\n",
            "Validation loss decreased (inf --> 7.870570).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 10.300012\n",
            "Epoch 2, Batch 101 loss: 9.382854\n",
            "Epoch 2, Batch 201 loss: 9.244595\n",
            "Epoch: 2 \tTraining Loss: 9.666555 \tValidation Loss: 10.850804\n",
            "Epoch 3, Batch 1 loss: 8.612732\n",
            "Epoch 3, Batch 101 loss: 9.904053\n",
            "Epoch 3, Batch 201 loss: 9.365145\n",
            "Epoch: 3 \tTraining Loss: 8.865157 \tValidation Loss: 7.286494\n",
            "Validation loss decreased (7.870570 --> 7.286494).  Saving model ...\n",
            "Epoch 4, Batch 1 loss: 6.756888\n",
            "Epoch 4, Batch 101 loss: 7.567633\n",
            "Epoch 4, Batch 201 loss: 7.382145\n",
            "Epoch: 4 \tTraining Loss: 7.259842 \tValidation Loss: 7.401605\n",
            "Epoch 5, Batch 1 loss: 10.232670\n",
            "Epoch 5, Batch 101 loss: 7.521949\n",
            "Epoch 5, Batch 201 loss: 6.952010\n",
            "Epoch: 5 \tTraining Loss: 6.771816 \tValidation Loss: 8.308432\n",
            "Epoch 6, Batch 1 loss: 2.896620\n",
            "Epoch 6, Batch 101 loss: 6.442059\n",
            "Epoch 6, Batch 201 loss: 6.289386\n",
            "Epoch: 6 \tTraining Loss: 6.312569 \tValidation Loss: 5.126032\n",
            "Validation loss decreased (7.286494 --> 5.126032).  Saving model ...\n",
            "Epoch 7, Batch 1 loss: 4.873833\n",
            "Epoch 7, Batch 101 loss: 6.282421\n",
            "Epoch 7, Batch 201 loss: 6.037024\n",
            "Epoch: 7 \tTraining Loss: 5.901232 \tValidation Loss: 4.964093\n",
            "Validation loss decreased (5.126032 --> 4.964093).  Saving model ...\n",
            "Epoch 8, Batch 1 loss: 4.562241\n",
            "Epoch 8, Batch 101 loss: 5.483347\n",
            "Epoch 8, Batch 201 loss: 5.374410\n",
            "Epoch: 8 \tTraining Loss: 5.496153 \tValidation Loss: 4.734196\n",
            "Validation loss decreased (4.964093 --> 4.734196).  Saving model ...\n",
            "Epoch 9, Batch 1 loss: 4.097488\n",
            "Epoch 9, Batch 101 loss: 5.587281\n",
            "Epoch 9, Batch 201 loss: 5.741415\n",
            "Epoch: 9 \tTraining Loss: 5.756905 \tValidation Loss: 6.165189\n",
            "Epoch 10, Batch 1 loss: 3.769029\n",
            "Epoch 10, Batch 101 loss: 4.961262\n",
            "Epoch 10, Batch 201 loss: 4.975190\n",
            "Epoch: 10 \tTraining Loss: 5.096213 \tValidation Loss: 5.081287\n",
            "Epoch 11, Batch 1 loss: 4.363635\n",
            "Epoch 11, Batch 101 loss: 4.713640\n",
            "Epoch 11, Batch 201 loss: 4.644732\n",
            "Epoch: 11 \tTraining Loss: 4.666773 \tValidation Loss: 7.024680\n",
            "Epoch 12, Batch 1 loss: 10.915337\n",
            "Epoch 12, Batch 101 loss: 4.686534\n",
            "Epoch 12, Batch 201 loss: 4.561974\n",
            "Epoch: 12 \tTraining Loss: 4.497517 \tValidation Loss: 4.516865\n",
            "Validation loss decreased (4.734196 --> 4.516865).  Saving model ...\n",
            "Epoch 13, Batch 1 loss: 4.654205\n",
            "Epoch 13, Batch 101 loss: 4.706965\n",
            "Epoch 13, Batch 201 loss: 4.601140\n",
            "Epoch: 13 \tTraining Loss: 4.781335 \tValidation Loss: 4.450882\n",
            "Validation loss decreased (4.516865 --> 4.450882).  Saving model ...\n",
            "Epoch 14, Batch 1 loss: 2.113366\n",
            "Epoch 14, Batch 101 loss: 4.403451\n",
            "Epoch 14, Batch 201 loss: 4.171737\n",
            "Epoch: 14 \tTraining Loss: 4.273782 \tValidation Loss: 5.013819\n",
            "Epoch 15, Batch 1 loss: 4.827311\n",
            "Epoch 15, Batch 101 loss: 3.984670\n",
            "Epoch 15, Batch 201 loss: 4.027212\n",
            "Epoch: 15 \tTraining Loss: 4.021631 \tValidation Loss: 4.130851\n",
            "Validation loss decreased (4.450882 --> 4.130851).  Saving model ...\n",
            "Epoch 16, Batch 1 loss: 1.295960\n",
            "Epoch 16, Batch 101 loss: 3.869712\n",
            "Epoch 16, Batch 201 loss: 3.785525\n",
            "Epoch: 16 \tTraining Loss: 3.839849 \tValidation Loss: 3.812582\n",
            "Validation loss decreased (4.130851 --> 3.812582).  Saving model ...\n",
            "Epoch 17, Batch 1 loss: 5.952350\n",
            "Epoch 17, Batch 101 loss: 3.626832\n",
            "Epoch 17, Batch 201 loss: 3.686797\n",
            "Epoch: 17 \tTraining Loss: 3.689905 \tValidation Loss: 3.997886\n",
            "Epoch 18, Batch 1 loss: 3.462218\n",
            "Epoch 18, Batch 101 loss: 4.176491\n",
            "Epoch 18, Batch 201 loss: 3.737649\n",
            "Epoch: 18 \tTraining Loss: 3.727559 \tValidation Loss: 5.094762\n",
            "Epoch 19, Batch 1 loss: 3.320187\n",
            "Epoch 19, Batch 101 loss: 3.690749\n",
            "Epoch 19, Batch 201 loss: 3.506429\n",
            "Epoch: 19 \tTraining Loss: 3.576088 \tValidation Loss: 4.523637\n"
          ]
        }
      ],
      "source": [
        "model_conv,valid_loss_min=train_model(model_CNN, criterion, optimizer,train_dataloader,val_dataloader,n_epochs=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yw64BWRNj5CQ"
      },
      "source": [
        "#### Test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gAp6d65lvG4"
      },
      "outputs": [],
      "source": [
        "model = model_conv # [-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksNiueFxsMxA"
      },
      "outputs": [],
      "source": [
        "test_dataloader = DataLoader(covid_dataset_test, batch_size=8, shuffle=True, num_workers=0)\n",
        "\n",
        "df = pd.DataFrame(columns=['image_name','output'])\n",
        "for batch_idx, sample_batched in enumerate(test_dataloader):\n",
        "    image= sample_batched['image'].to(device)\n",
        "    img_name= sample_batched['img_name']\n",
        "    output = model(image).type(torch.LongTensor).reshape(-1)\n",
        "    img_name = np.array(img_name).reshape(output.shape[0],1)\n",
        "    o = output.cpu().data.numpy().reshape(output.shape[0],1)\n",
        "    a = np.concatenate((img_name,o),axis=1)\n",
        "    df = df.append(pd.DataFrame(a, columns=df.columns), ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVRo94hEyBjl"
      },
      "outputs": [],
      "source": [
        "#Extracting image name from the image path\n",
        "df['image_name']=df['image_name'].str.split(\"/\").str[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFib873XyETp"
      },
      "outputs": [],
      "source": [
        "df.to_csv('drive/MyDrive/DL_Project/predictions.csv', index=False, header=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qDgX-3G5yF56",
        "outputId": "8f6f5fd7-ab4e-4cfd-c6b5-e94adf08d79d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-45f9f9c6-e2e6-4885-be0f-756ddf5678b9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Image_0428.png</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Image_1226.png</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Image_0146.png</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Image_0321.png</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Image_0240.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45f9f9c6-e2e6-4885-be0f-756ddf5678b9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-45f9f9c6-e2e6-4885-be0f-756ddf5678b9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-45f9f9c6-e2e6-4885-be0f-756ddf5678b9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       image_name output\n",
              "0  Image_0428.png     69\n",
              "1  Image_1226.png     29\n",
              "2  Image_0146.png     32\n",
              "3  Image_0321.png      8\n",
              "4  Image_0240.png      0"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7U0q5gq9myZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncE2pyKICUh5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YahObt4wCVbO"
      },
      "source": [
        "#### Test for loss and optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HdWMN6lfGUe_",
        "outputId": "70822987-8377-402c-ebf6-e9f35544cf36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Epoch 1, Batch 1 loss: 11.601451\n",
            "Epoch: 1 \tTraining Loss: 10.271539 \tValidation Loss: 12.681701\n",
            "Validation loss decreased (inf --> 12.681701).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 7.639615\n",
            "Epoch: 2 \tTraining Loss: 5.569466 \tValidation Loss: 18.663755\n",
            "Epoch 3, Batch 1 loss: 7.731151\n",
            "Epoch: 3 \tTraining Loss: 4.840785 \tValidation Loss: 5.796551\n",
            "Validation loss decreased (12.681701 --> 5.796551).  Saving model ...\n",
            "Epoch 4, Batch 1 loss: 2.517676\n",
            "Epoch: 4 \tTraining Loss: 4.447001 \tValidation Loss: 8.018155\n",
            "Epoch 5, Batch 1 loss: 3.161429\n",
            "Epoch: 5 \tTraining Loss: 3.846349 \tValidation Loss: 6.621096\n",
            "Epoch 6, Batch 1 loss: 6.418601\n",
            "Epoch: 6 \tTraining Loss: 3.664398 \tValidation Loss: 6.475037\n",
            "Epoch 7, Batch 1 loss: 6.251128\n",
            "Epoch: 7 \tTraining Loss: 3.585536 \tValidation Loss: 6.969287\n",
            "Epoch 8, Batch 1 loss: 2.854709\n",
            "Epoch: 8 \tTraining Loss: 3.674078 \tValidation Loss: 5.792586\n",
            "Validation loss decreased (5.796551 --> 5.792586).  Saving model ...\n",
            "Epoch 9, Batch 1 loss: 3.675019\n",
            "Epoch: 9 \tTraining Loss: 3.316894 \tValidation Loss: 5.917814\n",
            "Epoch 10, Batch 1 loss: 6.368705\n",
            "Epoch: 10 \tTraining Loss: 3.846698 \tValidation Loss: 5.740936\n",
            "Validation loss decreased (5.792586 --> 5.740936).  Saving model ...\n",
            "Epoch 11, Batch 1 loss: 2.697203\n",
            "Epoch: 11 \tTraining Loss: 3.118947 \tValidation Loss: 5.272302\n",
            "Validation loss decreased (5.740936 --> 5.272302).  Saving model ...\n",
            "Epoch 12, Batch 1 loss: 3.239723\n",
            "Epoch: 12 \tTraining Loss: 3.369357 \tValidation Loss: 5.323894\n",
            "Epoch 13, Batch 1 loss: 2.772679\n",
            "Epoch: 13 \tTraining Loss: 3.189272 \tValidation Loss: 7.296361\n",
            "Epoch 14, Batch 1 loss: 1.828326\n",
            "Epoch: 14 \tTraining Loss: 2.814636 \tValidation Loss: 5.488516\n",
            "1\n",
            "Epoch 1, Batch 1 loss: 2.227611\n",
            "Epoch: 1 \tTraining Loss: 3.761868 \tValidation Loss: 2.751615\n",
            "Validation loss decreased (inf --> 2.751615).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 1.814380\n",
            "Epoch: 2 \tTraining Loss: 3.258822 \tValidation Loss: 2.145589\n",
            "Validation loss decreased (2.751615 --> 2.145589).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 2.121669\n",
            "Epoch: 3 \tTraining Loss: 3.083216 \tValidation Loss: 3.767459\n",
            "Epoch 4, Batch 1 loss: 2.461300\n",
            "Epoch: 4 \tTraining Loss: 3.429573 \tValidation Loss: 3.614802\n",
            "Epoch 5, Batch 1 loss: 7.575171\n",
            "Epoch: 5 \tTraining Loss: 2.948707 \tValidation Loss: 3.171427\n",
            "Epoch 6, Batch 1 loss: 1.608114\n",
            "Epoch: 6 \tTraining Loss: 2.277317 \tValidation Loss: 2.890727\n",
            "Epoch 7, Batch 1 loss: 2.010574\n",
            "Epoch: 7 \tTraining Loss: 2.561770 \tValidation Loss: 5.076377\n",
            "Epoch 8, Batch 1 loss: 2.248955\n",
            "Epoch: 8 \tTraining Loss: 2.218021 \tValidation Loss: 2.304774\n",
            "Epoch 9, Batch 1 loss: 2.190924\n",
            "Epoch: 9 \tTraining Loss: 1.903797 \tValidation Loss: 3.049832\n",
            "Epoch 10, Batch 1 loss: 1.577995\n",
            "Epoch: 10 \tTraining Loss: 1.806534 \tValidation Loss: 3.329083\n",
            "Epoch 11, Batch 1 loss: 1.334560\n",
            "Epoch: 11 \tTraining Loss: 1.525442 \tValidation Loss: 4.048081\n",
            "Epoch 12, Batch 1 loss: 0.764080\n",
            "Epoch: 12 \tTraining Loss: 1.664019 \tValidation Loss: 2.234968\n",
            "Epoch 13, Batch 1 loss: 1.899348\n",
            "Epoch: 13 \tTraining Loss: 1.452326 \tValidation Loss: 3.343588\n",
            "Epoch 14, Batch 1 loss: 0.871859\n",
            "Epoch: 14 \tTraining Loss: 1.574910 \tValidation Loss: 2.434053\n",
            "2\n",
            "Epoch 1, Batch 1 loss: 1.526399\n",
            "Epoch: 1 \tTraining Loss: 1.913430 \tValidation Loss: 2.107551\n",
            "Validation loss decreased (inf --> 2.107551).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 1.905952\n",
            "Epoch: 2 \tTraining Loss: 2.008835 \tValidation Loss: 3.102231\n",
            "Epoch 3, Batch 1 loss: 1.381434\n",
            "Epoch: 3 \tTraining Loss: 2.671405 \tValidation Loss: 5.199889\n",
            "Epoch 4, Batch 1 loss: 1.562731\n",
            "Epoch: 4 \tTraining Loss: 2.162541 \tValidation Loss: 1.642110\n",
            "Validation loss decreased (2.107551 --> 1.642110).  Saving model ...\n",
            "Epoch 5, Batch 1 loss: 1.837134\n",
            "Epoch: 5 \tTraining Loss: 2.012033 \tValidation Loss: 1.546948\n",
            "Validation loss decreased (1.642110 --> 1.546948).  Saving model ...\n",
            "Epoch 6, Batch 1 loss: 1.531995\n",
            "Epoch: 6 \tTraining Loss: 1.658416 \tValidation Loss: 1.825801\n",
            "Epoch 7, Batch 1 loss: 1.149141\n",
            "Epoch: 7 \tTraining Loss: 1.287970 \tValidation Loss: 2.230014\n",
            "Epoch 8, Batch 1 loss: 2.000630\n",
            "Epoch: 8 \tTraining Loss: 1.308377 \tValidation Loss: 2.886015\n",
            "Epoch 9, Batch 1 loss: 0.493144\n",
            "Epoch: 9 \tTraining Loss: 1.343937 \tValidation Loss: 1.782785\n",
            "Epoch 10, Batch 1 loss: 1.065693\n",
            "Epoch: 10 \tTraining Loss: 1.341592 \tValidation Loss: 2.206452\n",
            "Epoch 11, Batch 1 loss: 1.808462\n",
            "Epoch: 11 \tTraining Loss: 3.049881 \tValidation Loss: 3.607404\n",
            "Epoch 12, Batch 1 loss: 2.316263\n",
            "Epoch: 12 \tTraining Loss: 1.869880 \tValidation Loss: 3.265388\n",
            "Epoch 13, Batch 1 loss: 2.220694\n",
            "Epoch: 13 \tTraining Loss: 1.607668 \tValidation Loss: 1.772707\n",
            "Epoch 14, Batch 1 loss: 1.165936\n",
            "Epoch: 14 \tTraining Loss: 1.235721 \tValidation Loss: 1.885269\n",
            "3\n",
            "Epoch 1, Batch 1 loss: 1.268780\n",
            "Epoch: 1 \tTraining Loss: 1.741119 \tValidation Loss: 1.919709\n",
            "Validation loss decreased (inf --> 1.919709).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 1.606708\n",
            "Epoch: 2 \tTraining Loss: 1.904666 \tValidation Loss: 0.902386\n",
            "Validation loss decreased (1.919709 --> 0.902386).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 0.948982\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-8352ff8ad50a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m## training model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel_conv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_loss_min1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_CNN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-dde19f68a414>\u001b[0m in \u001b[0;36mcv_train\u001b[0;34m(model_CNN_cv, k)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m## training model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mmodel_conv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_CNN_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmodel_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_conv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-a490b207f0a0>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, train_dataloader, val_dataloader, n_epochs)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0;31m# back prop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Setting model and moving to device\n",
        "model_CNN = CNN11(True).to(device)\n",
        "\n",
        "criterion = nn.SmoothL1Loss()\n",
        "#optimizer = optim.SGD(model_CNN.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = optim.Adam(model_CNN.parameters(), lr=0.0005)\n",
        "\n",
        "## training model\n",
        "model_conv1,valid_loss_min1=cv_train(model_CNN,k=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "661d9d1b11894dbd98ddad952e7ec2db",
            "e1660f5e755b4806aae88416788eac16",
            "c914c2847f0a48a6b9c62333b44f4f5b",
            "cf50c8c99ad84493bc8e3fab0e03e09f",
            "ee52f13df6794edb82309fc823105d33",
            "e170e4f8325647a7a4c8baa73521e489",
            "137209566cb74b059ad382754a47a701",
            "5faf3b346fa44c75aded558eb391118d",
            "2f7d61cd7f7c4f458ae4f3e33c02f648",
            "830b1d5682c94b96b1551345f2e7e7bd",
            "3caab6801e204676a38d022d3e6d0661"
          ]
        },
        "id": "Zc79TS-FGhmH",
        "outputId": "b4878ea3-7e72-474f-9602-d3c499654240"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "661d9d1b11894dbd98ddad952e7ec2db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/83.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "Epoch 1, Batch 1 loss: 947.663025\n",
            "Epoch: 1 \tTraining Loss: 277.514343 \tValidation Loss: 156.115585\n",
            "Validation loss decreased (inf --> 156.115585).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 289.343201\n",
            "Epoch: 2 \tTraining Loss: 125.729805 \tValidation Loss: 157.570801\n",
            "Epoch 3, Batch 1 loss: 29.608173\n",
            "Epoch: 3 \tTraining Loss: 81.448135 \tValidation Loss: 103.794708\n",
            "Validation loss decreased (156.115585 --> 103.794708).  Saving model ...\n",
            "Epoch 4, Batch 1 loss: 54.609699\n",
            "Epoch: 4 \tTraining Loss: 70.998604 \tValidation Loss: 73.816879\n",
            "Validation loss decreased (103.794708 --> 73.816879).  Saving model ...\n",
            "Epoch 5, Batch 1 loss: 24.446907\n",
            "Epoch: 5 \tTraining Loss: 53.192715 \tValidation Loss: 81.044930\n",
            "Epoch 6, Batch 1 loss: 20.399981\n",
            "Epoch: 6 \tTraining Loss: 40.874634 \tValidation Loss: 193.283600\n",
            "Epoch 7, Batch 1 loss: 39.604458\n",
            "Epoch: 7 \tTraining Loss: 34.152679 \tValidation Loss: 88.972496\n",
            "Epoch 8, Batch 1 loss: 7.292533\n",
            "Epoch: 8 \tTraining Loss: 28.627386 \tValidation Loss: 82.835793\n",
            "Epoch 9, Batch 1 loss: 25.668018\n",
            "Epoch: 9 \tTraining Loss: 24.020102 \tValidation Loss: 79.477509\n",
            "Epoch 10, Batch 1 loss: 21.664167\n",
            "Epoch: 10 \tTraining Loss: 26.127373 \tValidation Loss: 92.244377\n",
            "Epoch 11, Batch 1 loss: 15.831478\n",
            "Epoch: 11 \tTraining Loss: 23.362446 \tValidation Loss: 77.616295\n",
            "Epoch 12, Batch 1 loss: 12.551205\n",
            "Epoch: 12 \tTraining Loss: 17.851219 \tValidation Loss: 116.088036\n",
            "Epoch 13, Batch 1 loss: 25.942698\n",
            "Epoch: 13 \tTraining Loss: 22.539726 \tValidation Loss: 114.118568\n",
            "Epoch 14, Batch 1 loss: 7.075692\n",
            "Epoch: 14 \tTraining Loss: 21.411942 \tValidation Loss: 85.617996\n",
            "1\n",
            "Epoch 1, Batch 1 loss: 84.024078\n",
            "Epoch: 1 \tTraining Loss: 39.435623 \tValidation Loss: 161.755661\n",
            "Validation loss decreased (inf --> 161.755661).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 57.847633\n",
            "Epoch: 2 \tTraining Loss: 101.790184 \tValidation Loss: 147.935287\n",
            "Validation loss decreased (161.755661 --> 147.935287).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 165.436142\n",
            "Epoch: 3 \tTraining Loss: 82.470650 \tValidation Loss: 98.331772\n",
            "Validation loss decreased (147.935287 --> 98.331772).  Saving model ...\n",
            "Epoch 4, Batch 1 loss: 73.692429\n",
            "Epoch: 4 \tTraining Loss: 35.474304 \tValidation Loss: 35.250645\n",
            "Validation loss decreased (98.331772 --> 35.250645).  Saving model ...\n",
            "Epoch 5, Batch 1 loss: 19.508533\n",
            "Epoch: 5 \tTraining Loss: 27.493336 \tValidation Loss: 37.307041\n",
            "Epoch 6, Batch 1 loss: 5.460844\n",
            "Epoch: 6 \tTraining Loss: 22.593527 \tValidation Loss: 51.231647\n",
            "Epoch 7, Batch 1 loss: 18.508167\n",
            "Epoch: 7 \tTraining Loss: 25.403748 \tValidation Loss: 70.248428\n",
            "Epoch 8, Batch 1 loss: 28.740086\n",
            "Epoch: 8 \tTraining Loss: 16.465799 \tValidation Loss: 50.824104\n",
            "Epoch 9, Batch 1 loss: 3.050517\n",
            "Epoch: 9 \tTraining Loss: 15.643981 \tValidation Loss: 55.173508\n",
            "Epoch 10, Batch 1 loss: 17.527489\n",
            "Epoch: 10 \tTraining Loss: 14.997330 \tValidation Loss: 48.564339\n",
            "Epoch 11, Batch 1 loss: 16.077358\n",
            "Epoch: 11 \tTraining Loss: 10.986092 \tValidation Loss: 30.549347\n",
            "Validation loss decreased (35.250645 --> 30.549347).  Saving model ...\n",
            "Epoch 12, Batch 1 loss: 9.002106\n",
            "Epoch: 12 \tTraining Loss: 9.113070 \tValidation Loss: 41.550163\n",
            "Epoch 13, Batch 1 loss: 4.442794\n",
            "Epoch: 13 \tTraining Loss: 9.576401 \tValidation Loss: 47.958096\n",
            "Epoch 14, Batch 1 loss: 16.996746\n",
            "Epoch: 14 \tTraining Loss: 9.777955 \tValidation Loss: 47.401035\n",
            "2\n",
            "Epoch 1, Batch 1 loss: 16.406677\n",
            "Epoch: 1 \tTraining Loss: 19.839848 \tValidation Loss: 8.994790\n",
            "Validation loss decreased (inf --> 8.994790).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 25.091719\n",
            "Epoch: 2 \tTraining Loss: 18.722012 \tValidation Loss: 6.584730\n",
            "Validation loss decreased (8.994790 --> 6.584730).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 11.319361\n",
            "Epoch: 3 \tTraining Loss: 15.156802 \tValidation Loss: 8.002102\n",
            "Epoch 4, Batch 1 loss: 28.724539\n",
            "Epoch: 4 \tTraining Loss: 12.591393 \tValidation Loss: 6.163071\n",
            "Validation loss decreased (6.584730 --> 6.163071).  Saving model ...\n",
            "Epoch 5, Batch 1 loss: 4.187112\n",
            "Epoch: 5 \tTraining Loss: 13.434288 \tValidation Loss: 4.991982\n",
            "Validation loss decreased (6.163071 --> 4.991982).  Saving model ...\n",
            "Epoch 6, Batch 1 loss: 10.633739\n",
            "Epoch: 6 \tTraining Loss: 17.807734 \tValidation Loss: 9.852637\n",
            "Epoch 7, Batch 1 loss: 5.273367\n",
            "Epoch: 7 \tTraining Loss: 14.519198 \tValidation Loss: 4.796011\n",
            "Validation loss decreased (4.991982 --> 4.796011).  Saving model ...\n",
            "Epoch 8, Batch 1 loss: 4.733130\n",
            "Epoch: 8 \tTraining Loss: 11.393393 \tValidation Loss: 11.540211\n",
            "Epoch 9, Batch 1 loss: 14.923515\n",
            "Epoch: 9 \tTraining Loss: 10.761868 \tValidation Loss: 7.903353\n",
            "Epoch 10, Batch 1 loss: 10.062361\n",
            "Epoch: 10 \tTraining Loss: 10.816447 \tValidation Loss: 5.040545\n",
            "Epoch 11, Batch 1 loss: 10.477837\n",
            "Epoch: 11 \tTraining Loss: 9.339100 \tValidation Loss: 5.939199\n",
            "Epoch 12, Batch 1 loss: 4.860453\n",
            "Epoch: 12 \tTraining Loss: 8.588276 \tValidation Loss: 5.371150\n",
            "Epoch 13, Batch 1 loss: 3.858064\n",
            "Epoch: 13 \tTraining Loss: 7.667947 \tValidation Loss: 7.119717\n",
            "Epoch 14, Batch 1 loss: 7.367826\n",
            "Epoch: 14 \tTraining Loss: 8.779711 \tValidation Loss: 12.318471\n",
            "3\n",
            "Epoch 1, Batch 1 loss: 21.140696\n",
            "Epoch: 1 \tTraining Loss: 12.431154 \tValidation Loss: 5.478555\n",
            "Validation loss decreased (inf --> 5.478555).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 8.183376\n",
            "Epoch: 2 \tTraining Loss: 7.825760 \tValidation Loss: 4.197027\n",
            "Validation loss decreased (5.478555 --> 4.197027).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 4.453186\n",
            "Epoch: 3 \tTraining Loss: 12.412145 \tValidation Loss: 4.187009\n",
            "Validation loss decreased (4.197027 --> 4.187009).  Saving model ...\n",
            "Epoch 4, Batch 1 loss: 3.872917\n",
            "Epoch: 4 \tTraining Loss: 10.458120 \tValidation Loss: 11.772754\n",
            "Epoch 5, Batch 1 loss: 7.888569\n",
            "Epoch: 5 \tTraining Loss: 8.703466 \tValidation Loss: 4.778265\n",
            "Epoch 6, Batch 1 loss: 10.773360\n",
            "Epoch: 6 \tTraining Loss: 8.830089 \tValidation Loss: 5.838366\n",
            "Epoch 7, Batch 1 loss: 6.106362\n",
            "Epoch: 7 \tTraining Loss: 19.586206 \tValidation Loss: 35.243271\n",
            "Epoch 8, Batch 1 loss: 17.028467\n",
            "Epoch: 8 \tTraining Loss: 11.602269 \tValidation Loss: 28.454428\n",
            "Epoch 9, Batch 1 loss: 8.684587\n",
            "Epoch: 9 \tTraining Loss: 8.600023 \tValidation Loss: 15.336770\n",
            "Epoch 10, Batch 1 loss: 8.153193\n",
            "Epoch: 10 \tTraining Loss: 9.947354 \tValidation Loss: 14.463114\n",
            "Epoch 11, Batch 1 loss: 4.905182\n",
            "Epoch: 11 \tTraining Loss: 8.637819 \tValidation Loss: 17.222212\n",
            "Epoch 12, Batch 1 loss: 4.963948\n",
            "Epoch: 12 \tTraining Loss: 7.317616 \tValidation Loss: 21.039330\n",
            "Epoch 13, Batch 1 loss: 6.705432\n",
            "Epoch: 13 \tTraining Loss: 9.350425 \tValidation Loss: 15.524716\n",
            "Epoch 14, Batch 1 loss: 6.108454\n",
            "Epoch: 14 \tTraining Loss: 8.638796 \tValidation Loss: 38.950119\n"
          ]
        }
      ],
      "source": [
        "#Setting model and moving to device\n",
        "model_CNN = CNN1(True).to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "# optimizer = optim.SGD(model_CNN.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = optim.Adam(model_CNN.parameters(), lr=0.0005)\n",
        "\n",
        "## training model\n",
        "model_conv2,valid_loss_min2=cv_train(k=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cae8a1bbb2d34649b736aa710183f415",
            "75fe158b2b034aea9725757d6eba1743",
            "4c0a784a29b84361aa6e22ad749595f0",
            "feb6a1d7dea1432587c8dfd6189dc11b",
            "63da08f537714100914f9295f9be0b93",
            "5b30ad828fd14dc697da34f537b7daa6",
            "9065f2dc94d3461988c2dc1311aafd87",
            "5a180283f5304aef82b844e5e20f917a",
            "0ab7725bb68f47648e5b5df6ae5c048a",
            "4b995773b6eb4d8a83e22ecf106d084b",
            "1e6eabeca776498e9d5260198c80d40c"
          ]
        },
        "id": "sLK8ZcARszoM",
        "outputId": "891aabde-1cd8-4ac9-a61b-834f3ae598ac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cae8a1bbb2d34649b736aa710183f415",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "Epoch 1, Batch 1 loss: 17.204060\n",
            "Epoch: 1 \tTraining Loss: 8.288336 \tValidation Loss: 13.703668\n",
            "Validation loss decreased (inf --> 13.703668).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 6.245621\n",
            "Epoch: 2 \tTraining Loss: 6.670979 \tValidation Loss: 5.823530\n",
            "Validation loss decreased (13.703668 --> 5.823530).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 7.547464\n",
            "Epoch: 3 \tTraining Loss: 5.507205 \tValidation Loss: 7.046657\n",
            "Epoch 4, Batch 1 loss: 6.282132\n",
            "Epoch: 4 \tTraining Loss: 4.679069 \tValidation Loss: 7.005981\n",
            "Epoch 5, Batch 1 loss: 5.298170\n",
            "Epoch: 5 \tTraining Loss: 3.832575 \tValidation Loss: 6.864169\n",
            "Epoch 6, Batch 1 loss: 6.661264\n",
            "Epoch: 6 \tTraining Loss: 3.622874 \tValidation Loss: 6.235278\n",
            "Epoch 7, Batch 1 loss: 3.185163\n",
            "Epoch: 7 \tTraining Loss: 3.414101 \tValidation Loss: 5.902202\n",
            "Epoch 8, Batch 1 loss: 1.990951\n",
            "Epoch: 8 \tTraining Loss: 3.054630 \tValidation Loss: 4.911829\n",
            "Validation loss decreased (5.823530 --> 4.911829).  Saving model ...\n",
            "Epoch 9, Batch 1 loss: 2.107827\n",
            "Epoch: 9 \tTraining Loss: 2.832856 \tValidation Loss: 5.419910\n",
            "Epoch 10, Batch 1 loss: 2.554662\n",
            "Epoch: 10 \tTraining Loss: 3.107054 \tValidation Loss: 5.996853\n",
            "Epoch 11, Batch 1 loss: 1.568995\n",
            "Epoch: 11 \tTraining Loss: 2.953341 \tValidation Loss: 8.793843\n",
            "Epoch 12, Batch 1 loss: 4.238340\n",
            "Epoch: 12 \tTraining Loss: 2.510683 \tValidation Loss: 7.502400\n",
            "Epoch 13, Batch 1 loss: 3.799630\n",
            "Epoch: 13 \tTraining Loss: 2.090297 \tValidation Loss: 4.612908\n",
            "Validation loss decreased (4.911829 --> 4.612908).  Saving model ...\n",
            "Epoch 14, Batch 1 loss: 1.089250\n",
            "Epoch: 14 \tTraining Loss: 2.016332 \tValidation Loss: 5.080099\n",
            "1\n",
            "Epoch 1, Batch 1 loss: 5.736974\n",
            "Epoch: 1 \tTraining Loss: 3.405793 \tValidation Loss: 1.974317\n",
            "Validation loss decreased (inf --> 1.974317).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 2.181343\n",
            "Epoch: 2 \tTraining Loss: 2.903369 \tValidation Loss: 2.404805\n",
            "Epoch 3, Batch 1 loss: 2.883870\n",
            "Epoch: 3 \tTraining Loss: 3.330401 \tValidation Loss: 1.932156\n",
            "Validation loss decreased (1.974317 --> 1.932156).  Saving model ...\n",
            "Epoch 4, Batch 1 loss: 3.308275\n",
            "Epoch: 4 \tTraining Loss: 2.846864 \tValidation Loss: 2.346931\n",
            "Epoch 5, Batch 1 loss: 2.149835\n",
            "Epoch: 5 \tTraining Loss: 2.646996 \tValidation Loss: 1.904823\n",
            "Validation loss decreased (1.932156 --> 1.904823).  Saving model ...\n",
            "Epoch 6, Batch 1 loss: 1.572678\n",
            "Epoch: 6 \tTraining Loss: 2.561386 \tValidation Loss: 2.973689\n",
            "Epoch 7, Batch 1 loss: 3.537059\n",
            "Epoch: 7 \tTraining Loss: 3.027661 \tValidation Loss: 2.887442\n",
            "Epoch 8, Batch 1 loss: 1.620565\n",
            "Epoch: 8 \tTraining Loss: 2.616120 \tValidation Loss: 2.301606\n",
            "Epoch 9, Batch 1 loss: 2.986407\n",
            "Epoch: 9 \tTraining Loss: 2.187126 \tValidation Loss: 2.163004\n",
            "Epoch 10, Batch 1 loss: 2.224707\n",
            "Epoch: 10 \tTraining Loss: 2.327252 \tValidation Loss: 2.221138\n",
            "Epoch 11, Batch 1 loss: 1.661642\n",
            "Epoch: 11 \tTraining Loss: 2.062736 \tValidation Loss: 2.598844\n",
            "Epoch 12, Batch 1 loss: 2.311083\n",
            "Epoch: 12 \tTraining Loss: 1.832040 \tValidation Loss: 2.551920\n",
            "Epoch 13, Batch 1 loss: 2.757876\n",
            "Epoch: 13 \tTraining Loss: 1.922981 \tValidation Loss: 2.506984\n",
            "Epoch 14, Batch 1 loss: 0.984694\n",
            "Epoch: 14 \tTraining Loss: 2.084733 \tValidation Loss: 2.907162\n",
            "2\n",
            "Epoch 1, Batch 1 loss: 2.182214\n",
            "Epoch: 1 \tTraining Loss: 1.970824 \tValidation Loss: 2.412300\n",
            "Validation loss decreased (inf --> 2.412300).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 1.732289\n",
            "Epoch: 2 \tTraining Loss: 1.843290 \tValidation Loss: 1.395450\n",
            "Validation loss decreased (2.412300 --> 1.395450).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 1.540417\n",
            "Epoch: 3 \tTraining Loss: 1.588142 \tValidation Loss: 1.751777\n",
            "Epoch 4, Batch 1 loss: 1.689764\n",
            "Epoch: 4 \tTraining Loss: 1.552286 \tValidation Loss: 1.157177\n",
            "Validation loss decreased (1.395450 --> 1.157177).  Saving model ...\n",
            "Epoch 5, Batch 1 loss: 1.597130\n",
            "Epoch: 5 \tTraining Loss: 1.666893 \tValidation Loss: 2.705154\n",
            "Epoch 6, Batch 1 loss: 1.743423\n",
            "Epoch: 6 \tTraining Loss: 1.592149 \tValidation Loss: 1.508525\n",
            "Epoch 7, Batch 1 loss: 1.532709\n",
            "Epoch: 7 \tTraining Loss: 1.410820 \tValidation Loss: 2.090617\n",
            "Epoch 8, Batch 1 loss: 0.946224\n",
            "Epoch: 8 \tTraining Loss: 1.601006 \tValidation Loss: 1.692830\n",
            "Epoch 9, Batch 1 loss: 1.529642\n",
            "Epoch: 9 \tTraining Loss: 1.405690 \tValidation Loss: 1.362613\n",
            "Epoch 10, Batch 1 loss: 1.677657\n",
            "Epoch: 10 \tTraining Loss: 1.809523 \tValidation Loss: 1.627933\n",
            "Epoch 11, Batch 1 loss: 1.927765\n",
            "Epoch: 11 \tTraining Loss: 1.474320 \tValidation Loss: 1.632981\n",
            "Epoch 12, Batch 1 loss: 1.709230\n",
            "Epoch: 12 \tTraining Loss: 1.441942 \tValidation Loss: 1.555114\n",
            "Epoch 13, Batch 1 loss: 2.084473\n",
            "Epoch: 13 \tTraining Loss: 1.539559 \tValidation Loss: 1.857084\n",
            "Epoch 14, Batch 1 loss: 0.888029\n",
            "Epoch: 14 \tTraining Loss: 1.299866 \tValidation Loss: 2.643337\n",
            "3\n",
            "Epoch 1, Batch 1 loss: 2.437686\n",
            "Epoch: 1 \tTraining Loss: 1.968420 \tValidation Loss: 0.967203\n",
            "Validation loss decreased (inf --> 0.967203).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 1.022048\n",
            "Epoch: 2 \tTraining Loss: 1.800980 \tValidation Loss: 0.776697\n",
            "Validation loss decreased (0.967203 --> 0.776697).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 1.649864\n",
            "Epoch: 3 \tTraining Loss: 1.844160 \tValidation Loss: 1.000825\n",
            "Epoch 4, Batch 1 loss: 1.058605\n",
            "Epoch: 4 \tTraining Loss: 1.342328 \tValidation Loss: 1.108706\n",
            "Epoch 5, Batch 1 loss: 1.724117\n",
            "Epoch: 5 \tTraining Loss: 1.574903 \tValidation Loss: 1.128333\n",
            "Epoch 6, Batch 1 loss: 1.875562\n",
            "Epoch: 6 \tTraining Loss: 1.714503 \tValidation Loss: 0.862990\n",
            "Epoch 7, Batch 1 loss: 0.466186\n",
            "Epoch: 7 \tTraining Loss: 1.366086 \tValidation Loss: 1.237704\n",
            "Epoch 8, Batch 1 loss: 1.102798\n",
            "Epoch: 8 \tTraining Loss: 1.400415 \tValidation Loss: 0.884098\n",
            "Epoch 9, Batch 1 loss: 0.893127\n",
            "Epoch: 9 \tTraining Loss: 1.389801 \tValidation Loss: 1.091711\n",
            "Epoch 10, Batch 1 loss: 1.836817\n",
            "Epoch: 10 \tTraining Loss: 1.356625 \tValidation Loss: 0.940827\n",
            "Epoch 11, Batch 1 loss: 1.458233\n",
            "Epoch: 11 \tTraining Loss: 1.230986 \tValidation Loss: 0.847114\n",
            "Epoch 12, Batch 1 loss: 0.985363\n",
            "Epoch: 12 \tTraining Loss: 1.143862 \tValidation Loss: 1.070495\n",
            "Epoch 13, Batch 1 loss: 1.478799\n",
            "Epoch: 13 \tTraining Loss: 1.175735 \tValidation Loss: 1.202122\n",
            "Epoch 14, Batch 1 loss: 0.773960\n",
            "Epoch: 14 \tTraining Loss: 1.330857 \tValidation Loss: 1.197345\n"
          ]
        }
      ],
      "source": [
        "#Setting model and moving to device\n",
        "model_CNN = CNN2(True).to(device)\n",
        "\n",
        "criterion = nn.SmoothL1Loss()\n",
        "#optimizer = optim.SGD(model_CNN.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = optim.Adam(model_CNN.parameters(), lr=0.0005)\n",
        "\n",
        "## training model\n",
        "model_conv3,valid_loss_min3=cv_train(k=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRBr3rQc6nDm",
        "outputId": "549218e4-ce37-4786-feb0-1ceba415e0c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<module 'torch.cuda' from '/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py'>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYcvuy9XuSs2"
      },
      "outputs": [],
      "source": [
        "#Setting model and moving to device\n",
        "model_CNN = CNN3(True).to(device)\n",
        "\n",
        "criterion = nn.SmoothL1Loss()\n",
        "#optimizer = optim.SGD(model_CNN.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = optim.Adam(model_CNN.parameters(), lr=0.0005)\n",
        "\n",
        "## training model\n",
        "model_conv3,valid_loss_min3=cv_train(k=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBVmmy1muclK",
        "outputId": "0a1e55e7-2303-4b24-9fe2-b2f12b457e13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "Epoch 1, Batch 1 loss: 26.393410\n",
            "Epoch: 1 \tTraining Loss: 10.704541 \tValidation Loss: 8.541584\n",
            "Validation loss decreased (inf --> 8.541584).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 18.721191\n",
            "Epoch: 2 \tTraining Loss: 6.624544 \tValidation Loss: 6.062243\n",
            "Validation loss decreased (8.541584 --> 6.062243).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 6.440409\n",
            "Epoch: 3 \tTraining Loss: 6.225703 \tValidation Loss: 6.342294\n",
            "Epoch 4, Batch 1 loss: 4.825891\n",
            "Epoch: 4 \tTraining Loss: 5.340618 \tValidation Loss: 6.578068\n",
            "Epoch 5, Batch 1 loss: 7.345747\n",
            "Epoch: 5 \tTraining Loss: 4.805613 \tValidation Loss: 5.368511\n",
            "Validation loss decreased (6.062243 --> 5.368511).  Saving model ...\n",
            "Epoch 6, Batch 1 loss: 2.951734\n",
            "Epoch: 6 \tTraining Loss: 4.795612 \tValidation Loss: 7.648978\n",
            "Epoch 7, Batch 1 loss: 4.023851\n",
            "Epoch: 7 \tTraining Loss: 4.254448 \tValidation Loss: 5.551319\n",
            "Epoch 8, Batch 1 loss: 7.179605\n",
            "Epoch: 8 \tTraining Loss: 4.944319 \tValidation Loss: 4.787115\n",
            "Validation loss decreased (5.368511 --> 4.787115).  Saving model ...\n",
            "Epoch 9, Batch 1 loss: 2.720835\n",
            "Epoch: 9 \tTraining Loss: 4.169171 \tValidation Loss: 5.272889\n",
            "Epoch 10, Batch 1 loss: 3.629121\n",
            "Epoch: 10 \tTraining Loss: 3.195107 \tValidation Loss: 6.145646\n",
            "Epoch 11, Batch 1 loss: 2.803900\n",
            "Epoch: 11 \tTraining Loss: 3.285473 \tValidation Loss: 5.766869\n",
            "Epoch 12, Batch 1 loss: 3.813545\n",
            "Epoch: 12 \tTraining Loss: 3.343019 \tValidation Loss: 5.958863\n",
            "Epoch 13, Batch 1 loss: 3.724773\n",
            "Epoch: 13 \tTraining Loss: 2.998682 \tValidation Loss: 6.956916\n",
            "Epoch 14, Batch 1 loss: 4.100685\n",
            "Epoch: 14 \tTraining Loss: 3.002846 \tValidation Loss: 6.418864\n",
            "1\n",
            "Epoch 1, Batch 1 loss: 2.751076\n",
            "Epoch: 1 \tTraining Loss: 3.445366 \tValidation Loss: 2.552567\n",
            "Validation loss decreased (inf --> 2.552567).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 3.363415\n",
            "Epoch: 2 \tTraining Loss: 3.084492 \tValidation Loss: 3.943426\n",
            "Epoch 3, Batch 1 loss: 2.431679\n",
            "Epoch: 3 \tTraining Loss: 2.743841 \tValidation Loss: 3.185412\n",
            "Epoch 4, Batch 1 loss: 2.846439\n",
            "Epoch: 4 \tTraining Loss: 2.652272 \tValidation Loss: 3.089136\n",
            "Epoch 5, Batch 1 loss: 1.487981\n",
            "Epoch: 5 \tTraining Loss: 2.492269 \tValidation Loss: 2.943902\n",
            "Epoch 6, Batch 1 loss: 1.560173\n",
            "Epoch: 6 \tTraining Loss: 2.487900 \tValidation Loss: 6.119244\n",
            "Epoch 7, Batch 1 loss: 5.037970\n",
            "Epoch: 7 \tTraining Loss: 2.343847 \tValidation Loss: 3.516815\n",
            "Epoch 8, Batch 1 loss: 1.318261\n",
            "Epoch: 8 \tTraining Loss: 2.171670 \tValidation Loss: 3.024740\n",
            "Epoch 9, Batch 1 loss: 1.791992\n",
            "Epoch: 9 \tTraining Loss: 2.312456 \tValidation Loss: 4.362578\n",
            "Epoch 10, Batch 1 loss: 3.811621\n",
            "Epoch: 10 \tTraining Loss: 2.171836 \tValidation Loss: 4.483524\n",
            "Epoch 11, Batch 1 loss: 3.293169\n",
            "Epoch: 11 \tTraining Loss: 2.164979 \tValidation Loss: 3.298889\n",
            "Epoch 12, Batch 1 loss: 2.332764\n",
            "Epoch: 12 \tTraining Loss: 1.933282 \tValidation Loss: 2.808948\n",
            "Epoch 13, Batch 1 loss: 1.609431\n",
            "Epoch: 13 \tTraining Loss: 1.728840 \tValidation Loss: 3.357959\n",
            "Epoch 14, Batch 1 loss: 1.210796\n",
            "Epoch: 14 \tTraining Loss: 2.167637 \tValidation Loss: 3.429233\n",
            "2\n",
            "Epoch 1, Batch 1 loss: 3.261141\n",
            "Epoch: 1 \tTraining Loss: 2.580327 \tValidation Loss: 3.548683\n",
            "Validation loss decreased (inf --> 3.548683).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 1.937978\n",
            "Epoch: 2 \tTraining Loss: 2.809040 \tValidation Loss: 1.296348\n",
            "Validation loss decreased (3.548683 --> 1.296348).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 3.559692\n",
            "Epoch: 3 \tTraining Loss: 2.232631 \tValidation Loss: 1.493937\n",
            "Epoch 4, Batch 1 loss: 1.930159\n",
            "Epoch: 4 \tTraining Loss: 2.219546 \tValidation Loss: 1.390850\n",
            "Epoch 5, Batch 1 loss: 1.874236\n",
            "Epoch: 5 \tTraining Loss: 2.031519 \tValidation Loss: 1.248226\n",
            "Validation loss decreased (1.296348 --> 1.248226).  Saving model ...\n",
            "Epoch 6, Batch 1 loss: 2.316832\n",
            "Epoch: 6 \tTraining Loss: 2.165668 \tValidation Loss: 1.352754\n",
            "Epoch 7, Batch 1 loss: 3.856695\n",
            "Epoch: 7 \tTraining Loss: 2.000010 \tValidation Loss: 1.825675\n",
            "Epoch 8, Batch 1 loss: 1.612749\n",
            "Epoch: 8 \tTraining Loss: 1.852759 \tValidation Loss: 1.984029\n",
            "Epoch 9, Batch 1 loss: 1.179146\n",
            "Epoch: 9 \tTraining Loss: 1.941442 \tValidation Loss: 1.924146\n",
            "Epoch 10, Batch 1 loss: 1.498281\n",
            "Epoch: 10 \tTraining Loss: 2.141470 \tValidation Loss: 1.689799\n",
            "Epoch 11, Batch 1 loss: 1.327950\n",
            "Epoch: 11 \tTraining Loss: 1.910533 \tValidation Loss: 2.334144\n",
            "Epoch 12, Batch 1 loss: 1.956792\n",
            "Epoch: 12 \tTraining Loss: 2.004815 \tValidation Loss: 1.350683\n",
            "Epoch 13, Batch 1 loss: 1.275437\n",
            "Epoch: 13 \tTraining Loss: 1.975666 \tValidation Loss: 1.393790\n",
            "Epoch 14, Batch 1 loss: 3.776517\n",
            "Epoch: 14 \tTraining Loss: 1.986747 \tValidation Loss: 1.836097\n",
            "3\n",
            "Epoch 1, Batch 1 loss: 2.268735\n",
            "Epoch: 1 \tTraining Loss: 1.771253 \tValidation Loss: 1.096131\n",
            "Validation loss decreased (inf --> 1.096131).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 1.081677\n",
            "Epoch: 2 \tTraining Loss: 1.875242 \tValidation Loss: 0.930786\n",
            "Validation loss decreased (1.096131 --> 0.930786).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 1.170198\n",
            "Epoch: 3 \tTraining Loss: 1.814905 \tValidation Loss: 1.023490\n",
            "Epoch 4, Batch 1 loss: 1.224455\n",
            "Epoch: 4 \tTraining Loss: 1.728519 \tValidation Loss: 1.583263\n",
            "Epoch 5, Batch 1 loss: 2.352843\n",
            "Epoch: 5 \tTraining Loss: 1.660437 \tValidation Loss: 0.989466\n",
            "Epoch 6, Batch 1 loss: 2.569325\n",
            "Epoch: 6 \tTraining Loss: 1.660324 \tValidation Loss: 1.423295\n",
            "Epoch 7, Batch 1 loss: 1.593301\n",
            "Epoch: 7 \tTraining Loss: 1.676461 \tValidation Loss: 1.202206\n",
            "Epoch 8, Batch 1 loss: 1.880923\n",
            "Epoch: 8 \tTraining Loss: 1.736173 \tValidation Loss: 1.017153\n",
            "Epoch 9, Batch 1 loss: 1.329840\n",
            "Epoch: 9 \tTraining Loss: 1.616120 \tValidation Loss: 1.058836\n",
            "Epoch 10, Batch 1 loss: 1.349606\n",
            "Epoch: 10 \tTraining Loss: 1.438676 \tValidation Loss: 1.132954\n",
            "Epoch 11, Batch 1 loss: 1.068774\n",
            "Epoch: 11 \tTraining Loss: 1.506087 \tValidation Loss: 1.640239\n",
            "Epoch 12, Batch 1 loss: 2.920017\n",
            "Epoch: 12 \tTraining Loss: 1.758475 \tValidation Loss: 1.813938\n",
            "Epoch 13, Batch 1 loss: 1.683419\n",
            "Epoch: 13 \tTraining Loss: 1.807595 \tValidation Loss: 1.514521\n",
            "Epoch 14, Batch 1 loss: 1.988578\n",
            "Epoch: 14 \tTraining Loss: 1.610194 \tValidation Loss: 2.432391\n"
          ]
        }
      ],
      "source": [
        "#Setting model and moving to device\n",
        "model_CNN = CNN4(True).to(device)\n",
        "\n",
        "criterion = nn.SmoothL1Loss()\n",
        "#optimizer = optim.SGD(model_CNN.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = optim.Adam(model_CNN.parameters(), lr=0.0005)\n",
        "\n",
        "## training model\n",
        "model_conv4,valid_loss_min4=cv_train(k=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNGjcjWMGrNk"
      },
      "outputs": [],
      "source": [
        "cri_set = [nn.L1Loss(),\n",
        "           nn.CrossEntropyLoss(),\n",
        "           nn.CrossEntropyLoss(label_smoothing=0.1)]\n",
        "optim_set = [optim.Adam(model_CNN.parameters(), lr=0.0005)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5SofOm8Nrej"
      },
      "outputs": [],
      "source": [
        "from itertools import product, chain\n",
        "\n",
        "comp_model = []\n",
        "comp_valid_loss = []\n",
        "for n, (cri,optim) in enumerate(product(cri_set, optim_set)):\n",
        "    print(n,cri,optim)\n",
        "    criterion = cri\n",
        "    optimizer = optim\n",
        "\n",
        "    model_conv,valid_loss_min=cv_train(k=4)\n",
        "    comp_model.append(model_conv)\n",
        "    comp_valid_loss.append(valid_loss_min)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewvENjMYYI3O"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7bWS52qYKLD"
      },
      "source": [
        "#### view distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "MxwYKyOTYNrH",
        "outputId": "7accfb72-d825-497c-bf72-ed38ba230eed"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "idx = pd.read_csv('drive/MyDrive/DL_Project/Train.csv',header=None)\n",
        "idx.iloc[:,2].plot.density(color='green')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1YgmKV-Y6JY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Competition_decoder.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0896d0cd9c4748bcb97a2d62ddbbb4b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ab7725bb68f47648e5b5df6ae5c048a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b98173bafa145d6b4177980dbcc8e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc64b23ee7e347b88c382f04ed060ecf",
            "placeholder": "",
            "style": "IPY_MODEL_bd7f5b63ebd5454ea06d65a56c7494a3",
            "value": "100%"
          }
        },
        "137209566cb74b059ad382754a47a701": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e6eabeca776498e9d5260198c80d40c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f7d61cd7f7c4f458ae4f3e33c02f648": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3caab6801e204676a38d022d3e6d0661": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b995773b6eb4d8a83e22ecf106d084b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c0a784a29b84361aa6e22ad749595f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a180283f5304aef82b844e5e20f917a",
            "max": 46827520,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ab7725bb68f47648e5b5df6ae5c048a",
            "value": 46827520
          }
        },
        "5a180283f5304aef82b844e5e20f917a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b30ad828fd14dc697da34f537b7daa6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5faf3b346fa44c75aded558eb391118d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63da08f537714100914f9295f9be0b93": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "661d9d1b11894dbd98ddad952e7ec2db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1660f5e755b4806aae88416788eac16",
              "IPY_MODEL_c914c2847f0a48a6b9c62333b44f4f5b",
              "IPY_MODEL_cf50c8c99ad84493bc8e3fab0e03e09f"
            ],
            "layout": "IPY_MODEL_ee52f13df6794edb82309fc823105d33"
          }
        },
        "75fe158b2b034aea9725757d6eba1743": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b30ad828fd14dc697da34f537b7daa6",
            "placeholder": "",
            "style": "IPY_MODEL_9065f2dc94d3461988c2dc1311aafd87",
            "value": "100%"
          }
        },
        "7bc572e934ba405bbe39a2fd44c02d2c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "830b1d5682c94b96b1551345f2e7e7bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9065f2dc94d3461988c2dc1311aafd87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd7f5b63ebd5454ea06d65a56c7494a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf3333241e054d0fa2a46657cdacbed6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c914c2847f0a48a6b9c62333b44f4f5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5faf3b346fa44c75aded558eb391118d",
            "max": 87306240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f7d61cd7f7c4f458ae4f3e33c02f648",
            "value": 87306240
          }
        },
        "cae8a1bbb2d34649b736aa710183f415": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75fe158b2b034aea9725757d6eba1743",
              "IPY_MODEL_4c0a784a29b84361aa6e22ad749595f0",
              "IPY_MODEL_feb6a1d7dea1432587c8dfd6189dc11b"
            ],
            "layout": "IPY_MODEL_63da08f537714100914f9295f9be0b93"
          }
        },
        "cc6d157f800f4c96b8da64a32a1298ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf50c8c99ad84493bc8e3fab0e03e09f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_830b1d5682c94b96b1551345f2e7e7bd",
            "placeholder": "",
            "style": "IPY_MODEL_3caab6801e204676a38d022d3e6d0661",
            "value": " 83.3M/83.3M [00:02&lt;00:00, 66.9MB/s]"
          }
        },
        "e1660f5e755b4806aae88416788eac16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e170e4f8325647a7a4c8baa73521e489",
            "placeholder": "",
            "style": "IPY_MODEL_137209566cb74b059ad382754a47a701",
            "value": "100%"
          }
        },
        "e170e4f8325647a7a4c8baa73521e489": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e84546b433f1415ea6287656adf1703b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee52f13df6794edb82309fc823105d33": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef461751c81746a0beb9254782b89ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc6d157f800f4c96b8da64a32a1298ec",
            "placeholder": "",
            "style": "IPY_MODEL_bf3333241e054d0fa2a46657cdacbed6",
            "value": " 83.3M/83.3M [00:02&lt;00:00, 36.4MB/s]"
          }
        },
        "f74ca6a37b2146799c5fcb5b152fb607": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bc572e934ba405bbe39a2fd44c02d2c",
            "max": 87306240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e84546b433f1415ea6287656adf1703b",
            "value": 87306240
          }
        },
        "fc64b23ee7e347b88c382f04ed060ecf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feb6a1d7dea1432587c8dfd6189dc11b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b995773b6eb4d8a83e22ecf106d084b",
            "placeholder": "",
            "style": "IPY_MODEL_1e6eabeca776498e9d5260198c80d40c",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 72.3MB/s]"
          }
        },
        "ffda023e33ca45bfb72bd87bc878e847": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b98173bafa145d6b4177980dbcc8e28",
              "IPY_MODEL_f74ca6a37b2146799c5fcb5b152fb607",
              "IPY_MODEL_ef461751c81746a0beb9254782b89ad5"
            ],
            "layout": "IPY_MODEL_0896d0cd9c4748bcb97a2d62ddbbb4b1"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}